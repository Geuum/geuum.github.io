<!doctype html>



  


<html class="theme-next muse use-motion">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.1" />






<meta name="description" content="æ˜¯ç¿©ç¿©å…¬å­ï¼Œä¹Ÿæ˜¯æµŠä¸–çƒŸæª
æ˜¯ä¸‰åˆ†å‰‘ä¾ ï¼Œåˆæ˜¯ä¸‰åˆ†éªšå®¢
çˆ±è‡ªç”±åˆè¨€æ…ç‹¬
æ˜æ˜¯éå´æ€§æ¿€æ„¤
è½»è£…ä¸Šé˜µï¼Œä¸å¿˜ä¸‡é‡Œå±±æ²³
æ¬²ç™»äº‘å¤©ï¼Œè°äººå»æˆ‘é˜¡é™Œ
å°†é”™å°±é”™æ— äººä¹‹è¿‡
ä¼¼é†’éé†’æœ¬æ˜¯å¯‚å¯">
<meta property="og:type" content="website">
<meta property="og:title" content="Lvvançš„åšå®¢">
<meta property="og:url" content="http://lvvan.top/index.html">
<meta property="og:site_name" content="Lvvançš„åšå®¢">
<meta property="og:description" content="æ˜¯ç¿©ç¿©å…¬å­ï¼Œä¹Ÿæ˜¯æµŠä¸–çƒŸæª
æ˜¯ä¸‰åˆ†å‰‘ä¾ ï¼Œåˆæ˜¯ä¸‰åˆ†éªšå®¢
çˆ±è‡ªç”±åˆè¨€æ…ç‹¬
æ˜æ˜¯éå´æ€§æ¿€æ„¤
è½»è£…ä¸Šé˜µï¼Œä¸å¿˜ä¸‡é‡Œå±±æ²³
æ¬²ç™»äº‘å¤©ï¼Œè°äººå»æˆ‘é˜¡é™Œ
å°†é”™å°±é”™æ— äººä¹‹è¿‡
ä¼¼é†’éé†’æœ¬æ˜¯å¯‚å¯">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Lvvançš„åšå®¢">
<meta name="twitter:description" content="æ˜¯ç¿©ç¿©å…¬å­ï¼Œä¹Ÿæ˜¯æµŠä¸–çƒŸæª
æ˜¯ä¸‰åˆ†å‰‘ä¾ ï¼Œåˆæ˜¯ä¸‰åˆ†éªšå®¢
çˆ±è‡ªç”±åˆè¨€æ…ç‹¬
æ˜æ˜¯éå´æ€§æ¿€æ„¤
è½»è£…ä¸Šé˜µï¼Œä¸å¿˜ä¸‡é‡Œå±±æ²³
æ¬²ç™»äº‘å¤©ï¼Œè°äººå»æˆ‘é˜¡é™Œ
å°†é”™å°±é”™æ— äººä¹‹è¿‡
ä¼¼é†’éé†’æœ¬æ˜¯å¯‚å¯">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 0,
      author: 'åšä¸»'
    }
  };
</script>




  <link rel="canonical" href="http://lvvan.top/"/>

  <title> Lvvançš„åšå®¢ </title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  










  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container one-collumn sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Lvvançš„åšå®¢</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle">å¤œåˆèŠ±å¼€é¦™æ»¡åº­ï¼Œå¤œæ·±å¾®é›¨é†‰åˆé†’</p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            é¦–é¡µ
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            åˆ†ç±»
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            å…³äº
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            å½’æ¡£
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            æ ‡ç­¾
          </a>
        </li>
      

      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/03/ä¸€ç§åŸºäºDualåæ ‡ä¸‹é™æ³•çš„SVM/" itemprop="url">
                  ä¸€ç§åŸºäºDualåæ ‡ä¸‹é™æ³•çš„SVM
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">å‘è¡¨äº</span>
            <time itemprop="dateCreated" datetime="2016-10-03T14:43:22+08:00" content="2016-10-03">
              2016-10-03
            </time>
          </span>

          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/10/03/ä¸€ç§åŸºäºDualåæ ‡ä¸‹é™æ³•çš„SVM/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/10/03/ä¸€ç§åŸºäºDualåæ ‡ä¸‹é™æ³•çš„SVM/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>From</p>
<ul>
<li><em><a href="http://www.csie.ntu.edu.tw/~cjlin/papers/cddual.pdf" target="_blank" rel="external">A Dual Coordinate Descent Method for Large-scale Linear SVM</a></em></li>
<li>C.-J. Hsieh, K.-W. Chang, C.-J. Lin, S. Sundararajan, and S. Sathiya Keerthi.</li>
<li><strong>ICML</strong> 2008</li>
</ul>
<hr>
<h1 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a>SVM</h1><p>SVMä½œä¸ºä¸€ç§ååˆ†æœ‰æ•ˆçš„åˆ†ç±»å™¨ï¼Œå…¶instanceã€labelç»„æˆè¿™æ ·çš„å½¢å¼${x_i,y_i}$çš„å½¢å¼ï¼Œå…¶ä¸­$x_i\in R^n,y_i\in{-1.+1}$ã€‚æœ€ç»ˆéœ€è¦è§£å†³çš„å°±æ˜¯è¿™æ ·ä¸€ä¸ªé—®é¢˜<br>$$<br>\min_w\frac{1}{2}w^\top w+C\sum^l_{i=1}\xi(w;x_i,y_i)<br>$$</p>
<p>å…¶ä¸­$C&gt;0$ç§°ä¸ºæƒ©ç½šå› å­ï¼ˆpenalty parameterï¼‰,$\xi(w;x_i,y_i)$æ˜¯æŸå¤±å‡½æ•°ï¼ˆloss functionï¼‰ã€‚</p>
<p>ä¸€èˆ¬å¸¸ç”¨çš„æŸå¤±å‡½æ•°æœ‰ä¸¤ä¸ªåˆ†åˆ«æ˜¯</p>
<p>$$<br>\begin{array}{l}<br>\displaystyle L1:\max{(1-y_iw^\top x_i,0)} \<br>\displaystyle L2:\max{(1-y_iw^\top x_i,0)^2}<br>\end{array}<br>$$</p>
<p>æ‰€ä»¥å¸¦è¿™ä¸¤ä¸ªæŸå¤±å‡½æ•°çš„SVMåˆ†åˆ«å«åšL1-SVMï¼ŒL2-SVMã€‚</p>
<p>SVMé—®é¢˜å¯èƒ½ä¼šæœ‰åç½®bï¼Œä¸€èˆ¬éƒ½æ˜¯é€šè¿‡å¢åŠ ä¸€ä¸ªç»´åº¦æ¥å®ç°</p>
<p>$$<br>x_i^\top\leftarrow[x_i^\top,1]\ \ \ \ w^\top\leftarrow[w^\top,b]<br>$$<br>ä»¥ä¸ŠSVMé—®é¢˜è¢«ç§°ä¸ºåŸé—®é¢˜ï¼ˆprimal problemï¼‰</p>
<p>ç›¸å¯¹åº”ï¼Œæˆ‘ä»¬è¿˜æœ‰å¯¹å¶é—®é¢˜ï¼ˆdual problemï¼‰çš„å½¢å¼ã€‚</p>
<p>$$<br>\begin{array}{l}<br>\displaystyle \min_\alpha f(\alpha)=\frac{1}{2}\alpha^\top\bar{Q}\alpha-e^\top\alpha \<br>\displaystyle s.t.\ \ 0\le\alpha_i\le U,\forall i<br>\end{array}<br>$$</p>
<p>$\bar{Q}=Q+D$ï¼ŒDæ˜¯å¯¹è§’çŸ©é˜µï¼Œ$Q_{ij}=y_iy_jx_i\top x_j$ã€‚</p>
<p>å¯¹äºL1-SVMï¼Œ$U=C$ï¼Œ$D_{ii}=0$ã€‚</p>
<p>å¯¹äºL2-SVMï¼Œ$U=\infty$ï¼Œ$D_{ii}=\frac{1}{2C}$ã€‚</p>
<h1 id="åæ ‡ä¸‹é™æ³•"><a href="#åæ ‡ä¸‹é™æ³•" class="headerlink" title="åæ ‡ä¸‹é™æ³•"></a>åæ ‡ä¸‹é™æ³•</h1><p>åæ ‡ä¸‹é™æ³•æ˜¯ä¸€ç§ä¼˜åŒ–æ‰‹æ®µï¼Œè¯¥æ–¹æ³•é€šè¿‡æœ€å°åŒ–å•å˜é‡å­é—®é¢˜æ¥æ›´æ–°å‚æ•°è¾¾åˆ°ä¼˜åŒ–çš„ç›®çš„ã€‚</p>
<p>é¦–å…ˆï¼Œè€ƒè™‘æˆ‘ä»¬çš„SVM-dualå½¢å¼ï¼Œæˆ‘ä»¬è¿‡å»çš„è®¡ç®—æ–¹æ³•æ˜¯é€šè¿‡ä¸æ–­è¿­ä»£$\alpha$æ¥æ›´æ–°å‚æ•°ï¼Œè¿­ä»£çš„è¿‡ç¨‹å°†ä¼šç”±åˆå§‹åŒ–çš„$\alpha^0\in R^l$ä¸€ç›´åˆ°è¾¾åˆ°stop conditionä¸ºæ­¢ã€‚è¿™ä¸€è¿‡ç¨‹å°†ç”Ÿæˆè¿™æ ·ä¸€ä¸ªåºåˆ—<br>$$<br>{\alpha^0,\alpha^1,\alpha^2,â€¦,\alpha^\infty}<br>$$<br>å½“ç„¶å®é™…è¿‡ç¨‹ä¸­ä¸ä¼šåˆ°$\alpha^\infty$ï¼Œä½†æ˜¯æˆ‘ä»¬å¯ä»¥å°†è¿™ä¸ªä¸æ–­è¿­ä»£çš„è¿‡ç¨‹æŠ½è±¡ä¸ºä»$\alpha^K$åˆ°$\alpha^{K+1}$çš„è¿‡ç¨‹ã€‚</p>
<p>ç„¶è€Œï¼Œç”±äº$\alpha^K$æ˜¯å‘é‡ï¼Œæ‰€ä»¥åœ¨è®¡ç®—çš„è¿‡ç¨‹ä¸­ï¼Œåˆå¯ä»¥å°†è¿™ä¸ªå‘é‡æ‹†è§£ï¼Œå°†å…¶ç»„æˆä¸­çš„ä¸€ä¸ªä¸ªæ ‡é‡å…ƒç´ æŒ‰é¡ºåºè¿­ä»£ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œå‡å¦‚$\alpha^K$å±•å¼€å¯ä»¥å†™æˆ$[\alpha^k_1,\alpha^k_2,\alpha^k_3,â€¦,\alpha^k_l]$ï¼Œåœ¨è¿­ä»£è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä¸æ˜¯ç›´æ¥è¿­ä»£$\alpha^K$è¿™ä¸ªå‘é‡ï¼Œè€Œæ˜¯ä¸€ä¸ªä¸€ä¸ªæ›´æ–°å…¶å…ƒç´ ï¼Œå…ˆæ˜¯$\alpha^k_1$ï¼Œç„¶åæ˜¯$\alpha^k_2$ï¼Œä¾æ¬¡ç±»æ¨ã€‚æ›´æ–°åçš„å…ƒç´ å°±å˜æˆäº†$\alpha^{K+1}_1$ï¼Œ$\alpha^{K+1}_2$ã€‚æŠŠè¿™ä¸ªæ›´æ–°å†™æˆä¸€èˆ¬è¡¨è¾¾å¼å°±æ˜¯</p>
<p>$$<br>\alpha^{k,i}=[\alpha^{k+1}_1,\alpha^{k+1}_2,\alpha^{k+1}_3,â€¦,\alpha^{k+1}_{i-1},\alpha^k_i,â€¦,\alpha^k_i],\ \forall{i=2,â€¦l}<br>$$</p>
<p>$\alpha^{k,i}$å°±æ˜¯æ›´æ–°åˆ°ç¬¬iä¸ªå…ƒç´ çš„$\alpha^k$ã€‚æ‰€ä»¥ï¼Œæˆ‘ä»¬å¾ˆå®¹æ˜“å°±èƒ½çŸ¥é“ï¼Œ$\alpha^{k,1}=\alpha^k$ï¼Œ$\alpha^{k,1+l}=\alpha^{k+1}$ï¼Œä¸€ä¸ªå‘é‡å…¨éƒ¨å…ƒç´ éƒ½æ›´æ–°å®Œäº†ï¼Œä»–ä¹Ÿå°±è¦+1äº†ã€‚</p>
<p>äºæ˜¯æˆ‘ä»¬æŠŠåŸæ¥çš„é—®é¢˜è½¬åŒ–ä¸ºæ›´æ–°å…¶å­å…ƒç´ çš„é—®é¢˜ï¼Œè¿™ä¸ªé—®é¢˜å°±å«å­é—®é¢˜ã€‚</p>
<p>å› ä¸ºç»„æˆå…ƒç´ åªæ˜¯æ ‡é‡ï¼Œæ‰€ä»¥å¯¹äºå…¶æ›´æ–°ï¼Œåªè€ƒè™‘åšåŠ æ³•ï¼Œä¹Ÿå°±æ˜¯åŸæ¥çš„å€¼åŠ ä¸Šä»€ä¹ˆâ€œdâ€å˜æˆäº†æ–°çš„å€¼ï¼Œè¿™ä¸ªåŠ ä¸Šçš„â€œdâ€å°±æ˜¯æˆ‘ä»¬å­é—®é¢˜çš„å˜é‡ï¼Œä¹Ÿæ˜¯å”¯ä¸€å˜é‡ã€‚</p>
<p>æ‰€ä»¥ä»$\alpha^{k,i}$åˆ°$\alpha^{k,i+1}$ï¼Œå®é™…ä¸Šå°±æ˜¯</p>
<p>$$<br>\begin{array}{l}<br>\displaystyle [\alpha^{k+1}_1,\alpha^{k+1}_2,\alpha^{k+1}_3,â€¦,\alpha^{k+1}_{i-1},\alpha^{k+1}_i+d,â€¦,\alpha^k_i] \<br>\displaystyle =\alpha^{k,i}+de_i<br>\end{array}<br>$$<br>è¿™é‡Œçš„$e_i=[0,â€¦,0,1,0,â€¦,0]^\top$ï¼Œ1çš„å‰é¢ç”±i-1ä¸ª0ã€‚</p>
<p>æ‰€ä»¥å¯¹äºSVM-dualé—®é¢˜ï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥å°†è¿™é‡Œçš„$\alpha^{k,i}+de_i$å¸¦å…¥è®¡ç®—ã€‚é—®é¢˜å°±è½¬åŒ–ä¸º</p>
<p>$$<br>\min_d{f(\alpha^{k,i}+de_i)},\ \ \ s.t.\ \ 0\le\alpha_i^k+d\le U<br>$$</p>
<p>å°†å¼å­å±•å¼€ï¼Œé—®é¢˜å°±å˜æˆäº†ä¸€ä¸ªå…³äºdçš„ç®€å•çš„äºŒæ¬¡å‡½æ•°ã€‚</p>
<p>$$<br>f(\alpha^{k,i}+de_i)=\frac{1}{2}\bar{Q}_{ii}d^2+\nabla_if(\alpha^{k,i})d+constant<br>$$</p>
<p>ä»–çš„æœ€å°å€¼å¾ˆç®€å•ï¼Œåˆä¸­çš„çŸ¥è¯†ï¼ŒäºŒå…ƒä¸€æ¬¡æ–¹ç¨‹çš„æå€¼åœ¨$\frac{-b}{2a}$å¤„ï¼Œä¹Ÿå°±æ˜¯$-\frac{\nabla_if(\alpha^{k,i})}{\bar{Q}_{ii}}$å¤„ã€‚</p>
<p>ä¸è¿‡è¦å–è¿™ä¸ªæå€¼ï¼Œè¦æœ‰æ¡ä»¶ï¼Œæˆ‘ä»¬ä¹‹å‰é™åˆ¶äº†$0\le\alpha_i^k+d\le U$ï¼Œæ‰€ä»¥æˆ‘ä»¬å¾—åˆ°$-\frac{\nabla_if(\alpha^{k,i})}{\bar{Q}_{ii}}$çš„æ¢¯åº¦éœ€è¦è€ƒè™‘è¾¹ç¼˜æ¡ä»¶ã€‚</p>
<p>æˆ‘ä»¬ç”¨$\nabla^Pf(\alpha)$æ¥è¡¨ç¤ºæŠ•å°„æ¢¯åº¦</p>
<p>$$<br>\nabla^P_if(\alpha)=<br>\begin{cases}<br>\nabla_if(\alpha)\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \text{if}\ 0&lt;\alpha_i&lt;U,\\<br>\min{(0,\nabla_if(\alpha))}\ \ \ \ \text{if}\ \alpha_i=0,\\<br>\max{(0,\nabla_if(\alpha))}\ \ \ \ \text{if}\ \alpha_i=U<br>\end{cases}<br>$$</p>
<p>æ›´æ–°å…ƒç´ çš„æœ€ç»ˆç›®çš„æ˜¯ä»€ä¹ˆï¼Œå°±æ˜¯è®©å…ƒç´ ä¸æ›´æ–°äº†ï¼Œæ¯æ¬¡éƒ½æ˜¯ä¸€æ ·çš„ï¼Œæ„å³d=0ï¼Œè¿™æ ·æ‰¾åˆ°çš„$\alpha$æ‰æ˜¯æœ€ä¼˜çš„ã€‚</p>
<p>$$<br>d=0\Rightarrow-\frac{\nabla_if(\alpha^{k,i})}{\bar{Q}_{ii}}=0\Rightarrow\nabla_if(\alpha^{k,i})=0\ \ \ \ \ \ \ 0&lt;\alpha_i&lt;U<br>$$<br>å½“$\alpha_i=0$æˆ–è€…$\alpha_i=U$è¯¥æ€ä¹ˆåŠå‘¢ï¼Ÿ</p>
<p>å¯¹äºè¾¹ç¼˜ä¸Šçš„æ¢¯åº¦ï¼Œæˆ‘ä»¬åªè¦ä¿è¯ç­‰äºä¸‹é™æ—¶æ¢¯åº¦ä¸å¤§äº0ï¼Œç­‰äºä¸Šé™æ—¶æ¢¯åº¦ä¸å°äº0å³å¯ã€‚</p>
<p>æ‰€ä»¥å¯¹äºd=0ï¼Œåªè¦ä¿è¯$\nabla^P_if(\alpha)=0$ã€‚</p>
<p>å½“d=0æ—¶ï¼Œå…ƒç´ æ˜¯ä¸ç”¨æ›´æ–°çš„ã€‚</p>
<p>è¿™æ ·ï¼Œå¦‚æœ$\nabla^P_if(\alpha)\ne0$ï¼Œæˆ‘ä»¬æ›´æ–°åçš„å…ƒç´ <br>$$<br>\alpha^{k,i+1}_i=\min{(\max{(\alpha^{k,i}_i-\frac{\nabla_if(\alpha^{k,i})}{\bar{Q}_{ii}},0)},U)}<br>$$</p>
<p>æ‰€ä»¥ä¸æ›´æ–°å…ƒç´ æœ€å¥½ï¼Œä¸€æ—¦è¦æ›´æ–°åªéœ€è¦è®¡ç®—$\frac{\nabla_if(\alpha^{k,i})}{\bar{Q}_{ii}}$å³å¯ï¼Œåˆ$\bar{Q}_{ii}$æ˜¯å·²çŸ¥çš„ï¼ˆ$\bar{Q}=Q+D$ï¼Œ$Q_{ij}=y_iy_jx_i\top x_j$ï¼Œ$y=\pm1$ï¼‰ï¼Œæ‰€ä»¥åªè¦è®¡ç®—$\nabla_if(\alpha^{k,i})$å³å¯ï¼Œæ‰€ä»¥</p>
<p>$$<br>\begin{array}{l}<br>\displaystyle \ \ \ \ \nabla_if(\alpha)\\<br>\displaystyle =(\bar{Q}\alpha)_i-1\\<br>\displaystyle =\sum_{j=1}^l\bar{Q}_{ij}\alpha_j-1\\<br>\displaystyle =\sum_{j=1}^l(y_iy_jx_i^\top x_j+D_{ij})\alpha_j-1\\<br>\displaystyle =\sum_{j=1}^l(y_iy_j\alpha_jx_i^\top x_j)+D_{ii}\alpha_i-1<br>\end{array}<br>$$<br>åœ¨çº¿æ€§SVMä¸­ï¼Œæˆ‘ä»¬çŸ¥é“é€šè¿‡è¶…å¹³é¢æ¥åˆ†ç±»ï¼Œä¸€èˆ¬å½¢å¼æ˜¯</p>
<p>$$<br>f(x)=w^\top x+b<br>$$</p>
<p>æ ¹æ®<em>Functional margin</em>çš„å®šä¹‰ï¼Œ<br>$$<br>\hat{\gamma} = y(w^{\top}x + b) = yf(x)<br>$$</p>
<p>è¿™ä¸ªå½¢å¼æ˜¯ä¸æ˜¯å’Œæˆ‘ä»¬ä¸Šé¢çš„$\nabla_if(\alpha)$ç›¸ä¼¼ï¼Œæ²¡é”™ï¼Œå¦‚æœSVMæ˜¯çº¿æ€§çš„ï¼Œæˆ‘ä»¬å°±å¯ä»¥æŠŠ$\nabla_if(\alpha)$å½“ä½œè¶…å¹³é¢æ¥è®¡ç®—ã€‚æˆ‘ä»¬å®šä¹‰<br>$$<br>w=\sum_{j=1}^l{y_j\alpha_jx_j}<br>$$</p>
<p>äºæ˜¯ï¼Œ$\nabla_if(\alpha)$å°±å˜æˆäº†</p>
<p>$$<br>\nabla_if(\alpha)=y_jw^{\top}x_j+D_{ii}\alpha_i-1<br>$$</p>
<p>æ‰€ä»¥æœ€ç»ˆè®¡ç®—çš„å°±æ˜¯è¿™ä¸ªwå€¼ã€‚è¦æ›´æ–°çš„å˜é‡å°±å˜æˆäº†wã€‚</p>
<p>æ ¹æ®wçš„å®šä¹‰æˆ‘ä»¬å¯ä»¥å¾—å‡ºwçš„æ›´æ–°å…¬å¼</p>
<p>$$<br>w\leftarrow w+(\alpha_i-\bar{\alpha}_iy_ix_i<br>$$</p>
<p>æ€»ç»“ä¸‹æ¥ï¼Œè¿™ä¸ªåŸºäºdualä¸‹é™æ³•çš„SVMç®—æ³•æµç¨‹å¦‚ä¸‹</p>
<p><img src="http://i1.piimg.com/567571/0c2d742e80577bfe.png" alt="image"></p>
<p>ç®—æ³•é‡Œï¼Œç”¨$PG$ä»£è¡¨$\nabla^P_if(\alpha)$ï¼Œç”¨$G$ä»£è¡¨$\nabla_if(\alpha)$ã€‚</p>
<h1 id="éšæœºåºåˆ—å’ŒShrinking"><a href="#éšæœºåºåˆ—å’ŒShrinking" class="headerlink" title="éšæœºåºåˆ—å’ŒShrinking"></a>éšæœºåºåˆ—å’ŒShrinking</h1><p>åœ¨åæ ‡ä¸‹é™æ³•ä¸­ï¼Œé‡‡ç”¨é¡ºåºæ›´æ–°æ˜¯ä¸å¦‚randomæ›´æ–°é€Ÿåº¦å¿«çš„ã€‚è¯æ˜è¿‡ç¨‹ä¸åˆ—ä¸¾åœ¨æ­¤ã€‚</p>
<p>ç°åœ¨æˆ‘ä»¬è€ƒè™‘å¦‚ä½•ç¼©å°é—®é¢˜ï¼Œåœ¨æˆ‘ä»¬ä¹‹å‰çš„è®¡ç®—ä¸­</p>
<p>$$<br>\nabla^P_if(\alpha)=<br>\begin{cases}<br>\nabla_if(\alpha)\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \text{if}\ 0&lt;\alpha_i&lt;U,\\<br>\min{(0,\nabla_if(\alpha))}\ \ \ \ \text{if}\ \alpha_i=0,\\<br>\max{(0,\nabla_if(\alpha))}\ \ \ \ \text{if}\ \alpha_i=U,<br>\end{cases}<br>$$</p>
<p>å½“$\alpha_i=0$æˆ–è€…$\alpha_i=U$çš„æ—¶å€™ï¼Œæˆ‘ä»¬æœ‰å¾ˆå¤šå‡ ç‡å–åˆ°$\nabla^P_if(\alpha)=0$ã€‚å¦‚æœ$\nabla^P_if(\alpha)=0$ï¼Œç”±å‰é¢çš„æ¨å¯¼å¯çŸ¥ï¼Œè¿™æ—¶å€™$d=0$ï¼Œå–å¾—äº†æœ€ä¼˜ï¼Œ$\alpha_i$ä¸å¿…æ›´æ–°ã€‚æ‰€ä»¥ï¼Œè¿™æ—¶å€™æˆ‘ä»¬å¯ä»¥æŠŠè¿™äº›è¾¾åˆ°è¾¹ç•Œæ¡ä»¶çš„è¿™äº›$\alpha_i$ä¸è€ƒè™‘ï¼Œè¿™æ ·åœ¨è®¡ç®—é€Ÿåº¦ä¸Šï¼Œå°†ä¼šæå‡ã€‚</p>
<p>å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ª$A$æ˜¯${1,2,3,â€¦,l}$çš„å­é›†ï¼Œä»£è¡¨äº†ç§»é™¤äº†ä¸€äº›å…ƒç´ åçš„é›†åˆï¼Œ$\bar{A}$ä»£è¡¨äº†å·²è¢«ç§»é™¤çš„å…ƒç´ indexã€‚</p>
<p>æˆ‘ä»¬æ–°çš„é—®é¢˜å°±å˜æˆäº†</p>
<p>$$<br>\begin{array}{}<br>\displaystyle \min_{\alpha_A}{\frac{1}{2}\alpha^{\top}_A\bar{Q}_{AA}\alpha_A+(\bar{Q}_{A\bar{A}}\alpha_{\bar{A}}-e_A)^\top\alpha_A}\<br>\displaystyle s.t.\ \ 0\le\alpha_i\le U,i\in A<br>\end{array}<br>$$</p>
<p>è¿™é‡Œï¼Œæˆ‘ä»¬ç”¨$\bar{Q}_{AA}$å’Œ$\bar{Q}_{A\bar{A}}$æ¥åˆ†åˆ«è¡¨ç¤ºå…¶indexæ ‡å¿—å±äºå’Œä¸å±äºAçš„$\bar{Q}$é›†åˆï¼Œå› ä¸ºå¦‚æœ$i\in\bar{A}$ï¼Œé‚£ä¹ˆè¡¨ç¤ºè¿™ä¸ª$\alpha$ä¸ç”¨æ›´æ–°ï¼Œæ‰€ä»¥å¯ä»¥è®¤ä¸ºè¿™é‡Œçš„$\alpha_{\bar{A}}$æ˜¯å¸¸å‘é‡ã€‚</p>
<p>åŸé—®é¢˜çš„lé•¿åº¦ç¼©å‡ä¸ºAé•¿åº¦ï¼Œè¿™æ ·å¯¹æ•ˆç‡ç”±å¾ˆå¤§çš„æå‡ã€‚</p>
<p>é‚£æˆ‘ä»¬çš„æ¢¯åº¦å˜ä¸ºäº†</p>
<p>$$<br>\nabla_if(\alpha)=\bar{Q}_{i,A}\alpha_A+\bar{Q}_{i,\bar{A}}\alpha_{\bar{A}}-1<br>$$</p>
<p>æ˜¾ç„¶ï¼Œå¯¹äº$\bar{Q}_{i,\bar{A}}\alpha_{\bar{A}}-1$ä»ç„¶æ˜¯å¸¸é‡ï¼Œè¦è®¡ç®—çš„åªæ˜¯$\bar{Q}_{i,A}\alpha_A$ã€‚</p>
<p>ä¸è¿‡ï¼Œè€ƒè™‘åˆ°å¦‚æœè¦è®¡ç®—$\bar{Q}_{i,\bar{A}}$ï¼Œéœ€è¦é‡æ„æ¢¯åº¦ï¼Œè¿™ä¹Ÿæ˜¯ä¸€ä¸ªéå¸¸è€—æ—¶çš„æ“ä½œã€‚</p>
<p>ä½†æ˜¯æˆ‘ä»¬çº¿æ€§SVMä¸­ï¼Œå¯ä»¥å®šä¹‰</p>
<p>$$<br>w=\sum_{i\in A}{y_i\alpha_ix_i}+\sum_{i\in\bar{A}}{y_i\alpha_ix_i}<br>$$</p>
<p>å¦‚å‰é¢ä¸€æ ·ï¼Œæˆ‘ä»¬çš„wåªéœ€è¦æ›´æ–°å‰åŠéƒ¨åˆ†ï¼Œè¿™æ ·ï¼Œæˆ‘ä»¬çš„$\nabla_if(\alpha)$å°±å¾ˆå¥½å¾—å‡ºäº†ã€‚</p>
<h1 id="Stop-Condition"><a href="#Stop-Condition" class="headerlink" title="Stop Condition"></a>Stop Condition</h1><p>åˆ°è¿™é‡Œï¼Œæˆ‘ä»¬éœ€è¦è€ƒè™‘ä¸€ä¸‹ä»€ä¹ˆæƒ…å†µä¸‹å…ƒç´ ä¼šè¢«shrnkingï¼Ÿ</p>
<p>é¦–å…ˆæˆ‘ä»¬shrinkingæ˜¯å› ä¸ºï¼Œè¿™ä¸ªå…ƒç´ ä¸éœ€è¦æ›´æ–°äº†ï¼Œä¹Ÿå°±æ˜¯æœ‰$\nabla^Pf(\alpha)=0$ã€‚</p>
<p>å¯¹äº$\nabla^Pf(\alpha)$ï¼Œæˆ‘ä»¬å¯ä»¥æŠŠå…¶çœ‹ä¸ºéœ€è¦æ›´æ–°å…ƒç´ çš„ç¨‹åº¦ã€‚å¯ä»¥åˆ†ä¸ºä¸¤ç§æƒ…å†µï¼Œå°±æ˜¯å¤§äºé›¶å’Œå°äºé›¶çš„æƒ…å†µã€‚</p>
<p>$\min_j{\nabla^P_jf(\alpha_{k,j})}$&lt;â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”(0)â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”&gt;$\max_j{\nabla^P_jf(\alpha_{k,j})}$</p>
<p>æˆ‘ä»¬å¾ˆå®¹æ˜“å¾—çŸ¥$\min_j{\nabla^P_jf(\alpha_{k,j})}<0$ï¼Œ$\max\_j{\nabla^p\_jf(\alpha\_{k,j})}>0$ã€‚</0$ï¼Œ$\max\_j{\nabla^p\_jf(\alpha\_{k,j})}></p>
<p>æˆ‘ä»¬ä¸èƒ½ä¿è¯æ¯ä¸€ä¸ªè¾¹ç•Œéƒ½è€ƒè™‘ï¼Œä½†æ˜¯ï¼Œåªè¦æˆ‘ä»¬å½“å‰çš„$\nabla_jf(\alpha_{k,j})$æ¯”$\bar{M}_{k-1}=\max_j{\nabla^P_jf(\alpha_{k-1,j})}$è¿˜å¤§ï¼ˆæ³¨æ„è¾¹ç•Œæ¡ä»¶$\alpha_i^{k,i}=0$ï¼‰ï¼Œé‚£ä¹ˆä»–ä¸€å®šä¸º0ã€‚åŒæ ·çš„ï¼Œåªè¦æˆ‘ä»¬å½“å‰çš„$\nabla_jf(\alpha_{k,j})$æ¯”$\bar{m}_{k-1}=\min_j{\nabla^P_jf(\alpha_{k,j})}$è¿˜å°ï¼ˆè¾¹ç•Œæ¡ä»¶$\alpha_i^{k,i}=U$ï¼‰ï¼Œé‚£ä¹ˆä»–ä¸€å®šä¹Ÿä¸º0ã€‚</p>
<p>è¿™æ ·çš„é—®é¢˜å°±æ˜¯å‰é¢å‡ ä¸ªæ²¡åŠæ³•ä¿è¯æ»¡è¶³è¾¹ç•Œå•Šã€‚é‚£ä¹ˆæˆ‘ä»¬åœ¨è®¡ç®—è¿‡ç¨‹ä¸­ï¼Œå‡å¦‚$\bar{M}_{k-1}&lt;0$äº†ï¼Œæˆ‘ä»¬å°†å…¶è®¾ä¸º$\infty$ã€‚åŒæ ·ï¼Œï¼Œå‡å¦‚$\bar{m}_{k-1}&lt;0$äº†ï¼Œæˆ‘ä»¬å°†å…¶è®¾ä¸º$-\infty$ã€‚è¿™æ ·æˆ‘ä»¬å°±èƒ½ä¿è¯å°†æ‰€æœ‰è¾¹ç•Œæ¡ä»¶æ»¡è¶³çš„å…ƒç´ shrinkingã€‚</p>
<p>åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬$\bar{M}_k$å’Œ$\bar{m}_k$çš„é—´è·ä¸€å®šæ˜¯è¶Šæ¥è¶Šå°ï¼Œå› ä¸º</p>
<p>$$<br>\lim_{k\rightarrow\infty}{\max_j{\nabla^P_jf(\alpha_{k,j})}}=\lim_{k\rightarrow\infty}{\min_j{\nabla^P_jf(\alpha_{k,j})}}=0<br>$$</p>
<p>æ‰€ä»¥æˆ‘ä»¬å¯ä»¥å°†stop conditionè®¾å®šä¸º</p>
<p>$$<br>M^k-m^k&lt;\epsilon<br>$$</p>
<p>å…¶ä¸­$\epsilon$æ˜¯è®¾å®šçš„ä¸€ä¸ªstop conditionã€‚</p>
<p>åŠ å…¥shrinkingä¹‹åçš„ç®—æ³•æµç¨‹å¦‚ä¸‹</p>
<p><img src="http://i1.piimg.com/567571/d48b0b7bb704097b.png" alt="DCDL1"></p>
<h1 id="liblinaer-æºç åˆ†æ"><a href="#liblinaer-æºç åˆ†æ" class="headerlink" title="liblinaer æºç åˆ†æ"></a>liblinaer æºç åˆ†æ</h1><figure class="highlight cpp"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">solve_l2r_l1l2_svc</span><span class="params">(</span></span></div><div class="line">	<span class="keyword">const</span> problem *prob, <span class="keyword">double</span> *w, <span class="keyword">double</span> eps,</div><div class="line">	<span class="keyword">double</span> Cp, <span class="keyword">double</span> Cn, <span class="keyword">int</span> solver_type)</div><div class="line">&#123;</div><div class="line">	<span class="keyword">int</span> l = prob-&gt;l;</div><div class="line">	<span class="keyword">int</span> w_size = prob-&gt;n;</div><div class="line">	<span class="keyword">int</span> i, s, iter = <span class="number">0</span>;</div><div class="line">	<span class="keyword">double</span> C, d, G;</div><div class="line">	<span class="keyword">double</span> *QD = <span class="keyword">new</span> <span class="keyword">double</span>[l];</div><div class="line">	<span class="keyword">int</span> max_iter = <span class="number">1000</span>;</div><div class="line">	<span class="keyword">int</span> *index = <span class="keyword">new</span> <span class="keyword">int</span>[l];</div><div class="line">	<span class="keyword">double</span> *alpha = <span class="keyword">new</span> <span class="keyword">double</span>[l];</div><div class="line">	schar *y = <span class="keyword">new</span> schar[l];</div><div class="line">	<span class="keyword">int</span> active_size = l;</div><div class="line"></div><div class="line">	<span class="comment">// PG: projected gradient, for shrinking and stopping</span></div><div class="line">	<span class="keyword">double</span> PG;<span class="comment">//Projected Gradient</span></div><div class="line">	<span class="keyword">double</span> PGmax_old = INF;</div><div class="line">	<span class="keyword">double</span> PGmin_old = -INF;</div><div class="line">	<span class="keyword">double</span> PGmax_new, PGmin_new;</div><div class="line"></div><div class="line">	<span class="comment">// default solver_type: L2R_L2LOSS_SVC_DUAL</span></div><div class="line">	<span class="keyword">double</span> diag[<span class="number">3</span>] = &#123;<span class="number">0.5</span>/Cn, <span class="number">0</span>, <span class="number">0.5</span>/Cp&#125;;<span class="comment">//D_&#123;ii&#125;</span></div><div class="line">	<span class="keyword">double</span> upper_bound[<span class="number">3</span>] = &#123;INF, <span class="number">0</span>, INF&#125;;</div><div class="line">	<span class="keyword">if</span>(solver_type == L2R_L1LOSS_SVC_DUAL)<span class="comment">//judge if L1-SVM or L2-SVM</span></div><div class="line">	&#123;</div><div class="line">		diag[<span class="number">0</span>] = <span class="number">0</span>;</div><div class="line">		diag[<span class="number">2</span>] = <span class="number">0</span>;</div><div class="line">		upper_bound[<span class="number">0</span>] = Cn;</div><div class="line">		upper_bound[<span class="number">2</span>] = Cp;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="keyword">for</span>(i=<span class="number">0</span>; i&lt;l; i++)<span class="comment">//set all y in &#123;-1,+1&#125;</span></div><div class="line">	&#123;</div><div class="line">		<span class="keyword">if</span>(prob-&gt;y[i] &gt; <span class="number">0</span>)</div><div class="line">		&#123;</div><div class="line">			y[i] = +<span class="number">1</span>;</div><div class="line">		&#125;</div><div class="line">		<span class="keyword">else</span></div><div class="line">		&#123;</div><div class="line">			y[i] = <span class="number">-1</span>;</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="comment">// Initial alpha can be set here. Note that</span></div><div class="line">	<span class="comment">// 0 &lt;= alpha[i] &lt;= upper_bound[GETI(i)]</span></div><div class="line">	<span class="keyword">for</span>(i=<span class="number">0</span>; i&lt;l; i++)</div><div class="line">		alpha[i] = <span class="number">0</span>;</div><div class="line"></div><div class="line">	<span class="keyword">for</span>(i=<span class="number">0</span>; i&lt;w_size; i++)</div><div class="line">		w[i] = <span class="number">0</span>;</div><div class="line">	<span class="keyword">for</span>(i=<span class="number">0</span>; i&lt;l; i++)<span class="comment">//init QD</span></div><div class="line">	&#123;</div><div class="line">		QD[i] = diag[GETI(i)];</div><div class="line"></div><div class="line">		feature_node * <span class="keyword">const</span> xi = prob-&gt;x[i];</div><div class="line">		QD[i] += sparse_operator::nrm2_sq(xi);<span class="comment">//like \sum&#123;xi^2&#125;</span></div><div class="line">		sparse_operator::axpy(y[i]*alpha[i], xi, w);<span class="comment">//calcute w,where w=\sum&#123;yi*\alpha_i*xi&#125;</span></div><div class="line"></div><div class="line">		index[i] = i;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	<span class="keyword">while</span> (iter &lt; max_iter)</div><div class="line">	&#123;</div><div class="line">		PGmax_new = -INF;</div><div class="line">		PGmin_new = INF;</div><div class="line"></div><div class="line">		<span class="keyword">for</span> (i=<span class="number">0</span>; i&lt;active_size; i++)<span class="comment">//with active_size,we create a subset A</span></div><div class="line">		&#123;</div><div class="line">			<span class="keyword">int</span> j = i+rand()%(active_size-i);<span class="comment">//firstly, we set index value randomly</span></div><div class="line">			swap(index[i], index[j]);</div><div class="line">		&#125;</div><div class="line"></div><div class="line">		<span class="keyword">for</span> (s=<span class="number">0</span>; s&lt;active_size; s++)</div><div class="line">		&#123;</div><div class="line">			i = index[s];</div><div class="line">			<span class="keyword">const</span> schar yi = y[i];</div><div class="line">			feature_node * <span class="keyword">const</span> xi = prob-&gt;x[i];</div><div class="line"></div><div class="line">			G = yi*sparse_operator::dot(w, xi)<span class="number">-1</span>;<span class="comment">//gradient of f  </span></div><div class="line"></div><div class="line">			C = upper_bound[GETI(i)];<span class="comment">//the upper boundary of \alpha_i</span></div><div class="line">			G += alpha[i]*diag[GETI(i)];</div><div class="line"></div><div class="line">			PG = <span class="number">0</span>;</div><div class="line">			<span class="keyword">if</span> (alpha[i] == <span class="number">0</span>)</div><div class="line">			&#123;</div><div class="line">				<span class="keyword">if</span> (G &gt; PGmax_old)</div><div class="line">				&#123;</div><div class="line">					active_size--;<span class="comment">//with shrinking, we reduce the size of problem without considering bouded variables</span></div><div class="line">					swap(index[s], index[active_size]);<span class="comment">//remove the bounded variable from subset A</span></div><div class="line">					s--;</div><div class="line">					<span class="keyword">continue</span>;</div><div class="line">				&#125;</div><div class="line">				<span class="keyword">else</span> <span class="keyword">if</span> (G &lt; <span class="number">0</span>)</div><div class="line">					PG = G;</div><div class="line">			&#125;</div><div class="line">			<span class="keyword">else</span> <span class="keyword">if</span> (alpha[i] == C)</div><div class="line">			&#123;</div><div class="line">				<span class="keyword">if</span> (G &lt; PGmin_old)</div><div class="line">				&#123;</div><div class="line">					active_size--;</div><div class="line">					swap(index[s], index[active_size]);</div><div class="line">					s--;</div><div class="line">					<span class="keyword">continue</span>;</div><div class="line">				&#125;</div><div class="line">				<span class="keyword">else</span> <span class="keyword">if</span> (G &gt; <span class="number">0</span>)</div><div class="line">					PG = G;</div><div class="line">			&#125;</div><div class="line">			<span class="keyword">else</span></div><div class="line">				PG = G;</div><div class="line"></div><div class="line">			PGmax_new = max(PGmax_new, PG);</div><div class="line">			PGmin_new = min(PGmin_new, PG);</div><div class="line"></div><div class="line">			<span class="keyword">if</span>(<span class="built_in">fabs</span>(PG) &gt; <span class="number">1.0e-12</span>)</div><div class="line">			&#123;</div><div class="line">				<span class="keyword">double</span> alpha_old = alpha[i];</div><div class="line">				alpha[i] = min(max(alpha[i] - G/QD[i], <span class="number">0.0</span>), C);</div><div class="line">				d = (alpha[i] - alpha_old)*yi;</div><div class="line">				sparse_operator::axpy(d, xi, w);</div><div class="line">			&#125;</div><div class="line">		&#125;</div><div class="line"></div><div class="line">		iter++;</div><div class="line">		<span class="keyword">if</span>(iter % <span class="number">10</span> == <span class="number">0</span>)</div><div class="line">			info(<span class="string">"."</span>);</div><div class="line"></div><div class="line">		<span class="keyword">if</span>(PGmax_new - PGmin_new &lt;= eps)<span class="comment">//stop condition</span></div><div class="line">		&#123;</div><div class="line">			<span class="keyword">if</span>(active_size == l)</div><div class="line">				<span class="keyword">break</span>;</div><div class="line">			<span class="keyword">else</span></div><div class="line">			&#123;</div><div class="line">				active_size = l;</div><div class="line">				info(<span class="string">"*"</span>);</div><div class="line">				PGmax_old = INF;</div><div class="line">				PGmin_old = -INF;</div><div class="line">				<span class="keyword">continue</span>;</div><div class="line">			&#125;</div><div class="line">		&#125;</div><div class="line">		PGmax_old = PGmax_new;</div><div class="line">		PGmin_old = PGmin_new;</div><div class="line">		<span class="keyword">if</span> (PGmax_old &lt;= <span class="number">0</span>)</div><div class="line">			PGmax_old = INF;</div><div class="line">		<span class="keyword">if</span> (PGmin_old &gt;= <span class="number">0</span>)</div><div class="line">			PGmin_old = -INF;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	info(<span class="string">"\noptimization finished, #iter = %d\n"</span>,iter);</div><div class="line">	<span class="keyword">if</span> (iter &gt;= max_iter)</div><div class="line">		info(<span class="string">"\nWARNING: reaching max number of iterations\nUsing -s 2 may be faster (also see FAQ)\n\n"</span>);</div><div class="line"></div><div class="line">	<span class="comment">// calculate objective value</span></div><div class="line"></div><div class="line">	<span class="keyword">double</span> v = <span class="number">0</span>;</div><div class="line">	<span class="keyword">int</span> nSV = <span class="number">0</span>;</div><div class="line">	<span class="keyword">for</span>(i=<span class="number">0</span>; i&lt;w_size; i++)</div><div class="line">		v += w[i]*w[i];</div><div class="line">	<span class="keyword">for</span>(i=<span class="number">0</span>; i&lt;l; i++)</div><div class="line">	&#123;</div><div class="line">		v += alpha[i]*(alpha[i]*diag[GETI(i)] - <span class="number">2</span>);</div><div class="line">		<span class="keyword">if</span>(alpha[i] &gt; <span class="number">0</span>)</div><div class="line">			++nSV;</div><div class="line">	&#125;</div><div class="line">	info(<span class="string">"Objective value = %lf\n"</span>,v/<span class="number">2</span>);</div><div class="line">	info(<span class="string">"nSV = %d\n"</span>,nSV);</div><div class="line"></div><div class="line">	<span class="keyword">delete</span> [] QD;</div><div class="line">	<span class="keyword">delete</span> [] alpha;</div><div class="line">	<span class="keyword">delete</span> [] y;</div><div class="line">	<span class="keyword">delete</span> [] index;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h1 id="è¿è¡Œç»“æœ"><a href="#è¿è¡Œç»“æœ" class="headerlink" title="è¿è¡Œç»“æœ"></a>è¿è¡Œç»“æœ</h1><p>é€šè¿‡æ”¹å˜å‚æ•°Cåˆ†åˆ«ç­‰äº1ï¼Œ5ï¼Œ10ï¼Œè·å¾—å¦‚ä¸‹å®éªŒç»“æœ</p>
<p><img src="http://oegkvp6e0.bkt.clouddn.com/16-10-3/63493088.jpg" alt="image"></p>
<p><img src="http://oegkvp6e0.bkt.clouddn.com/16-10-3/89066272.jpg" alt=""></p>
<p><img src="http://oegkvp6e0.bkt.clouddn.com/16-10-3/85412031.jpg" alt=""></p>
<p>æ”¹å˜stop condition å¾—åˆ°å¦‚ä¸‹ç»“æœ</p>
<p><img src="http://oegkvp6e0.bkt.clouddn.com/16-10-3/36990146.jpg" alt="image"></p>
<p><img src="http://oegkvp6e0.bkt.clouddn.com/16-10-3/81256480.jpg" alt=""></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/09/27/å¿«é€Ÿäº†è§£Logistic-Regression/" itemprop="url">
                  å¿«é€Ÿäº†è§£Logistic Regression
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">å‘è¡¨äº</span>
            <time itemprop="dateCreated" datetime="2016-09-27T15:37:29+08:00" content="2016-09-27">
              2016-09-27
            </time>
          </span>

          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/09/27/å¿«é€Ÿäº†è§£Logistic-Regression/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/09/27/å¿«é€Ÿäº†è§£Logistic-Regression/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>ä¹‹å‰å­¦ä¹ theanoçš„æ—¶å€™ï¼Œå¯¹äºLogistic Regressionåªæœ‰ç²—ç•¥çš„äº†è§£ï¼Œå¯¹äºå…¶ä¸ªä¸­åŸç†è¿˜æ˜¯æ¬ ç¼ºè®¤è¯†ï¼Œä»Šå¤©æ¥è¡¥å…¨ä¸€ä¸‹ï¼Œä¹Ÿæ˜¯å¯¹MLçš„åŸºç¡€å†å¤¯å®ã€‚</p>
<p>è¨€å½’æ­£ä¼ ï¼ŒLogistic Regressionçš„å®šä¹‰</p>
<blockquote>
<p>Logistic regression is the appropriate regression analysis to conduct when the dependent variable is dichotomous (binary). <a href="http://www.statisticssolutions.com/what-is-logistic-regression/" target="_blank" rel="external">from</a></p>
<p>Logistic regression is a statistical method for analyzing a dataset in which there are one or more independent variables that determine an outcome. The outcome is measured with a dichotomous variable (in which there are only two possible outcomes).<a href="https://www.medcalc.org/manual/logistic_regression.php" target="_blank" rel="external">from</a></p>
</blockquote>
<p>ä»¥ä¸Šï¼ŒLogistic Regressionæ˜¯ä¸€ç§å›å½’æ¨¡å‹ï¼Œä½†æ˜¯å®ƒæ¯”è¾ƒç‰¹æ®Šçš„å°±æ˜¯output variableæ˜¯dichotomousçš„ã€‚</p>
<p>å…ˆæ’‡å¼€ä»€ä¹ˆæ˜¯dichotomousï¼Œæˆ‘ä»¬é¦–å…ˆè¦è€ƒè™‘ä»€ä¹ˆæ˜¯å›å½’æ¨¡å‹ï¼Ÿï¼ˆç»Ÿè®¡æ²¡å­¦å¥½ï¼Œæ©é¢ğŸ¤¦ï¼‰</p>
<h1 id="å›å½’æ¨¡å‹"><a href="#å›å½’æ¨¡å‹" class="headerlink" title="å›å½’æ¨¡å‹"></a>å›å½’æ¨¡å‹</h1><p>æˆ‘ä»¬å¹³æ—¶é‡åˆ°çš„å˜é‡ç›¸å…³é—®é¢˜ï¼Œå¤§ä½“å¯ä»¥åˆ†ä¸ºä¸¤ç§</p>
<ul>
<li>å‡½æ•°å…³ç³»</li>
<li>ç›¸å…³å…³ç³»</li>
</ul>
<p>å‡½æ•°å…³ç³»ï¼Œæ˜¯æˆ‘ä»¬ä»å°å­¦åˆ°å¤§çš„ï¼Œå˜é‡åˆ°å˜é‡æ˜¯ç¡®åˆ‡çš„å‡½æ•°å…³ç³»ï¼Œä¸å­˜åœ¨åå·®ï¼Œä¾‹å¦‚$y=2x+1$ï¼Œå°±æ˜¯å…¸å‹çš„å‡½æ•°å…³ç³»ã€‚</p>
<p>ç›¸å…³å…³ç³»ï¼Œå˜é‡ä¸å˜é‡ä¹‹é—´æ²¡æœ‰ç¡®åˆ‡çš„å‡½æ•°å…³ç³»ï¼Œè¿™ä¸ªå…³ç³»æ˜¯ä¸ç¡®å®šçš„ï¼Œä½†æ˜¯ä»–ä»¬æœ‰è‚¯å®šæœ‰ä¸€å®šçš„å…³ç³»ã€‚å…¸å‹çš„å°±æ˜¯è‚¡ç¥¨äº†ï¼Œè‚¡ç¥¨é‚£æ¡çº¿ï¼Œå’Œå¸‚åœºï¼Œå…¬å¸ç»è¥ï¼Œå†³ç­–ç­‰ç­‰æœ‰å¾ˆå¤§å…³ç³»ï¼Œå¯ä½ åˆè¯´ä¸å‡ºè¿™ç§å…³ç³»å…·ä½“æ˜¯ä»€ä¹ˆæ ·å­çš„ï¼ˆç‚’è‚¡è€å¸æœºå‹¿å–·ï¼‰ã€‚è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ç”¨ç»Ÿè®¡çš„æ–¹æ³•ï¼Œæ¥æ¨¡æ‹Ÿå…¶å‡½æ•°å…³ç³»ï¼Œè¿™ä¹Ÿåªèƒ½æ˜¯æ¨¡æ‹Ÿï¼Œæ— æ³•ç¡®åˆ‡ã€‚</p>
<p>æŒ‰ç…§è¾“å…¥å‚æ•°çš„æ•°ç›®ï¼Œå¦‚æœæ˜¯çº¿æ€§æ¨¡å‹ï¼Œå¯ä»¥åˆ†ä¸º</p>
<ol>
<li>ä¸€å…ƒçº¿æ€§å›å½’</li>
<li>å¤šå…ƒçº¿æ€§å›å½’</li>
</ol>
<p>ä¸€å…ƒçº¿æ€§å›å½’</p>
<p>$$<br>y=\beta_0+\beta_1x<br>$$</p>
<p>è¿™å°±ç§°ä¸ºä¸€å…ƒçº¿æ€§å›å½’æ–¹ç¨‹ï¼Œå…¶ç‰¹æ€§å°±ä¸è®¨è®ºäº†ï¼Œå¯ä»¥çœ‹å‡ºå¼å­é€¼è¿‘çš„æ˜¯ä¸€ä¸ªä¸€å…ƒçº¿æ€§æ–¹ç¨‹ã€‚</p>
<p>åŒç†ï¼Œå¤šå…ƒçº¿æ€§æ–¹ç¨‹</p>
<p>$$<br>y=\beta_0+\beta_1x_1+\beta_2x_2+â€¦+\beta_kx_k+\epsilon<br>$$</p>
<p>å½“ç„¶ï¼Œæƒ…å†µå¤šèµ·æ¥ä»¥åï¼ˆç»Ÿè®¡æ–¹æ³•ï¼Œæ€»ä¸èƒ½åªæœ‰ä¸€ç»„æ•°æ®å§ï¼‰ï¼Œè¾“å‡ºçš„yå¯ä»¥ç»„æˆä¸€ä¸ªå‘é‡<strong>Y</strong>ï¼Œè¾“å…¥å¯ä»¥å˜ä¸ºä¸€ä¸ªçŸ©é˜µ<strong>X</strong>ï¼Œå‚æ•°å¯ä»¥å˜ä¸ºä¸€ä¸ªå‘é‡$\beta$ã€‚</p>
<p>$$<br>Y=<br>\begin{pmatrix}<br>y_1\\<br>y_2\\<br>\vdots\\<br>y_n<br>\end{pmatrix},<br>X=<br>\begin{pmatrix}<br>1&amp;x_{11}&amp;x_{21}&amp;\cdots&amp;x_{k1}\\<br>1&amp;x_{12}&amp;x_{22}&amp;\cdots&amp;x_{k2}\\<br>1&amp;x_{13}&amp;x_{23}&amp;\cdots&amp;x_{k3}\\<br>\vdots&amp;\vdots&amp;\vdots&amp;\vdots&amp;\vdots\\<br>1&amp;x_{1n}&amp;x_{2n}&amp;\cdots&amp;x_{kn}<br>\end{pmatrix},<br>\beta=<br>\begin{pmatrix}<br>\beta_1\\<br>\beta_2\\<br>\vdots\\<br>\beta_n<br>\end{pmatrix},<br>\epsilon=<br>\begin{pmatrix}<br>\epsilon_1\\<br>\epsilon_2\\<br>\vdots\\<br>\epsilon_n<br>\end{pmatrix}<br>$$</p>
<p>ç»„åˆèµ·æ¥å°±æ˜¯</p>
<p>$$<br>Y=\beta{X}+\epsilon<br>$$<br>å¤šå…ƒçº¿æ€§å›å½’å°±æ­¤å®Œæˆï¼ˆåŸºæœ¬äº†è§£ï¼‰ã€‚</p>
<p>é™¤äº†çº¿æ€§å›å½’ï¼Œå›å½’æ¨¡å‹è¿˜å¯ä»¥æœ‰å„ç§éçº¿æ€§å›å½’ï¼Œè¿™é‡Œæš‚æ—¶ä¸è€ƒè™‘ã€‚</p>
<h1 id="äºŒå€¼é€»è¾‘æ¨¡å‹"><a href="#äºŒå€¼é€»è¾‘æ¨¡å‹" class="headerlink" title="äºŒå€¼é€»è¾‘æ¨¡å‹"></a>äºŒå€¼é€»è¾‘æ¨¡å‹</h1><p>å†å›å¤´çœ‹ä¸‹æˆ‘ä»¬çš„Logistic Regressionã€‚å’Œå›å½’æ¨¡å‹ä¸åŒçš„æ˜¯ï¼Œå®ƒçš„yæ˜¯dichotomousçš„ã€‚</p>
<p>ä»€ä¹ˆæ˜¯dichotomouså‘¢ï¼Ÿè‹±è¯­ç¿»è¯‘æ˜¯ã€å‰çŠ¶åˆ†æçš„ï¼›åˆ†æˆä¸¤ä¸ªçš„ã€‘ï¼Œå°±æ˜¯äºŒå€¼çš„ï¼ˆbinaryï¼‰ã€‚</p>
<p>å®é™…ä¸Šï¼Œæˆ‘ä»¬çš„yåªèƒ½å–0æˆ–è€…1ï¼Œä¹Ÿå°±æ˜¯æ— è®ºæ€ä¹ˆæ ·çš„æ¨¡æ‹Ÿï¼Œæˆ‘ä»¬çš„é¢„æµ‹å€¼éƒ½ä¼šæ˜¯0-1ä¹‹é—´çš„ã€‚è¿™å°±ç›¸å½“äºæœ€ç®€å•çš„åˆ†ä¸¤ç±»é—®é¢˜ï¼Œæ¯”å¦‚é¢„æµ‹å¼ ä¸‰æ˜¯å¦å‡ºè½¨äº†ï¼Œ1è¡¨ç¤ºå‡ºè½¨ï¼Œ0è¡¨ç¤ºæ²¡å‡ºè½¨ã€‚æˆ‘ä»¬é¢„æµ‹å€¼ä¸€å®šæ˜¯åœ¨0-1ä¹‹é—´å¾˜å¾Šçš„ã€‚</p>
<p>ç”±ä¸Šé¢æˆ‘ä»¬çŸ¥é“å¤šå…ƒçº¿æ€§å›å½’æ¨¡å‹æ˜¯</p>
<p>$$<br>y=\beta_0+\beta_1x_1+\beta_2x_2+â€¦+\beta_kx_k+\epsilon<br>$$</p>
<p>çš„ä¸€ç§å½¢å¼ã€‚ç°åœ¨æˆ‘ä»¬æŠŠè¾“å‡ºé™æ­»äº†æ˜¯0æˆ–è€…1ã€‚è¿™æ ·å°±å¯ä»¥å¼€å§‹è®­ç»ƒå¹¶é¢„æµ‹äº†ã€‚</p>
<p>ä»€ä¹ˆæ¦‚å¿µå‘¢ï¼Ÿæ„æ€å°±æ˜¯æˆ‘ä»¬ç»™å®šä¸€å †äººï¼Œç»™å®šè®¸å¤šå‚æ•°ï¼Œç„¶åå‘Šè¯‰ä½ å¼ ä¸‰å‡ºè½¨äº†ï¼Œæå››æ²¡å‡ºè½¨ï¼Œç‹äº”å‡ºè½¨äº†ç­‰ç­‰ç­‰ã€‚ç„¶åç»™ä½ ä¸€ä¸ªåˆ˜å°äºŒï¼Œç»™ä½ ä¸€äº›å‚æ•°ï¼Œä½ æ¥é¢„æµ‹ä»–å‡ºæ²¡å‡ºè½¨ã€‚ç„¶åä½ é¢„æµ‹å‡ºæ¥ï¼Œå“¦ï¼åˆ˜å°äºŒå‡ºè½¨çš„å€¼æ˜¯0.8ï¼Œé‚£ä¹ˆä»–æœ‰å¾ˆå¤§å‡ ç‡å‡ºè½¨ã€‚å°±æ˜¯è¿™ä¹ˆä¸ªé“ç†ã€‚</p>
<p>æˆ‘ä»¬å‡è®¾$E(Y)$è¡¨ç¤ºå…¶é¢„æµ‹å€¼ï¼Œç”¨$P(Y=i)$è¡¨ç¤ºYä¸º0æˆ–1çš„æ¦‚ç‡ã€‚å¯¹äºYåªèƒ½å–å€¼0å’Œ1çš„äºŒå€¼æ¨¡å‹ï¼Œæˆ‘ä»¬å‘ç°</p>
<p>$$<br>E(Y)=0(P(Y=0))+1(P(Y=1))=0(1-P(Y=1))+1(P(Y=1))=P(Y=1)<br>$$</p>
<p>æ‰€ä»¥é¢„æµ‹å€¼$E(Y)$å°±æ˜¯$Y=1$çš„æ¦‚ç‡$P(Y=1)$ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥è¯´</p>
<p>$$<br>P(Y=1)=\beta_0+\beta_1x_1+\beta_2x_2+â€¦+\beta_kx_k+\epsilon<br>$$</p>
<p><strong>é—®é¢˜1</strong>ï¼šé€šè¿‡ä¸Šå¼ï¼Œæˆ‘ä»¬å¹¶ä¸èƒ½ä¿è¯$P(Y=1)$çš„å€¼åœ¨0-1ä¹‹é—´ï¼Œè€Œå®é™…æƒ…å†µä¸­ï¼Œæˆ‘ä»¬ä¸éœ€è¦è¶…è¿‡1å’Œå°äº0çš„æƒ…å†µã€‚</p>
<p>æ‰€ä»¥æˆ‘ä»¬å®šä¹‰é¢„æµ‹è¾“å‡ºä¸æ˜¯$E(Y)$äº†ï¼Œè€Œæ˜¯$E(Y)=logit(E(Y))=\ln{\frac{E(Y)}{1-E(Y)}}$ï¼Œæ‰€ä»¥</p>
<p>$$<br>E(Y)=\frac{e^{\beta_0+\beta_1x_1+\beta_2x_2+â€¦+\beta_kx_k}}{1+e^{\beta_0+\beta_1x_1+\beta_2x_2+â€¦+\beta_kx_k}}=\frac{1}{1+e^{\beta_0+\beta_1x_1+\beta_2x_2+â€¦+\beta_kx_k}}<br>$$</p>
<p>æœ‰çš„åŒå­¦è¿™é‡Œä¸èƒ½ç†è§£ï¼Œä¸ºä»€ä¹ˆ$E(Y)$ç­‰å·åé¢çš„ä¸œè¥¿å®Œå…¨å˜äº†å‘¢ï¼Ÿ</p>
<p><strong>å…¶å®ï¼Œæˆ‘ä»¬ä¸€å¼€å§‹å‡è®¾é¢„æµ‹çš„å‡½æ•°æ˜¯å¤šå…ƒçº¿æ€§å›å½’æ¨¡å‹ï¼Œå¯æˆ‘ä»¬ç”¨è¿™ä¸ªæ¨¡å‹æ¥é¢„æµ‹å´æ— æ³•è¾¾åˆ°æ•ˆæœï¼Œäº§ç”Ÿäº†é—®é¢˜1</strong>ã€‚<strong>ä¸ºäº†è§£å†³é—®é¢˜1ï¼Œæˆ‘ä»¬åŠ¿å¿…ä¸èƒ½å†ç”¨çº¿æ€§å›å½’æ¨¡å‹ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯¹æ•´ä¸ªæ¨¡å‹è¿›è¡Œäº†æ”¹å˜ï¼Œæ‰€ä»¥é¢„æµ‹å€¼ä¹Ÿè¦è¿›è¡Œæ”¹å˜</strong>ã€‚å¾ˆæ˜¾ç„¶ï¼Œæ”¹å˜åçš„æ¨¡å‹å¾ˆå¥½çš„è§£å†³äº†é—®é¢˜1ã€‚</p>
<p>åˆ°è¿™é‡Œï¼Œæˆ‘ä»¬å»ºç«‹çš„æ¨¡å‹å°±å«åšlogisticæ¨¡å‹ã€‚</p>
<h1 id="ä¼°ç®—ç³»æ•°"><a href="#ä¼°ç®—ç³»æ•°" class="headerlink" title="ä¼°ç®—ç³»æ•°"></a>ä¼°ç®—ç³»æ•°</h1><p>å»ºç«‹äº†æ¨¡å‹ä¹‹åï¼Œæƒ³è¦æˆ‘ä»¬èƒ½å¤Ÿé¢„æµ‹ï¼Œæˆ‘ä»¬å½“ç„¶éœ€è¦çŸ¥é“çš„å°±æ˜¯å„ä¸ªç³»æ•°$\beta_0,\beta_1,\cdots,\beta_k$çš„å¤§å°ï¼Œä¸ç„¶æ€ä¹ˆé¢„æµ‹ã€‚</p>
<p>æˆ‘ä»¬æ€ä¹ˆé€šè¿‡æ¨¡å‹æ¥ä¼°ç®—è¿™æ ·çš„ç³»æ•°å‘¢ï¼Ÿ</p>
<p>æˆ‘ä»¬å¯ä»¥é€šè¿‡æœ€å¤§ä¼¼ç„¶ä¼°è®¡ï¼ˆæœ€å°äºŒä¹˜æ³•ä¸é€‚ç”¨ï¼‰æ¥ä¼°è®¡å‚æ•°ã€‚</p>
<p>è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨å¯¹æ•°ä¼¼ç„¶å‡½æ•°ï¼Œå‡è®¾ä¼¼ç„¶å‡½æ•°æ˜¯Lï¼Œå¦‚ä¸‹</p>
<p>$$<br>L=\prod_{i=1}^n{p(x_i)^{y_i}[1-p(x_i)]^{1-y_i}}<br>$$</p>
<p>å¯¹æ•°ä¼¼ç„¶å‡½æ•°æ˜¯</p>
<p>$$<br>\ln{L}=\sum_{i=1}^n{y_i\ln{E(Y)}+(1-y_i)\ln{(1-E(Y))}}<br>$$</p>
<p>æˆ‘ä»¬çš„ç›®çš„æ˜¯è®­ç»ƒ$\theta=[\beta_0,\beta_1,\cdots,\beta_k]$ä½¿å¾—$\ln{L}$æœ€å¤§ã€‚</p>
<p>åœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬æœ‰æŸå¤±å‡½æ•°çš„è¯´æ³•ï¼Œæ„å³è®­ç»ƒå‚æ•°ä½¿å¾—æŸå¤±å‡½æ•°æœ€å°ï¼Œå¯ä»¥å¥—ç”¨åœ¨è¿™ï¼Œå› ä¸ºæŸå¤±å‡½æ•°æ˜¯æœ€å°ï¼Œæ‰€ä»¥æˆ‘ä»¬åœ¨$\ln{L}$å‰é¢åŠ ä¸Šè´Ÿå·ã€‚</p>
<p>$$<br>J(\theta)=-\frac{1}{n}\sum_{i=1}^n{y_i\ln{E(Y)}+(1-y_i)\ln{(1-E(Y))}}<br>$$</p>
<p>é™¤ä»¥næ˜¯æ–¹ä¾¿åé¢è®¡ç®—ï¼Œç°åœ¨å¯ä»¥æš‚æ—¶ä¸è€ƒè™‘ã€‚</p>
<h1 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h1><p>åˆ°è¿™é‡Œï¼Œç›¸ä¿¡ä½ å¯¹LRæ¨¡å‹å·²ç»åˆæ­¥äº†è§£ï¼Œä¹Ÿå¯ä»¥åŠ¨æ‰‹å†™ç¨‹åºäº†ã€‚</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/09/18/ã€pythonæœºå™¨å­¦ä¹ ã€‘ä»Autoencoderåˆ°dAå†åˆ°SdA/" itemprop="url">
                  ã€pythonæœºå™¨å­¦ä¹ ã€‘ä»Autoencoderåˆ°dAå†åˆ°SdA
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">å‘è¡¨äº</span>
            <time itemprop="dateCreated" datetime="2016-09-18T21:56:38+08:00" content="2016-09-18">
              2016-09-18
            </time>
          </span>

          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/09/18/ã€pythonæœºå™¨å­¦ä¹ ã€‘ä»Autoencoderåˆ°dAå†åˆ°SdA/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/09/18/ã€pythonæœºå™¨å­¦ä¹ ã€‘ä»Autoencoderåˆ°dAå†åˆ°SdA/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>åœ¨å­¦ä¹ ä»€ä¹ˆæ˜¯Denoising Autoencodersä¹‹å‰ï¼Œé¦–å…ˆè¦äº†è§£ä»€ä¹ˆæ˜¯Autoencoderã€‚</p>
<h1 id="Autoencoder"><a href="#Autoencoder" class="headerlink" title="Autoencoder"></a>Autoencoder</h1><p>AEæ˜¯ä¸€ç§æ— ç›‘ç£çš„å­¦ä¹ ç®—æ³•ï¼Œä»–åˆ©ç”¨åå‘ä¼ æ’­ç®—æ³•ï¼Œè®©ç›®æ ‡å€¼ç­‰äºè¾“å…¥å€¼ã€‚</p>
<p><img src="http://deeplearning.stanford.edu/wiki/images/thumb/f/f9/Autoencoder636.png/400px-Autoencoder636.png" alt="image"></p>
<p>AEæœ¬èº«çš„ç›®çš„æ˜¯è®­ç»ƒä¸€ä¸ª$h_{w,b}(x)\approx{x}$çš„å‡½æ•°ã€‚ä¸ºäº†è®©è¾“å…¥æ›´å¥½çš„æ‹¥æœ‰ä¸€äº›ã€‚</p>
<p>å‡è®¾æˆ‘ä»¬æœ‰è¾“å…¥$x\in[0,1]^d$ï¼Œå°†å…¶æ˜ å°„åˆ°éšå±‚ä¸Š</p>
<p>$$<br>y=s(Wx+b)<br>$$</p>
<p>sæ˜¯éçº¿æ€§å‡½æ•°ï¼Œä¾‹å¦‚sigmoidå‡½æ•°ã€‚æ¥ç€å†å¯¹yé‡æ„ä½¿å…¶é€¼è¿‘x</p>
<p>$$<br>z=s(Wâ€™x+bâ€™)<br>$$</p>
<p>è¿™é‡Œçš„zä¸èƒ½å’Œxç”»ä¸Šç­‰å·ï¼Œåªèƒ½è¯´zæ˜¯xçš„é¢„æµ‹ã€‚è€Œé‡æ„çš„æƒé‡çŸ©é˜µ$Wâ€™$å¯ä»¥ç”±å‰é¢æ˜ å°„çš„æƒé‡çŸ©é˜µé™åˆ¶ï¼Œæœ‰$Wâ€™=W^{\top}$ï¼Œè¿™è¢«å«åštied weightsã€‚è¿™æ ·åœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­åªéœ€è¦ç¡®å®šä¸‰ä¸ªå‚æ•°Wï¼Œbï¼Œbâ€™ã€‚</p>
<p>é‡æ„æ˜¯é¢„æµ‹çš„è¿‡ç¨‹ï¼Œæ—¢ç„¶æ˜¯é¢„æµ‹ï¼Œé‚£å°±æœ‰è¯¯å·®ã€‚æˆ‘ä»¬ç”¨å‡æ–¹è¯¯å·®å°±èƒ½è®¡ç®—</p>
<p>$$<br>L(xz)=||x-z||^2<br>$$</p>
<p>å¦‚æœè¾“å…¥å¯ä»¥çœ‹ä½œæ˜¯ä½å‘é‡æˆ–è€…æ¦‚ç‡å‘é‡ï¼Œäº¤å‰ç†µä¹Ÿå¯ä»¥ç”¨æ¥è¡¡é‡ï¼š</p>
<p>$$<br>L_H(x,z)=-\sum^d_{k=1}[x_k\log{z_k}+(1-x_k)\log{(1-z_k)}]<br>$$</p>
<p>æˆ‘ä»¬å¸Œæœ›ç¼–ç yæ˜¯åˆ†å¸ƒå¼çš„ï¼Œå¯ä»¥æ•æ‰åˆ°è¾“å…¥æ•°æ®å˜åŒ–çš„ä¸»å…ƒçš„åæ ‡ï¼Œæœ‰ä¸€ç‚¹ç±»ä¼¼äºPCAã€‚</p>
<p>ä¸‹é¢æ¥çœ‹ä¸€ä¸‹ä»£ç æ„æˆ</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(</span></span></div><div class="line">       self,</div><div class="line">       numpy_rng,</div><div class="line">       theano_rng=None,</div><div class="line">       input=None,</div><div class="line">       n_visible=<span class="number">784</span>,</div><div class="line">       n_hidden=<span class="number">500</span>,</div><div class="line">       W=None,</div><div class="line">       bhid=None,</div><div class="line">       bvis=None</div><div class="line">   ):</div><div class="line">      </div><div class="line">       self.n_visible = n_visible</div><div class="line">       self.n_hidden = n_hidden</div><div class="line"></div><div class="line">       <span class="keyword">if</span> <span class="keyword">not</span> theano_rng:</div><div class="line">           theano_rng = RandomStreams(numpy_rng.randint(<span class="number">2</span> ** <span class="number">30</span>))</div><div class="line"></div><div class="line">       <span class="keyword">if</span> <span class="keyword">not</span> W:</div><div class="line">           initial_W = numpy.asarray(</div><div class="line">               numpy_rng.uniform(</div><div class="line">                   low=<span class="number">-4</span> * numpy.sqrt(<span class="number">6.</span> / (n_hidden + n_visible)),</div><div class="line">                   high=<span class="number">4</span> * numpy.sqrt(<span class="number">6.</span> / (n_hidden + n_visible)),</div><div class="line">                   size=(n_visible, n_hidden)</div><div class="line">               ),</div><div class="line">               dtype=theano.config.floatX</div><div class="line">           )</div><div class="line">           W = theano.shared(value=initial_W, name=<span class="string">'W'</span>, borrow=<span class="keyword">True</span>)</div><div class="line"></div><div class="line">       <span class="keyword">if</span> <span class="keyword">not</span> bvis:</div><div class="line">           bvis = theano.shared(</div><div class="line">               value=numpy.zeros(</div><div class="line">                   n_visible,</div><div class="line">                   dtype=theano.config.floatX</div><div class="line">               ),</div><div class="line">               borrow=<span class="keyword">True</span></div><div class="line">           )</div><div class="line"></div><div class="line">       <span class="keyword">if</span> <span class="keyword">not</span> bhid:</div><div class="line">           bhid = theano.shared(</div><div class="line">               value=numpy.zeros(</div><div class="line">                   n_hidden,</div><div class="line">                   dtype=theano.config.floatX</div><div class="line">               ),</div><div class="line">               name=<span class="string">'b'</span>,</div><div class="line">               borrow=<span class="keyword">True</span></div><div class="line">           )</div><div class="line"></div><div class="line">       self.W = W</div><div class="line">       self.b = bhid</div><div class="line">       self.b_prime = bvis</div><div class="line">       self.W_prime = self.W.T</div><div class="line">       self.theano_rng = theano_rng</div><div class="line">       <span class="keyword">if</span> input <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">           self.x = T.dmatrix(name=<span class="string">'input'</span>)</div><div class="line">       <span class="keyword">else</span>:</div><div class="line">           self.x = input</div><div class="line"></div><div class="line">       self.params = [self.W, self.b, self.b_prime]</div></pre></td></tr></table></figure>
<p>è¿™æ˜¯AEçš„åˆå§‹åŒ–å‡½æ•°ï¼ˆä¹Ÿæ˜¯ä¹‹åçš„dAåˆå§‹åŒ–å‡½æ•°ï¼‰ï¼ŒåŒ…å«å‡ ä¸ªå‚æ•°</p>
<ul>
<li>numpy_rngï¼šnumpyéšæœºæ•°ç”Ÿæˆå™¨æ¥æ„å»ºæƒé‡</li>
<li>theano_rngï¼štheanoéšæœºæ•°ç”Ÿæˆå™¨</li>
<li>input</li>
<li>n_visibleï¼šè¾“å…¥å±‚å•å…ƒæ•°</li>
<li>n_hiddenï¼šéšå±‚å•å…ƒæ•°</li>
<li>Wï¼š</li>
<li>bhidï¼šéšå±‚çš„blaså˜é‡</li>
<li>bvisï¼šæ˜¾å±‚çš„blaså˜é‡</li>
</ul>
<p>å†çœ‹ä¸‹AEçš„æµç¨‹</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">graph LR</div><div class="line">A[input]--&gt;B[hidden value]</div><div class="line">B--&gt;C[reconstract value]</div></pre></td></tr></table></figure>
<p>å› æ­¤ï¼Œæˆ‘ä»¬é¦–å…ˆéœ€è¦å¯¹inputåš$y=s(Wx+b)$æ“ä½œ</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_hidden_values</span><span class="params">(self, input)</span>:</span></div><div class="line">    <span class="keyword">return</span> T.nnet.sigmoid(T.dot(input, self.W) + self.b)</div></pre></td></tr></table></figure>
<p>æ¥ç€å¯¹éšå±‚è¾“å‡ºyå†è¿›è¡Œ$z=s(Wâ€™x+bâ€™)$æ“ä½œ</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_reconstructed_input</span><span class="params">(self, hidden)</span>:</span></div><div class="line">    <span class="keyword">return</span> T.nnet.sigmoid(T.dot(hidden, self.W_prime) + self.b_prime)</div></pre></td></tr></table></figure>
<p>è¿™é‡Œï¼Œå› ä¸ºç ”ç©¶è¡¨é¢$Wâ€™=W^{\top}$å¯ä»¥å‡å°‘è¿ç®—ï¼Œå®é™…ä¸Š$Wâ€™$æœ¬èº«ä¹Ÿæ— å¤ªå¤§æ„ä¹‰ï¼Œæ‰€ä»¥è¿™é‡Œçš„<code>W_prime</code>å°±æ˜¯æˆ‘ä»¬ä¹‹å‰å®šä¹‰çš„<code>self.W_prime = self.W.T</code></p>
<p>æˆ‘ä»¬æœ€ç»ˆçš„ç›®çš„è¿˜æ˜¯é€šè¿‡æœ€å°åŒ–$L_H(x,z)=-\sum^d_{k=1}[x_k\log{z_k}+(1-x_k)\log{(1-z_k)}]$æ¥è®¡ç®—ä¸‰ä¸ªå‚æ•°$W,b,bâ€™$çš„å€¼ã€‚åé¢çš„æµç¨‹å’Œä¹‹å‰çš„MLPsï¼ŒLRç­‰ç±»ä¼¼ã€‚</p>
<h1 id="Denoising-Autoencoders-dA"><a href="#Denoising-Autoencoders-dA" class="headerlink" title="Denoising Autoencoders (dA)"></a>Denoising Autoencoders (dA)</h1><p>Denoising Autoencoderså®é™…ä¸Šå°±æ˜¯AEçš„åŠ å¼ºç‰ˆã€‚æˆ‘ä»¬çŸ¥é“ç”Ÿç‰©è§†è§‰æ˜¯å¯ä»¥é‡ç°ï¼Œæˆ–è€…æ˜¯è‡ªåŠ¨è¡¥å…¨æ®‹æŸçš„éƒ¨åˆ†ï¼Œè€Œè¡¥å…¨çš„æ˜¯é€šè¿‡å¤§è„‘è®¡ç®—è·å¾—çš„æœ€ä¼˜ã€‚å¯èƒ½æ¯”æ— æ®‹æŸæœ¬èº«çš„è¿˜è¦ä¼˜åŒ–ã€‚è¿™é‡Œå°±æ˜¯ç”¨äº†è¿™æ ·ä¸€ä¸ªé“ç†ï¼ŒdAåœ¨AEçš„åŸºç¡€ä¸ŠåŠ å…¥äº†å™ªå£°ï¼Œç„¶åå†è¿›è¡ŒAEæ“ä½œã€‚</p>
<p>æ•™æä¸Šè¿™æ ·è§£é‡Š</p>
<blockquote>
<p>Hence the denoising auto-encoder is trying to predict the corrupted (i.e. missing) values from the uncorrupted (i.e., non-missing) values, for randomly selected subsets of missing patterns. </p>
</blockquote>
<p>æ„å³dAé€šè¿‡é¢„æµ‹æ¥è¡¥å…¨å™ªå£°åŒºåŸŸï¼Œå®é™…ä¸Šè¡¥å…¨çš„è¿‡ç¨‹åŠ å…¥äº†ä¸€äº›å…¶ä»–ç‰¹æ€§ï¼Œå½“ç„¶æ˜¯å¯¹æˆ‘æœ‰åˆ©çš„ï¼Œæ‰€ä»¥ç”¨è¿™ç§æ–¹æ³•é‡æ„çš„ç»“æœä½œä¸ºè¾“å‡ºï¼Œæ•ˆæœæ¯”åŸå›¾æœ¬èº«è¿˜è¦å¥½ã€‚</p>
<p>ä¸€ä¸ªé™å™ªè‡ªåŠ¨ç¼–ç å™¨å°±æ˜¯å»é€šè¿‡æŠŠä¸€äº›åŠ å™ªå£°çš„è¾“å…¥æ˜ å°„åˆ°éšå±‚ç©ºé—´ï¼Œç„¶åå†æ˜ å°„å›è¾“å…¥ç©ºé—´æ¥é‡æ„çœŸå®çš„è¾“å…¥ã€‚</p>
<ol>
<li>é¦–å…ˆæŠŠçœŸå®è¾“å…¥åŠ å™ªå£°</li>
<li>æŠŠåŠ å™ªå£°çš„è¾“å…¥æ˜ å°„åˆ°éšå±‚ç©ºé—´</li>
<li>é‡æ„çœŸå®è¾“å…¥</li>
<li>è®¡ç®—é‡æ„è¯¯å·®</li>
</ol>
<p>ä»£ç ä¸Šåªè¦æ¨¡æ‹Ÿå…¬å¼</p>
<p>$$<br>\tilde{x} \backsim q_D(\tilde{x}|x)<br>$$</p>
<p>å°†å…¶æ”¾åˆ°AEinputä¹‹å‰å°±å¥½äº†ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_corrupted_input</span><span class="params">(self, input, corruption_level)</span>:</span></div><div class="line">    <span class="keyword">return</span> self.theano_rng.binomial(size=input.shape, n=<span class="number">1</span>,</div><div class="line">                                    p=<span class="number">1</span> - corruption_level,</div><div class="line">                                    dtype=theano.config.floatX) * input</div></pre></td></tr></table></figure>
<blockquote>
<p>This function keeps <code>1-corruption_level</code> entries of the inputs the same and zero-out randomly selected subset of size <code>coruption_level</code></p>
</blockquote>
<p>è¿™ä¸ªå‡½æ•°çš„åŠŸèƒ½å°±æ˜¯å¯¹è¾“å…¥åŠ å™ªå£°ã€‚ä¹‹åå°†ä»¥è¿™ä¸ªåŠ å™ªçš„è¾“å…¥ä½œä¸ºè¾“å…¥è¿›è¡Œéšå±‚æ“ä½œã€‚</p>
<p>å°†ä¸åŠ å™ªé‡æ„ï¼ˆAEï¼‰å’ŒåŠ å™ªé‡æ„ï¼ˆdAï¼‰çš„è¾“å…¥å¯¹æ¯”</p>
<p><img src="http://deeplearning.net/tutorial/_images/filters_corruption_0.png" alt="image">   <img src="http://deeplearning.net/tutorial/_images/filters_corruption_30.png" alt="image"></p>
<p>å·¦è¾¹æ˜¯ä¸åŠ å™ªï¼Œå³è¾¹æ˜¯åŠ 30%å™ªå£°</p>
<h1 id="Stacked-Denoising-Autoencoders-SdA"><a href="#Stacked-Denoising-Autoencoders-SdA" class="headerlink" title="Stacked Denoising Autoencoders (SdA)"></a>Stacked Denoising Autoencoders (SdA)</h1><p>å°†dAçš„æ“ä½œè¿›è¡Œå †å ï¼Œæ„å³è¿›è¡Œå¤šæ¬¡ï¼Œæ¯ä¸€ä¸ªdAçš„è¾“å…¥éƒ½æ˜¯ä¸Šä¸€ä¸ªdAçš„è¾“å‡ºã€‚æŠŠå•å±‚å¯»æ‰¾æœ€ä¼˜è¾“å‡ºçš„è¿‡ç¨‹å«åšpre-trainã€‚</p>
<p>å½“æ‰€æœ‰å †å çš„dAéƒ½pre-trainå®Œæ¯•ä¹‹åï¼Œæ¥ä¸‹æ¥éœ€è¦è¿›è¡Œfine-tuneã€‚è¿™ä¸ªè¿‡ç¨‹æ˜¯ä¸€ä¸ªç›‘ç£å­¦ä¹ è¿‡ç¨‹ï¼Œé¦–å…ˆåœ¨ä¹‹å‰çš„outputä¹‹ååŠ å…¥ä¸€ä¸ªLRå±‚ï¼Œæ¥ç€å°†æ•´ä¸ªç½‘ç»œä½œä¸ºMLPè®­ç»ƒ</p>
<p><img src="http://img2.ph.126.net/RaHhD40I-9IWhhS987W7BQ==/6631470186957042581.png" alt="image"></p>
<p>ä»£ç åœ¨åŸæœ‰çš„dAåŸºç¡€ä¸ŠåŠ å…¥forå¾ªç¯</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(self.n_layers):</div><div class="line">    <span class="keyword">if</span> i == <span class="number">0</span>:</div><div class="line">        input_size = n_ins</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        input_size = hidden_layers_sizes[i - <span class="number">1</span>]</div><div class="line"></div><div class="line">    <span class="keyword">if</span> i == <span class="number">0</span>:</div><div class="line">        layer_input = self.x</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        layer_input = self.sigmoid_layers[<span class="number">-1</span>].output</div><div class="line"></div><div class="line">    sigmoid_layer = HiddenLayer(rng=numpy_rng,</div><div class="line">                                input=layer_input,</div><div class="line">                                n_in=input_size,</div><div class="line">                                n_out=hidden_layers_sizes[i],</div><div class="line">                                activation=T.nnet.sigmoid)</div><div class="line">                                </div><div class="line">    self.sigmoid_layers.append(sigmoid_layer)</div><div class="line">    </div><div class="line">    self.params.extend(sigmoid_layer.params)</div><div class="line"></div><div class="line">    dA_layer = dA(numpy_rng=numpy_rng,</div><div class="line">                  theano_rng=theano_rng,</div><div class="line">                  input=layer_input,</div><div class="line">                  n_visible=input_size,</div><div class="line">                  n_hidden=hidden_layers_sizes[i],</div><div class="line">                  W=sigmoid_layer.W,</div><div class="line">                  bhid=sigmoid_layer.b)</div><div class="line">    self.dA_layers.append(dA_layer)</div></pre></td></tr></table></figure>
<p>æˆ‘ä»¬ç”¨<code>self.sigmoid_layers</code>å°†æ¯ä¸€ä¸ªéšå±‚å­˜å‚¨èµ·æ¥ï¼Œè€Œç”¨<code>self.dA_layers</code>å°†dAå­˜å‚¨èµ·æ¥ï¼Œæ³¨æ„åˆ°ä»–ä»¬çš„è¾“å…¥éƒ½æ˜¯<code>layer_input</code>ï¼Œæ‰€ä»¥ä»–ä»¬æ˜¯å¹¶è¡Œå…³ç³»ã€‚</p>
<p>æ¥ä¸‹æ¥åœ¨æœ€ååŠ å…¥LRæ¨¡å—</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">self.logLayer = LogisticRegression(</div><div class="line">        input=self.sigmoid_layers[<span class="number">-1</span>].output,</div><div class="line">        n_in=hidden_layers_sizes[<span class="number">-1</span>],</div><div class="line">        n_out=n_outs</div><div class="line">    )</div><div class="line"></div><div class="line">self.params.extend(self.logLayer.params)</div><div class="line">self.finetune_cost = self.logLayer.negative_log_likelihood(self.y)</div><div class="line">self.errors = self.logLayer.errors(self.y)</div></pre></td></tr></table></figure>
<p>æ³¨æ„å…¶è¾“å…¥æ˜¯<code>elf.sigmoid_layers[-1].output</code>æ˜¯éšå±‚æœ€åä¸€ä¸ªçš„è¾“å‡ºï¼Œæ‰€ä»¥æœ€åçš„è¾“å‡ºå°±æ˜¯LRä¹‹åçš„paramsï¼Œfinetune_costï¼Œerrorsï¼Œè¿™äº›å…¨éƒ¨æ˜¯LRé‡Œé¢çš„ç®—æ³•ã€‚</p>
<p>æ¥ç€å°±æ˜¯æˆ‘ä»¬è¯´çš„pre-trainæ¨¡å—ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">pretraining_functions</span><span class="params">(self, train_set_x, batch_size)</span>:</span></div><div class="line">   index = T.lscalar(<span class="string">'index'</span>)  <span class="comment"># index to a minibatch</span></div><div class="line">   corruption_level = T.scalar(<span class="string">'corruption'</span>)  <span class="comment"># % of corruption to use</span></div><div class="line">   learning_rate = T.scalar(<span class="string">'lr'</span>)  <span class="comment"># learning rate to use</span></div><div class="line">   <span class="comment"># begining of a batch, given `index`</span></div><div class="line">   batch_begin = index * batch_size</div><div class="line">   <span class="comment"># ending of a batch given `index`</span></div><div class="line">   batch_end = batch_begin + batch_size</div><div class="line"></div><div class="line">   pretrain_fns = []</div><div class="line">   <span class="keyword">for</span> dA <span class="keyword">in</span> self.dA_layers:</div><div class="line">       <span class="comment"># get the cost and the updates list</span></div><div class="line">       cost, updates = dA.get_cost_updates(corruption_level,</div><div class="line">                                           learning_rate)</div><div class="line">       <span class="comment"># compile the theano function</span></div><div class="line">       fn = theano.function(</div><div class="line">           inputs=[</div><div class="line">               index,</div><div class="line">               theano.In(corruption_level, value=<span class="number">0.2</span>),</div><div class="line">               theano.In(learning_rate, value=<span class="number">0.1</span>)</div><div class="line">           ],</div><div class="line">           outputs=cost,</div><div class="line">           updates=updates,</div><div class="line">           givens=&#123;</div><div class="line">               self.x: train_set_x[batch_begin: batch_end]</div><div class="line">           &#125;</div><div class="line">       )</div><div class="line">       <span class="comment"># append `fn` to the list of functions</span></div><div class="line">       pretrain_fns.append(fn)</div><div class="line"></div><div class="line">   <span class="keyword">return</span> pretrain_fns</div></pre></td></tr></table></figure>
<p>æˆ‘ä»¬å°†æ¯ä¸€ä¸ªdAå±‚ï¼ˆ3å±‚ï¼‰å®šä¹‰ä¸ºä¸€ä¸ªtheano.functionï¼Œä¼˜åŒ–è®¡ç®—åï¼Œå°†å…¶ç»„åˆæˆä¸€ä¸ªåˆ—è¡¨ã€‚</p>
<p>åœ¨pre-trainä¹‹åå°±æ˜¯fit tuneè¿‡ç¨‹ã€‚fit tuneç®€è¨€ä¹‹å°±æ˜¯å°†ä¹‹å‰çš„æ‰€æœ‰å±‚åˆèµ·æ¥ä½œä¸ºä¸€ä¸ªMLPæ¥è®­ç»ƒã€‚</p>
<p>ç”¨trainæ¥è®­ç»ƒå‚æ•°ï¼Œç”¨validateæ¥è®¡ç®—äºvalidation setä¸­çš„é”™è¯¯ç‡ï¼Œç”¨testæ¥è®¡ç®—äºtest set ä¸­æ‰“çš„é”™è¯¯ç‡ã€‚</p>
<p>æœ€ç»ˆï¼Œè¾“å…¥inputè¿›è¡Œæµ‹è¯•ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_SdA</span><span class="params">(finetune_lr=<span class="number">0.1</span>, pretraining_epochs=<span class="number">15</span>,</span></span></div><div class="line">             pretrain_lr=<span class="number">0.001</span>, training_epochs=<span class="number">1000</span>,</div><div class="line">             dataset=<span class="string">'mnist.pkl.gz'</span>, batch_size=<span class="number">1</span>):</div><div class="line">             </div><div class="line">    datasets = load_data(dataset)</div><div class="line"></div><div class="line">    train_set_x, train_set_y = datasets[<span class="number">0</span>]</div><div class="line">    valid_set_x, valid_set_y = datasets[<span class="number">1</span>]</div><div class="line">    test_set_x, test_set_y = datasets[<span class="number">2</span>]</div><div class="line"></div><div class="line">    <span class="comment"># compute number of minibatches for training, validation and testing</span></div><div class="line">    n_train_batches = train_set_x.get_value(borrow=<span class="keyword">True</span>).shape[<span class="number">0</span>]</div><div class="line">    n_train_batches //= batch_size</div><div class="line"></div><div class="line">    <span class="comment"># numpy random generator</span></div><div class="line">    <span class="comment"># start-snippet-3</span></div><div class="line">    numpy_rng = numpy.random.RandomState(<span class="number">89677</span>)</div><div class="line">    print(<span class="string">'... building the model'</span>)</div><div class="line">    <span class="comment"># construct the stacked denoising autoencoder class</span></div><div class="line">    sda = SdA(</div><div class="line">        numpy_rng=numpy_rng,</div><div class="line">        n_ins=<span class="number">28</span> * <span class="number">28</span>,</div><div class="line">        hidden_layers_sizes=[<span class="number">1000</span>, <span class="number">1000</span>, <span class="number">1000</span>],</div><div class="line">        n_outs=<span class="number">10</span></div><div class="line">    )</div><div class="line">    </div><div class="line">    <span class="comment"># end-snippet-3 start-snippet-4</span></div><div class="line">    <span class="comment">#########################</span></div><div class="line">    <span class="comment"># PRETRAINING THE MODEL #</span></div><div class="line">    <span class="comment">#########################</span></div><div class="line">    print(<span class="string">'... getting the pretraining functions'</span>)</div><div class="line">    pretraining_fns = sda.pretraining_functions(train_set_x=train_set_x,</div><div class="line">                                                batch_size=batch_size)</div><div class="line"></div><div class="line">    print(<span class="string">'... pre-training the model'</span>)</div><div class="line">    start_time = timeit.default_timer()</div><div class="line">    <span class="comment">## Pre-train layer-wise</span></div><div class="line">    corruption_levels = [<span class="number">.1</span>, <span class="number">.2</span>, <span class="number">.3</span>]</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(sda.n_layers):</div><div class="line">        <span class="comment"># go through pretraining epochs</span></div><div class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> range(pretraining_epochs):</div><div class="line">            <span class="comment"># go through the training set</span></div><div class="line">            c = []</div><div class="line">            <span class="keyword">for</span> batch_index <span class="keyword">in</span> range(n_train_batches):</div><div class="line">                c.append(pretraining_fns[i](index=batch_index,</div><div class="line">                         corruption=corruption_levels[i],</div><div class="line">                         lr=pretrain_lr))</div><div class="line">            print(<span class="string">'Pre-training layer %i, epoch %d, cost %f'</span> % (i, epoch, numpy.mean(c)))</div><div class="line"></div><div class="line">    end_time = timeit.default_timer()</div><div class="line"></div><div class="line">    print((<span class="string">'The pretraining code for file '</span> +</div><div class="line">           os.path.split(__file__)[<span class="number">1</span>] +</div><div class="line">           <span class="string">' ran for %.2fm'</span> % ((end_time - start_time) / <span class="number">60.</span>)), file=sys.stderr)</div><div class="line">    <span class="comment"># end-snippet-4</span></div><div class="line">    </div><div class="line">    <span class="comment">########################</span></div><div class="line">    <span class="comment"># FINETUNING THE MODEL #</span></div><div class="line">    <span class="comment">########################</span></div><div class="line"></div><div class="line">    <span class="comment"># get the training, validation and testing function for the model</span></div><div class="line">    print(<span class="string">'... getting the finetuning functions'</span>)</div><div class="line">    train_fn, validate_model, test_model = sda.build_finetune_functions(</div><div class="line">        datasets=datasets,</div><div class="line">        batch_size=batch_size,</div><div class="line">        learning_rate=finetune_lr</div><div class="line">    )</div><div class="line"></div><div class="line">    print(<span class="string">'... finetunning the model'</span>)</div><div class="line">    <span class="comment"># early-stopping parameters</span></div><div class="line">    patience = <span class="number">10</span> * n_train_batches  <span class="comment"># look as this many examples regardless</span></div><div class="line">    patience_increase = <span class="number">2.</span>  <span class="comment"># wait this much longer when a new best is</span></div><div class="line">                            <span class="comment"># found</span></div><div class="line">    improvement_threshold = <span class="number">0.995</span>  <span class="comment"># a relative improvement of this much is</span></div><div class="line">                                   <span class="comment"># considered significant</span></div><div class="line">    validation_frequency = min(n_train_batches, patience // <span class="number">2</span>)</div><div class="line">                                  <span class="comment"># go through this many</span></div><div class="line">                                  <span class="comment"># minibatche before checking the network</span></div><div class="line">                                  <span class="comment"># on the validation set; in this case we</span></div><div class="line">                                  <span class="comment"># check every epoch</span></div><div class="line"></div><div class="line">    best_validation_loss = numpy.inf</div><div class="line">    test_score = <span class="number">0.</span></div><div class="line">    start_time = timeit.default_timer()</div><div class="line"></div><div class="line">    done_looping = <span class="keyword">False</span></div><div class="line">    epoch = <span class="number">0</span></div><div class="line"></div><div class="line">    <span class="keyword">while</span> (epoch &lt; training_epochs) <span class="keyword">and</span> (<span class="keyword">not</span> done_looping):</div><div class="line">        epoch = epoch + <span class="number">1</span></div><div class="line">        <span class="keyword">for</span> minibatch_index <span class="keyword">in</span> range(n_train_batches):</div><div class="line">            minibatch_avg_cost = train_fn(minibatch_index)</div><div class="line">            iter = (epoch - <span class="number">1</span>) * n_train_batches + minibatch_index</div><div class="line"></div><div class="line">            <span class="keyword">if</span> (iter + <span class="number">1</span>) % validation_frequency == <span class="number">0</span>:</div><div class="line">                validation_losses = validate_model()</div><div class="line">                this_validation_loss = numpy.mean(validation_losses)</div><div class="line">                print(<span class="string">'epoch %i, minibatch %i/%i, validation error %f %%'</span> %</div><div class="line">                      (epoch, minibatch_index + <span class="number">1</span>, n_train_batches,</div><div class="line">                       this_validation_loss * <span class="number">100.</span>))</div><div class="line"></div><div class="line">                <span class="comment"># if we got the best validation score until now</span></div><div class="line">                <span class="keyword">if</span> this_validation_loss &lt; best_validation_loss:</div><div class="line"></div><div class="line">                    <span class="comment">#improve patience if loss improvement is good enough</span></div><div class="line">                    <span class="keyword">if</span> (</div><div class="line">                        this_validation_loss &lt; best_validation_loss *</div><div class="line">                        improvement_threshold</div><div class="line">                    ):</div><div class="line">                        patience = max(patience, iter * patience_increase)</div><div class="line"></div><div class="line">                    <span class="comment"># save best validation score and iteration number</span></div><div class="line">                    best_validation_loss = this_validation_loss</div><div class="line">                    best_iter = iter</div><div class="line"></div><div class="line">                    <span class="comment"># test it on the test set</span></div><div class="line">                    test_losses = test_model()</div><div class="line">                    test_score = numpy.mean(test_losses)</div><div class="line">                    print((<span class="string">'     epoch %i, minibatch %i/%i, test error of '</span></div><div class="line">                           <span class="string">'best model %f %%'</span>) %</div><div class="line">                          (epoch, minibatch_index + <span class="number">1</span>, n_train_batches,</div><div class="line">                           test_score * <span class="number">100.</span>))</div><div class="line"></div><div class="line">            <span class="keyword">if</span> patience &lt;= iter:</div><div class="line">                done_looping = <span class="keyword">True</span></div><div class="line">                <span class="keyword">break</span></div><div class="line"></div><div class="line">    end_time = timeit.default_timer()</div><div class="line">    print(</div><div class="line">        (</div><div class="line">            <span class="string">'Optimization complete with best validation score of %f %%, '</span></div><div class="line">            <span class="string">'on iteration %i, '</span></div><div class="line">            <span class="string">'with test performance %f %%'</span></div><div class="line">        )</div><div class="line">        % (best_validation_loss * <span class="number">100.</span>, best_iter + <span class="number">1</span>, test_score * <span class="number">100.</span>)</div><div class="line">    )</div><div class="line">    print((<span class="string">'The training code for file '</span> +</div><div class="line">           os.path.split(__file__)[<span class="number">1</span>] +</div><div class="line">           <span class="string">' ran for %.2fm'</span> % ((end_time - start_time) / <span class="number">60.</span>)), file=sys.stderr)</div></pre></td></tr></table></figure>
<h1 id="æ€è€ƒ"><a href="#æ€è€ƒ" class="headerlink" title="æ€è€ƒ"></a>æ€è€ƒ</h1><p>SdAçš„æ ¸å¿ƒå°±åœ¨äº</p>
<ul>
<li>pre train</li>
<li>fit tune</li>
</ul>
<p>pre trainæ˜¯å¯¹æ¯ä¸ªdAå±‚åˆ†åˆ«trainè·å¾—æœ€ä¼˜çš„å‚æ•°ï¼Œfit tuneæ˜¯å°†æ‰€æœ‰çš„dAç»„åˆåŠ ä¸Šä¸€ä¸ªLRæ¨¡å‹ï¼Œå°†å…¶çœ‹ä½œæ˜¯ä¸€ä¸ªMLPsæ¨¡å‹è¿›è¡Œè®­ç»ƒã€‚</p>
<p>ä¸¤ä¸ªçš„è¾“å‡ºéƒ½æ˜¯ä¸€ä¸ªinputï¼Œè¾“å‡ºå´æ˜¯ä¸åŒçš„ã€‚äºŒè€…çš„å…³ç³»ä½•åœ¨å‘¢ï¼Ÿ</p>
<p>ä»ä»£ç ä¸Šçœ‹ï¼Œä¸¤ä¸ªå®Œå…¨æ˜¯å¹¶è¡Œï¼Œäº’ä¸ç›¸å¹²çš„ã€‚</p>
<p>å¯¹äºè¿™ä¸€ç‚¹ï¼Œæ•™æä¸Šæ˜¯è¿™æ ·è§£é‡Šçš„</p>
<blockquote>
<p>We can see the stacked denoising autoencoder as having two facades: a list of autoencoders, and an MLP. During pre-training we use the first facade, i.e., we treat our model as a list of autoencoders, and train each autoencoder seperately. In the second stage of training, we use the second facade. These two facades are linked because:1.the autoencoders and the sigmoid layers of the MLP share parameters,2.the latent representations computed by intermediate layers of the MLP are fed as input to the autoencoders.</p>
</blockquote>
<p>æ„å³è¿™ä¸¤ä¸ªä¸œè¥¿çœ‹ä¼¼åˆ†å‰²ï¼Œå®åˆ™ä¸ç„¶ï¼Œæœ‰ä¸¤ä¸ªåŸå› </p>
<ul>
<li>MLPçš„AEä»¬å’Œsigmoidè®¡ç®—å±‚å…±äº«å‚æ•°</li>
<li>é€šè¿‡MLPçš„ä¸­é—´å±‚æ¥è®¡ç®—çš„éšå¼è¡¨è¾¾æ˜¯ä½œä¸ºAEçš„è¾“å…¥çš„</li>
</ul>
<p>wtfï¼Ÿ</p>
<p>å†æ¥åˆ†æä¸‹ä»£ç ï¼Œå‘ç°æ— è®ºæ˜¯pretrainè¿˜æ˜¯fittuneéƒ½æ˜¯ç”±ä¸€ä¸ª</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">sda = SdA(</div><div class="line">    numpy_rng=numpy_rng,</div><div class="line">    n_ins=<span class="number">28</span> * <span class="number">28</span>,</div><div class="line">    hidden_layers_sizes=[<span class="number">1000</span>, <span class="number">1000</span>, <span class="number">1000</span>],</div><div class="line">    n_outs=<span class="number">10</span></div><div class="line">)</div></pre></td></tr></table></figure>
<p>æ¥è¿›è¡Œæ“ä½œã€‚</p>
<p>ç¬¬äºŒï¼Œå…¶å®é€šè¿‡ç¬¬ä¸€æ­¥çš„pretrainï¼Œsdaçš„å‚æ•°å·²ç„¶æ”¹å˜ï¼Œå› ä¸ºè¿‡ç¨‹æ˜¯æ— ç›‘ç£çš„ï¼Œæ‰€ä»¥è®¡ç®—å‡ºæ¥åçš„å‚æ•°ä¹Ÿä¼šæ”¹å˜ã€‚</p>
<p>è¿™æ ·ï¼ŒSdAæ‰ç®—çœŸæ­£ç†è§£ã€‚</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/09/17/ã€pythonæœºå™¨å­¦ä¹ ã€‘Convolutional-Neural-Networkså·ç§¯ç¥ç»ç½‘ç»œå’ŒLeNet/" itemprop="url">
                  ã€pythonæœºå™¨å­¦ä¹ ã€‘Convolutional Neural Networkså·ç§¯ç¥ç»ç½‘ç»œå’ŒLeNet
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">å‘è¡¨äº</span>
            <time itemprop="dateCreated" datetime="2016-09-17T09:32:20+08:00" content="2016-09-17">
              2016-09-17
            </time>
          </span>

          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/09/17/ã€pythonæœºå™¨å­¦ä¹ ã€‘Convolutional-Neural-Networkså·ç§¯ç¥ç»ç½‘ç»œå’ŒLeNet/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/09/17/ã€pythonæœºå™¨å­¦ä¹ ã€‘Convolutional-Neural-Networkså·ç§¯ç¥ç»ç½‘ç»œå’ŒLeNet/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>è¯´åˆ°CNNï¼Œè¿˜æ˜¯è¦æä¸€ä¸‹BPç®—æ³•ã€‚</p>
<p>BPç®—æ³•åœ¨æœ¬æ¥çš„MLPsçš„åŸºç¡€ä¸Šï¼Œåå‘å±•å¼€æŸå¤±å‡½æ•°ï¼Œç„¶åå¯¹åŒ…å«äº†æ‰€æœ‰å‚æ•°çš„æŸå¤±å‡½æ•°$J(\theta)$æ±‚åå¯¼ï¼Œæ¥ä½¿å¾—$J(\theta)$å°½å¯èƒ½å°ã€‚é€šè¿‡æå°åŒ–è¯¯å·®åå‘ä¼ æ’­è°ƒæ•´æƒå€¼çŸ©é˜µï¼Œä¸æ–­å¾ªç¯ç›´åˆ°æœ€ä½³ã€‚</p>
<p>é—®é¢˜æ˜¯ï¼Œå½“æ‰€ç»™è¾“å…¥è¶³å¤Ÿå¤§çš„æ—¶å€™ï¼Œæ±‚å–é‚£ä¹ˆå¤šå‚æ•°å¯¹è®¡ç®—æœºæ˜¯å¾ˆå¤§è´Ÿæ‹…ï¼Œä¹Ÿä¸æ˜¯å¾ˆç°å®ï¼Œæ¯”å¦‚è¾“å…¥å¦‚æœæ˜¯ä¸€å¼ 128Ã—128çš„å›¾ç‰‡è¿›è¡Œè®­ç»ƒï¼Œé‚£ä¹ˆè®­ç»ƒåå‡ ä¸ªå°æ—¶ä¹Ÿä¸æ˜¯ä¸å¯èƒ½ã€‚</p>
<p>åœ¨å…­ä¸ƒåå¹´ä»£ï¼Œæœºå™¨å­¦ä¹ çš„ä½è°·æ—¶æœŸï¼ŒHubelå’ŒWieselç­‰äººåœ¨ç ”ç©¶çŒ«è„‘çš®å±‚ä¸­ç”¨äºå±€éƒ¨æ•æ„Ÿå’Œæ–¹å‘é€‰æ‹©çš„ç¥ç»å…ƒæ—¶ï¼Œå‘ç°å…¶ç‹¬ç‰¹çš„ç½‘ç»œç»“æ„å¯ä»¥æœ‰æ•ˆåœ°é™ä½åé¦ˆç¥ç»ç½‘ç»œçš„å¤æ‚æ€§ï¼Œç»§è€Œæå‡ºäº†å·ç§¯ç¥ç»ç½‘ç»œï¼ˆConvolutional Neural Networks-ç®€ç§°CNNï¼‰ã€‚</p>
<p>åœ¨é‚£ä¹‹åï¼ŒCNNå´æ²¡æœ‰è·å¾—è¶³å¤Ÿçš„é‡è§†ï¼Œç›´åˆ°1980å¹´K.Fukushimaå¹´æå‡ºçš„æ–°è¯†åˆ«æœº(<em>neocognitron</em>)æ˜¯å·ç§¯ç¥ç»ç½‘ç»œçš„ç¬¬ä¸€ä¸ªå®ç°ç½‘ç»œã€‚éšåï¼ŒCNNä¸æ–­å‘å±•ï¼Œåˆ°ç›®å‰ä¸ºæ­¢ï¼ŒCNNå·²ç»æˆä¸ºä¼—å¤šç§‘å­¦é¢†åŸŸçš„ç ”ç©¶çƒ­ç‚¹ä¹‹ä¸€ï¼Œç‰¹åˆ«æ˜¯åœ¨æ¨¡å¼åˆ†ç±»é¢†åŸŸï¼Œç”±äºè¯¥ç½‘ç»œé¿å…äº†å¯¹å›¾åƒçš„å¤æ‚å‰æœŸé¢„å¤„ç†ï¼Œå¯ä»¥ç›´æ¥è¾“å…¥åŸå§‹å›¾åƒï¼Œå› è€Œå¾—åˆ°äº†æ›´ä¸ºå¹¿æ³›çš„åº”ç”¨ã€‚</p>
<p>ä¸€èˆ¬åœ°ï¼ŒCNNçš„åŸºæœ¬ç»“æ„åŒ…æ‹¬ä¸¤å±‚</p>
<ul>
<li>å…¶ä¸€ä¸ºç‰¹å¾æå–å±‚ï¼Œæ¯ä¸ªç¥ç»å…ƒçš„è¾“å…¥ä¸å‰ä¸€å±‚çš„å±€éƒ¨æ¥å—åŸŸç›¸è¿ï¼Œå¹¶æå–è¯¥å±€éƒ¨çš„ç‰¹å¾ã€‚ä¸€æ—¦è¯¥å±€éƒ¨ç‰¹å¾è¢«æå–åï¼Œå®ƒä¸å…¶å®ƒç‰¹å¾é—´çš„ä½ç½®å…³ç³»ä¹Ÿéšä¹‹ç¡®å®šä¸‹æ¥</li>
<li>å…¶äºŒæ˜¯ç‰¹å¾æ˜ å°„å±‚ï¼Œç½‘ç»œçš„æ¯ä¸ªè®¡ç®—å±‚ç”±å¤šä¸ªç‰¹å¾æ˜ å°„ç»„æˆï¼Œæ¯ä¸ªç‰¹å¾æ˜ å°„æ˜¯ä¸€ä¸ªå¹³é¢ï¼Œå¹³é¢ä¸Šæ‰€æœ‰ç¥ç»å…ƒçš„æƒå€¼ç›¸ç­‰ã€‚</li>
</ul>
<p>ç‰¹å¾æ˜ å°„ç»“æ„é‡‡ç”¨å½±å“å‡½æ•°æ ¸å°çš„sigmoidå‡½æ•°ä½œä¸ºå·ç§¯ç½‘ç»œçš„æ¿€æ´»å‡½æ•°ï¼Œä½¿å¾—ç‰¹å¾æ˜ å°„å…·æœ‰ä½ç§»ä¸å˜æ€§ã€‚æ­¤å¤–ï¼Œç”±äºä¸€ä¸ªæ˜ å°„é¢ä¸Šçš„ç¥ç»å…ƒå…±äº«æƒå€¼ï¼Œå› è€Œå‡å°‘äº†ç½‘ç»œè‡ªç”±å‚æ•°çš„ä¸ªæ•°ã€‚å·ç§¯ç¥ç»ç½‘ç»œä¸­çš„æ¯ä¸€ä¸ªå·ç§¯å±‚éƒ½ç´§è·Ÿç€ä¸€ä¸ªç”¨æ¥æ±‚å±€éƒ¨å¹³å‡ä¸äºŒæ¬¡æå–çš„è®¡ç®—å±‚ï¼Œè¿™ç§ç‰¹æœ‰çš„ä¸¤æ¬¡ç‰¹å¾æå–ç»“æ„å‡å°äº†ç‰¹å¾åˆ†è¾¨ç‡ã€‚</p>
<h1 id="ç¥ç»ç½‘ç»œ"><a href="#ç¥ç»ç½‘ç»œ" class="headerlink" title="ç¥ç»ç½‘ç»œ"></a>ç¥ç»ç½‘ç»œ</h1><p>æˆ‘ä»¬ä¹‹å‰å·²ç»å­¦ä¹ äº†LRæ¨¡å‹ï¼ŒMLPæ¨¡å‹ï¼Œå®é™…ä¸Šåœ¨ä¸€å®šæ„ä¹‰ä¸Šå·²ç»æ„æˆäº†ç¥ç»ç½‘ç»œã€‚</p>
<p>ç¥ç»ç½‘ç»œæ¯ä¸ªç¥ç»å…ƒç»“æ„éƒ½æ˜¯ä¸€ä¸ªLR</p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/115.png" alt="image"></p>
<p>ç„¶åï¼Œåœ¨input layerå’Œoutput layerä¸­é—´æ’å…¥hidden layerå°±å˜æˆäº†MLPsæ¨¡å‹ï¼Œhidden layerè¶Šå¤šï¼Œè®­ç»ƒè¶Šç²¾ç¡®ã€‚</p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/34.png" alt="image"></p>
<p>åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä½¿ç”¨BPç®—æ³•åå‘æ±‚å–å„ä¸ªå‚æ•°ã€‚</p>
<h1 id="å·ç§¯ç¥ç»ç½‘ç»œCNN"><a href="#å·ç§¯ç¥ç»ç½‘ç»œCNN" class="headerlink" title="å·ç§¯ç¥ç»ç½‘ç»œCNN"></a>å·ç§¯ç¥ç»ç½‘ç»œCNN</h1><h2 id="ç¨€ç–è¿é€š"><a href="#ç¨€ç–è¿é€š" class="headerlink" title="ç¨€ç–è¿é€š"></a>ç¨€ç–è¿é€š</h2><p>é¦–å…ˆå†çœ‹ä¸€ä¸‹ä¹‹å‰çš„MLPsæ¨¡å‹ï¼Œä»input layeråˆ°hidden layerï¼Œæ¯ä¸€ä¸ªè¾“å…¥éƒ½å’Œéšå±‚çš„æ¯ä¸€ä¸ªç¥ç»å…ƒç›¸è¿æ¥ï¼Œè¿™ä¸ªä»£ä»·æ˜¯å‚æ•°å¤ªå¤šã€‚</p>
<p>CNNæŠŠå…¨è¿é€šå˜æˆäº†ç¨€ç–è¿é€šï¼Œå¯ä»¥çœ‹ä¸‹å›¾çš„ç»“æ„ã€‚</p>
<p><img src="http://deeplearning.net/tutorial/_images/sparse_1D_nn.png" alt="image"></p>
<p>çœ‹è¿™ä¸ªå›¾ï¼Œå›¾ä¸­ï¼Œä»ä¸‹å¾€ä¸Šæ˜¯ä¿¡æ¯ä¼ é€’çš„è¿‡ç¨‹ã€‚</p>
<p>ä»ä½å±‚å‘é«˜å±‚çš„è¿æ¥ï¼Œæœ€å¤šæ˜¯3è¿é€šã€‚å‡å¦‚m-1å±‚æ˜¯è¾“å…¥ï¼Œm+1å±‚æ˜¯è¾“å‡ºã€‚é‚£ä¹ˆéšå±‚æ¯ä¸ªç¥ç»å…ƒåªèƒ½æ”¶åˆ°3ä¸ªinputçš„ä¿¡æ¯ï¼Œä½†æ˜¯æœ€ç»ˆçš„outputå´ä»ç„¶å¯ä»¥æ”¶åˆ°å…¨éƒ¨çš„5ä¸ªè¾“å…¥ä¿¡æ¯ã€‚</p>
<p>æ‰€ä»¥ï¼Œåœ¨å…¶ä¸­é—´å±‚çš„æ¯ä¸€ä¸ªå•å…ƒï¼Œåªèƒ½ååº”å…¶è¿é€šçš„åŒºåŸŸå˜åŒ–ï¼Œåªè¦ç®¡å¥½è‡ªå·±çš„ä¸€äº©ä¸‰åˆ†åœ°å°±å¥½äº†ã€‚</p>
<p>è¿™ä¹Ÿå«å±€éƒ¨æ„ŸçŸ¥ã€‚å®ƒçš„é“ç†å°±æ˜¯ï¼Œæˆ‘ä»¬çœ‹ä¸œè¥¿éƒ½æ˜¯ä»å±€éƒ¨åˆ°æ•´ä½“çš„ï¼Œä½ ä¸€ä¸‹å­çœ‹ä¸€æ•´ä¸ªå›¾æ˜¾ç„¶æ¯”è¾ƒåƒåŠ›ï¼Œä½†æ˜¯æˆ‘ä»¬ä¸€éƒ¨åˆ†ä¸€éƒ¨åˆ†çœ‹ï¼Œå°±å®¹æ˜“å¤šäº†ã€‚è€Œåªè€ƒè™‘éƒ¨åˆ†ä¹Ÿä½¿å¾—å¯¹å±€éƒ¨çš„æŒæ¡æ›´åŠ å‡†ç¡®ã€‚</p>
<p>å±€éƒ¨æ„ŸçŸ¥æœ€å¤§çš„å¥½å¤„å°±æ˜¯å‡å°‘äº†å‚æ•°ï¼Œåƒæ˜¯æˆ‘ä»¬ä¹‹å‰çš„å›¾ä¸­ï¼Œå‡å¦‚æ¯ä¸€æ¡éƒ½æ˜¯ä¸€ä¸ªå‚æ•°çš„è¯ï¼Œä»input layeråˆ°hidden layeréœ€è¦9ä¸ªå‚æ•°ï¼Œè€Œå¦‚æœæ˜¯å…¨è¿é€šçš„æ–¹å¼çš„è¯ï¼Œéœ€è¦3Ã—5=15ä¸ªå‚æ•°ã€‚</p>
<p>è€Œç½‘ç»œä¸Šæœ‰ä¸€ä¸ªæ›´æ˜æ˜¾çš„è¯´æ˜å›¾</p>
<p><img src="http://www.36dsj.com/wp-content/uploads/2015/03/511-600x224.jpg" alt="image"></p>
<p>å‡è®¾æœ‰ä¸€å¼ 1000*1000çš„å›¾åƒä½œä¸ºinput layerï¼Œå‡è®¾æœ‰1000000ä¸ªéšå±‚ç¥ç»å…ƒã€‚å·¦è¾¹æ˜¯å…¨è¿é€šçš„æ–¹å¼ï¼Œéœ€è¦å¤šå°‘å‚æ•°å‘¢ï¼Ÿç­”æ¡ˆå¾ˆç®€å•ï¼š$1000\times1000\times1000000=10^{12}$ä¸ªå‚æ•°ã€‚è€Œå‡å¦‚æŠŠè¿™1000000ä¸ªç¥ç»å…ƒå¹³é“ºå¼€æ¥ï¼Œæ¯äººç®¡ä¸€å—$10\times10$åŒºåŸŸï¼Œé‚£ä¹ˆåªéœ€è¦$100\times1000000=10^{8}$ä¸ªå‚æ•°ã€‚è¿™ä¸ªé“ç†å°±åƒæ˜¯æˆ‘æœ‰è®¸å¤šäººæ‰ï¼Œå…¨æ”¾åœ¨ä¸­å¤®æ²¡é‚£ä¹ˆå¤šå²—ä½ï¼Œè®©æ¯ä¸ªäººéƒ½ç®¡å…¨å›½ï¼Œä¸¥é‡èµ„æºæµªè´¹ï¼Œæ•ˆç‡è¿˜ä¸é«˜ã€‚ä¸å¦‚æŠŠè¿™äº›äººéƒ½æ´¾åˆ°å„ä¸ªå¿å¸‚ï¼Œåšä¸ªåœ°æ–¹å®˜ï¼Œç„¶åå„è‡ªæ²»ç†ï¼Œç„¶åæŠŠç»“æœæ±‡æŠ¥ä¸­å¤®å°±å¥½äº†ï¼Œçœäº†ä¸å°‘äº‹æƒ…ã€‚</p>
<h2 id="å…±äº«æƒå€¼"><a href="#å…±äº«æƒå€¼" class="headerlink" title="å…±äº«æƒå€¼"></a>å…±äº«æƒå€¼</h2><p>æŠŠéšå±‚ç¥ç»å…ƒåˆ†é…ä¸‹å»ä¹‹åï¼Œè¿˜è§‰å¾—å‚æ•°å¤ªå¤šï¼Œæ€ä¹ˆåŠï¼Ÿ</p>
<p>æœ‰ä¸€ä¸ªåŠæ³•ï¼Œé‚£å°±è®©æ¯ä¸ªç¥ç»å…ƒè¿æ¥çš„å‚æ•°éƒ½ç›¸åŒã€‚é‚£ä¹ˆ1000000ä¸ªç¥ç»å…ƒä¹Ÿè¿˜æ˜¯åªè¦$10\times10=100$ä¸ªå‚æ•°ã€‚ä½†æ˜¯è¿™æ ·ä¹Ÿæ˜¯æœ‰å¼Šç«¯çš„ï¼Œåªèƒ½ç›‘æµ‹æŸä¸€ä¸ªç‰¹æ€§ã€‚é‚£ä¹ˆæ€ä¹ˆåŠå‘¢ï¼Ÿé‚£å°±å¤šç»™ä½ å‡ ä¸ªå‚æ•°ç»„å‘—ï¼Œä½ ä»¬æ¯ä¸ªç¥ç»å…ƒå¯¹æ¯ä¸ªå‚æ•°ç»„éƒ½æ¥ä¸€éã€‚è¿™æ ·å°±å…¨é¢äº†å§ï¼å®é™…ä¸Šï¼Œå°±ç›¸å½“äºé‚£ä¹ˆå¤šäººéƒ½åˆ°åœ°æ–¹å»ä»»èŒäº†ï¼Œä¸­å¤®è¦æ±‚æ‰€æœ‰åœ°æ–¹ç®¡ç†è¦å…¨éƒ¨æŒ‰ç…§ä¸€å®šè§„çŸ©ï¼Œç„¶åè®¡ç”Ÿè¦å…¨éƒ¨æŒ‰è®¡ç”Ÿçš„è§„çŸ©ï¼Œæ°‘æ”¿è¦æŒ‰æ°‘æ”¿çš„è§„çŸ©ç­‰ç­‰ï¼Œåæ­£å…¨å›½ç»Ÿä¸€ï¼Œåˆé¢é¢ä¿±åˆ°ã€‚</p>
<p><img src="http://deeplearning.net/tutorial/_images/conv_1D_nn.png" alt="image"></p>
<p>å¦‚å›¾æ‰€ç¤ºï¼ŒåŒä¸€ä¸ªé¢œè‰²çš„çº¿ä»£è¡¨è¿™åŒä¸€ä¸ªå‚æ•°ï¼Œè¿™é‡Œè®¡ç®—å‚æ•°æ¢¯åº¦åªè¦æ±‚å„ä¸ªæ¢¯åº¦ç„¶åæ±‚å–å¹³å‡å€¼å³å¯ã€‚</p>
<h2 id="ç‰¹å¾æ˜ å°„ï¼ˆFeature-Mapï¼‰"><a href="#ç‰¹å¾æ˜ å°„ï¼ˆFeature-Mapï¼‰" class="headerlink" title="ç‰¹å¾æ˜ å°„ï¼ˆFeature Mapï¼‰"></a>ç‰¹å¾æ˜ å°„ï¼ˆ<em>Feature Map</em>ï¼‰</h2><p>äºŒç»´ç©ºé—´ä¸Šçš„å±€éƒ¨æ¥å—åŸŸä½¿å¾—ç¥ç»ç½‘ç»œå¯ä»¥ä»è¾“å…¥å›¾åƒä¸­æå–åˆçº§è§†è§‰ç‰¹å¾ï¼Œå¦‚ç‰¹å®šè§’åº¦çš„è¾¹ç¼˜ï¼Œç«¯ç‚¹å’Œæ‹è§’ç­‰ã€‚</p>
<p>æƒå€¼å…±äº«è¿«ä½¿é‚£äº›å…±äº«åŒä¸€ç»„æƒå€¼çš„ç¥ç»å…ƒåœ¨è¾“å…¥çš„ä¸åŒä½ç½®æ£€æµ‹åŒä¸€ç§ç‰¹å¾ã€‚å·ç§¯ç¥ç»ç½‘ç»œæŠŠæ¯å±‚å…±äº«ç›¸åŒæƒå€¼çš„ç¥ç»å…ƒç»„ç»‡æˆä¸€ä¸ªäºŒç»´å¹³é¢ï¼Œç§°ä¸ºç‰¹å¾æ˜ å°„(Feature Map)</p>
<p>ä¸€ä¸ªfeature mapé‡Œé¢çš„æ‰€æœ‰ç¥ç»å…ƒçš„è¾“å…¥éƒ½å¯ä»¥æœ‰åŒæ ·çš„è¡¨è¾¾æ–¹å¼ï¼Œå› ä¸ºä»–ä»¬çš„å‚æ•°ç›¸åŒã€‚</p>
<p>å‡å¦‚ç¬¬kä¸ªfeature mapè¡¨ç¤ºä¸º$h^k$ï¼Œå…¶æƒé‡çŸ©é˜µä¸º$W^k$ï¼Œåç½®å‘é‡ä¸º$b_k$ã€‚æˆ‘ä»¬ä½¿ç”¨tanhä½œä¸ºéçº¿æ€§æ¿€æ´»å‡½æ•°ã€‚é‚£ä¹ˆ</p>
<p>$$<br>h^k_{ij}=tanh((W^k*x)_{ij}+b_k)<br>$$</p>
<p>æˆ‘ä»¬çŸ¥é“æ¯ä¸€ä¸ªéšå±‚éƒ½æ˜¯ç”±å¤šä¸ªfeature mapæ„æˆã€‚</p>
<p><img src="http://deeplearning.net/tutorial/_images/cnn_explained.png" alt="image"></p>
<p>å¦‚å›¾ï¼Œå±•ç°äº†ä¸¤å±‚ï¼Œå…¶ä¸­m-1å±‚åŒ…å«4ä¸ªfeature mapï¼Œè€Œmå±‚åŒ…å«2ä¸ªã€‚$W_{ij}^{kl}$ è¡¨ç¤ºåœ¨ $m-1$ å±‚çš„ç¬¬ $k$ å¹…ç‰¹å¾å›¾çš„æ¯ä¸€ä¸ªåƒç´ ä¸ç¬¬ $m$ å±‚çš„ç¬¬ $l$ å¹…ç‰¹å¾å›¾çš„åƒç´  $(i,j)$ ä¹‹é—´çš„è¿æ¥æƒé‡ã€‚</p>
<h2 id="pythonä¸­çš„å·ç§¯è¿ç®—"><a href="#pythonä¸­çš„å·ç§¯è¿ç®—" class="headerlink" title="pythonä¸­çš„å·ç§¯è¿ç®—"></a>pythonä¸­çš„å·ç§¯è¿ç®—</h2><p>å¼•ç”¨<a href="http://blog.csdn.net/niuwei22007/article/details/48025939" target="_blank" rel="external">æ·±åº¦å­¦ä¹ (DL)ä¸å·ç§¯ç¥ç»ç½‘ç»œ(CNN)å­¦ä¹ ç¬”è®°éšç¬”-02-åŸºäºPythonçš„å·ç§¯è¿ç®—
</a>çš„æ³¨é‡Šï¼ŒåŠ ä¸Šéƒ¨åˆ†è‡ªå·±ç†è§£ï¼Œé¦–å…ˆæºç å¦‚ä¸‹<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#-*- coding: UTF-8 -*- </span></div><div class="line"><span class="keyword">import</span> theano</div><div class="line"><span class="keyword">import</span> numpy</div><div class="line"><span class="keyword">import</span> pylab</div><div class="line"><span class="keyword">from</span> theano <span class="keyword">import</span> tensor <span class="keyword">as</span> T</div><div class="line"><span class="keyword">from</span> theano.tensor.nnet <span class="keyword">import</span> conv</div><div class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</div><div class="line"></div><div class="line">rng = numpy.random.RandomState(<span class="number">23455</span>)</div><div class="line">input = T.tensor4(name=<span class="string">'input'</span>)</div><div class="line">w_shp = (<span class="number">2</span>, <span class="number">3</span>, <span class="number">9</span>, <span class="number">9</span>) </div><div class="line">w_bound = numpy.sqrt(<span class="number">3</span> * <span class="number">9</span> * <span class="number">9</span>)</div><div class="line">W = theano.shared( numpy.asarray(</div><div class="line">            rng.uniform(</div><div class="line">                low=<span class="number">-1.0</span> / w_bound,</div><div class="line">                high=<span class="number">1.0</span> / w_bound,</div><div class="line">                size=w_shp),</div><div class="line">            dtype=input.dtype), name =<span class="string">'W'</span>)</div><div class="line">b_shp = (<span class="number">2</span>,)</div><div class="line">b = theano.shared(numpy.asarray(</div><div class="line">            rng.uniform(low=<span class="number">-.5</span>, high=<span class="number">.5</span>, size=b_shp),</div><div class="line">            dtype=input.dtype), name =<span class="string">'b'</span>)</div><div class="line">conv_out = conv.conv2d(input, W)</div><div class="line">output = T.nnet.sigmoid(conv_out + b.dimshuffle(<span class="string">'x'</span>, <span class="number">0</span>, <span class="string">'x'</span>, <span class="string">'x'</span>))</div><div class="line"></div><div class="line">f = theano.function([input], output)</div><div class="line"></div><div class="line">img = Image.open(<span class="string">'g:\\b.jpg'</span>)</div><div class="line">img_w, img_h = img.size</div><div class="line">img = numpy.asarray(img, dtype=<span class="string">'float32'</span>) / <span class="number">256.</span></div><div class="line">img_ = img.transpose(<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>).reshape(<span class="number">1</span>, <span class="number">3</span>, img_h, img_w)</div><div class="line">filtered_img = f(img_)</div><div class="line">pylab.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>); pylab.axis(<span class="string">'off'</span>); pylab.imshow(img)</div><div class="line">pylab.gray();</div><div class="line"></div><div class="line">pylab.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>); pylab.axis(<span class="string">'off'</span>); pylab.imshow(filtered_img[<span class="number">0</span>, <span class="number">0</span>, :, :])</div><div class="line">pylab.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>); pylab.axis(<span class="string">'off'</span>); pylab.imshow(filtered_img[<span class="number">0</span>, <span class="number">1</span>, :, :])</div><div class="line">pylab.show()</div></pre></td></tr></table></figure></p>
<p><code>w_shp</code>ç”¨æ¥å®šä¹‰ä¸€ä¸ªçŸ©é˜µå½¢çŠ¶ï¼Œè¯¥å¤§å°å¯ä»¥ç†è§£ä¸ºæ˜¯ä¸€ä¸ª2è¡Œ3åˆ—çš„çŸ©é˜µï¼Œå…¶ä¸­æ¯ä¸ªçŸ©é˜µå…ƒç´ åˆæ˜¯ä¸€ä¸ª9è¡Œ9åˆ—çš„çŸ©é˜µã€‚</p>
<p>Wå’Œbèµ‹äºˆéšæœºåˆå€¼ï¼Œè¿™é‡Œçš„bä¸èƒ½èµ‹å€¼0ï¼Œæ˜¯å› ä¸ºå…¶éœ€è¦ä¹‹é—´è¿›è¡Œè®¡ç®—ã€‚</p>
<p>é€šè¿‡<code>conv.conv2d(input,W)</code>æ¥è®¡ç®—inputå’ŒWçš„å·ç§¯ã€‚ä¸ºäº†èƒ½ä½¿å¾—å·ç§¯åè¿˜èƒ½å’Œbç›¸åŠ ï¼Œéœ€è¦å¯¹bæ”¹å˜ç»´åº¦ï¼Œ<code>b.dimshuffle(&#39;x&#39;,0,&#39;x&#39;,&#39;x&#39;)</code></p>
<p>è¿™æ˜¯è¿™ä¸ªpythonä»£ç æœ€ä¸»è¦å®Œæˆçš„å·¥ä½œã€‚æ¥ç€è¾“å…¥å›¾åƒï¼Œè¾“å‡ºç»“æœ</p>
<p><img src="http://img1.ph.126.net/7ozUm-0Z28ZcNIfXL8X6zw==/6631701084398814898.png" alt="image"></p>
<h2 id="æœ€å¤§æ± "><a href="#æœ€å¤§æ± " class="headerlink" title="æœ€å¤§æ± "></a>æœ€å¤§æ± </h2><p>è¿™æ˜¯ä¸€ç§é‡‡æ ·çš„æ–¹æ³•ï¼Œç§°ä¹‹ä¸ºéçº¿æ€§ä¸‹é‡‡æ ·ã€‚æœ€å¤§æ± åŒ–å°†è¾“å…¥å›¾åƒåˆ’åˆ†ä¸ºä¸é‡å çš„çŸ©é˜µå—ï¼Œæ¯ä¸€ä¸ªå­åŒºåŸŸè¾“å‡ºå…¶æœ€å¤§å€¼ã€‚</p>
<p>åœ¨é€šè¿‡å·ç§¯è·å¾—äº†ç‰¹å¾ (features) ä¹‹åï¼Œä¸‹ä¸€æ­¥æˆ‘ä»¬å¸Œæœ›åˆ©ç”¨è¿™äº›ç‰¹å¾å»åšåˆ†ç±»ã€‚ç†è®ºä¸Šè®²ï¼Œäººä»¬å¯ä»¥ç”¨æ‰€æœ‰æå–å¾—åˆ°çš„ç‰¹å¾å»è®­ç»ƒåˆ†ç±»å™¨ï¼Œä¾‹å¦‚ softmax åˆ†ç±»å™¨ï¼Œä½†è¿™æ ·åšé¢ä¸´è®¡ç®—é‡çš„æŒ‘æˆ˜ã€‚ä¾‹å¦‚ï¼šå¯¹äºä¸€ä¸ª 96X96 åƒç´ çš„å›¾åƒï¼Œå‡è®¾æˆ‘ä»¬å·²ç»å­¦ä¹ å¾—åˆ°äº†400ä¸ªå®šä¹‰åœ¨8X8è¾“å…¥ä¸Šçš„ç‰¹å¾ï¼Œæ¯ä¸€ä¸ªç‰¹å¾å’Œå›¾åƒå·ç§¯éƒ½ä¼šå¾—åˆ°ä¸€ä¸ª (96 âˆ’ 8 + 1) Ã— (96 âˆ’ 8 + 1) = 7921 ç»´çš„å·ç§¯ç‰¹å¾ï¼Œç”±äºæœ‰ 400 ä¸ªç‰¹å¾ï¼Œæ‰€ä»¥æ¯ä¸ªæ ·ä¾‹ (example) éƒ½ä¼šå¾—åˆ°ä¸€ä¸ª 7921 Ã— 400 = 3,168,400 ç»´çš„å·ç§¯ç‰¹å¾å‘é‡ã€‚å­¦ä¹ ä¸€ä¸ªæ‹¥æœ‰è¶…è¿‡ 3 ç™¾ä¸‡ç‰¹å¾è¾“å…¥çš„åˆ†ç±»å™¨ååˆ†ä¸ä¾¿ï¼Œå¹¶ä¸”å®¹æ˜“å‡ºç°è¿‡æ‹Ÿåˆ (over-fitting)ã€‚</p>
<p>ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œé¦–å…ˆå›å¿†ä¸€ä¸‹ï¼Œæˆ‘ä»¬ä¹‹æ‰€ä»¥å†³å®šä½¿ç”¨å·ç§¯åçš„ç‰¹å¾æ˜¯å› ä¸ºå›¾åƒå…·æœ‰ä¸€ç§â€œé™æ€æ€§â€çš„å±æ€§ï¼Œè¿™ä¹Ÿå°±æ„å‘³ç€åœ¨ä¸€ä¸ªå›¾åƒåŒºåŸŸæœ‰ç”¨çš„ç‰¹å¾ææœ‰å¯èƒ½åœ¨å¦ä¸€ä¸ªåŒºåŸŸåŒæ ·é€‚ç”¨ã€‚å› æ­¤ï¼Œä¸ºäº†æè¿°å¤§çš„å›¾åƒï¼Œä¸€ä¸ªå¾ˆè‡ªç„¶çš„æƒ³æ³•å°±æ˜¯å¯¹ä¸åŒä½ç½®çš„ç‰¹å¾è¿›è¡Œèšåˆç»Ÿè®¡ï¼Œä¾‹å¦‚ï¼Œäººä»¬å¯ä»¥è®¡ç®—å›¾åƒä¸€ä¸ªåŒºåŸŸä¸Šçš„æŸä¸ªç‰¹å®šç‰¹å¾çš„å¹³å‡å€¼ (æˆ–æœ€å¤§å€¼)ã€‚è¿™äº›æ¦‚è¦ç»Ÿè®¡ç‰¹å¾ä¸ä»…å…·æœ‰ä½å¾—å¤šçš„ç»´åº¦ (ç›¸æ¯”ä½¿ç”¨æ‰€æœ‰æå–å¾—åˆ°çš„ç‰¹å¾)ï¼ŒåŒæ—¶è¿˜ä¼šæ”¹å–„ç»“æœ(ä¸å®¹æ˜“è¿‡æ‹Ÿåˆ)ã€‚è¿™ç§èšåˆçš„æ“ä½œå°±å«åšæ± åŒ– (pooling)ï¼Œæœ‰æ—¶ä¹Ÿç§°ä¸ºå¹³å‡æ± åŒ–æˆ–è€…æœ€å¤§æ± åŒ– (å–å†³äºè®¡ç®—æ± åŒ–çš„æ–¹æ³•)ã€‚</p>
<h1 id="CNNåº”ç”¨ä¹‹LeNet"><a href="#CNNåº”ç”¨ä¹‹LeNet" class="headerlink" title="CNNåº”ç”¨ä¹‹LeNet"></a>CNNåº”ç”¨ä¹‹LeNet</h1><p>ä¸€ç§å…¸å‹çš„ç”¨æ¥è¯†åˆ«æ•°å­—çš„å·ç§¯ç½‘ç»œæ˜¯LeNet-5ã€‚å½“å¹´ç¾å›½å¤§å¤šæ•°é“¶è¡Œå°±æ˜¯ç”¨å®ƒæ¥è¯†åˆ«æ”¯ç¥¨ä¸Šé¢çš„æ‰‹å†™æ•°å­—çš„ã€‚èƒ½å¤Ÿè¾¾åˆ°è¿™ç§å•†ç”¨çš„åœ°æ­¥ï¼Œå®ƒçš„å‡†ç¡®æ€§å¯æƒ³è€ŒçŸ¥ã€‚æ¯•ç«Ÿç›®å‰å­¦æœ¯ç•Œå’Œå·¥ä¸šç•Œçš„ç»“åˆæ˜¯æœ€å—äº‰è®®çš„ã€‚</p>
<p>æ”¯æŒè¿™ä¸ªç®—æ³•åªéœ€è¦æˆ‘ä»¬ä¸Šé¢è®²çš„ç¨€ç–ã€å·ç§¯å’Œæœ€å¤§æ± å°±å¯ä»¥äº†ã€‚ç®—æ³•ç»“æ„å›¾å¦‚ä¸‹ï¼š</p>
<p><img src="http://deeplearning.net/tutorial/_images/mylenet.png" alt="image"></p>
<p>å¦‚å›¾æ‰€ç¤ºï¼Œæ•´ä¸ªç®—æ³•åˆ†ä¸ºäº†è®¸å¤šå±‚ï¼Œä»å‰å¾€ååˆ†åˆ«æ˜¯S1ï¼ŒC1ï¼ŒS2ï¼ŒC2ä»¥åŠè¾“å‡ºå±‚ã€‚</p>
<p>æˆ‘ä»¬ä»æºç æ¥åˆ†æåŸç†ã€‚</p>
<p>é¦–å…ˆä»£ç åˆ†ä¸ºäº†ä¸¤å¤§å—ï¼Œåˆ†åˆ«æ˜¯å®šä¹‰LeNet Classçš„LeNetConvPoolLayerï¼Œå’Œè®­ç»ƒLeNetçš„evaluate_lenet5ã€‚</p>
<h2 id="LeNetConvPoolLayer-Class"><a href="#LeNetConvPoolLayer-Class" class="headerlink" title="LeNetConvPoolLayer Class"></a>LeNetConvPoolLayer Class</h2><p>å…ˆæ¥çœ‹LeNetConvPoolLayerã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">LeNetConvPoolLayer</span><span class="params">(object)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, rng, input, filter_shape, image_shape, poolsize=<span class="params">(<span class="number">2</span>, <span class="number">2</span>)</span>)</span>:</span></div><div class="line">        <span class="keyword">assert</span> image_shape[<span class="number">1</span>] == filter_shape[<span class="number">1</span>]</div><div class="line">        self.input = input</div><div class="line">        fan_in = numpy.prod(filter_shape[<span class="number">1</span>:])</div><div class="line">        fan_out = (filter_shape[<span class="number">0</span>] * numpy.prod(filter_shape[<span class="number">2</span>:]) //</div><div class="line">                   numpy.prod(poolsize))</div><div class="line">        W_bound = numpy.sqrt(<span class="number">6.</span> / (fan_in + fan_out))</div><div class="line">        self.W = theano.shared(</div><div class="line">            numpy.asarray(</div><div class="line">                rng.uniform(low=-W_bound, high=W_bound, size=filter_shape),</div><div class="line">                dtype=theano.config.floatX</div><div class="line">            ),</div><div class="line">            borrow=<span class="keyword">True</span></div><div class="line">        )</div><div class="line"></div><div class="line">        b_values = numpy.zeros((filter_shape[<span class="number">0</span>],), dtype=theano.config.floatX)</div><div class="line">        self.b = theano.shared(value=b_values, borrow=<span class="keyword">True</span>)</div><div class="line"></div><div class="line">        conv_out = conv2d(</div><div class="line">            input=input,</div><div class="line">            filters=self.W,</div><div class="line">            filter_shape=filter_shape,</div><div class="line">            input_shape=image_shape</div><div class="line">        )</div><div class="line"></div><div class="line">        pooled_out = pool.pool_2d(</div><div class="line">            input=conv_out,</div><div class="line">            ds=poolsize,</div><div class="line">            ignore_border=<span class="keyword">True</span></div><div class="line">        )</div><div class="line"></div><div class="line">        self.output = T.tanh(pooled_out + self.b.dimshuffle(<span class="string">'x'</span>, <span class="number">0</span>, <span class="string">'x'</span>, <span class="string">'x'</span>))</div><div class="line"></div><div class="line">        self.params = [self.W, self.b]</div><div class="line"></div><div class="line">        self.input = input</div></pre></td></tr></table></figure>
<p>é¦–å…ˆå…¶åˆå§‹åŒ–å‡½æ•°<code>__init__</code>æœ‰å‡ ä¸ªå‚æ•°éœ€è¦æ³¨æ„ï¼Œåˆ†åˆ«æ˜¯</p>
<ul>
<li>filter_shapeï¼šæ»¤æ³¢å™¨å½¢çŠ¶ï¼ŒåŒ…æ‹¬4ä¸ªå‚æ•°çš„å…ƒç»„ï¼ˆæ»¤æ³¢å™¨æ•°ç›®ï¼Œè¾“å…¥ç‰¹å¾æ˜ å°„æ•°ç›®ï¼Œæ»¤æ³¢å™¨é«˜ï¼Œæ»¤æ³¢å™¨å®½ï¼‰</li>
<li>image_shapeï¼šï¼ˆè®¾ç½®çš„batchå¤§å°ï¼Œè¾“å…¥ç‰¹å¾æ˜ å°„æ•°ç›®ï¼Œå›¾åƒé«˜ï¼Œå›¾åƒå®½ï¼‰</li>
<li>poolsizeï¼šæœ€å¤§æ± å–æ ·å‚æ•°ï¼ˆè¡Œã€åˆ—ï¼‰</li>
</ul>
<p>æ¥ç€éšæœºå‡åŒ€åˆå§‹åŒ–æƒå€¼Wï¼Œè®¾ç½®åç½®å‘é‡båˆå€¼0ã€‚</p>
<p>å…³é”®ç‚¹åœ¨äº<code>self.output = T.tanh(pooled_out + self.b.dimshuffle(&#39;x&#39;, 0, &#39;x&#39;, &#39;x&#39;))</code>,è¿™å¥è¯æ¨¡æ‹Ÿå…¬å¼</p>
<p>$$<br>h^k_{ij}=tanh((W^k*x)_{ij}+b_k)<br>$$<br>pooled_outæ˜¯å·ç§¯å¹¶æœ€å¤§æ± é‡‡æ ·åçš„ç»“æœï¼Œç»“æœæ˜¯4ç»´çš„ï¼Œä¸ºäº†èƒ½å’Œbç›¸åŠ ï¼Œå¿…é¡»å¯¹bå˜å‹ï¼Œè¿™é‡Œä½¿ç”¨äº†dimshuffleæ–¹æ³•ã€‚</p>
<p>å…¶å½¢å¼æ˜¯</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Pool&#123;ds=(<span class="number">2</span>, <span class="number">2</span>), ignore_border=<span class="keyword">True</span>, st=(<span class="number">2</span>, <span class="number">2</span>), padding=(<span class="number">0</span>, <span class="number">0</span>), mode=<span class="string">'max'</span>&#125;<span class="number">.0</span></div></pre></td></tr></table></figure>
<p>å¯ä»¥çœ‹å‡ºconv_outæ˜¯feature mapå¹³é¢çš„æ‰€æœ‰feature mapå½¢æˆçš„å‘é‡ï¼Œpooled_outåˆ™æ˜¯æœ€å¤§æ± é‡‡æ ·åçš„ç»“æœã€‚æ‰€ä»¥åœ¨ç¨‹åºä¸­ï¼Œç›´æ¥æŠŠç‰¹å¾æå–å’Œç‰¹å¾æ˜ å°„å˜ä¸ºäº†ä¸€ä¸ªæ“ä½œã€‚æ„å³S1å’ŒC1ä¸€èµ·æ“ä½œï¼ŒS2ï¼ŒC2ä¸€èµ·æ“ä½œã€‚</p>
<p>å¦å¤–ï¼Œconv_outæ˜¯å·ç§¯çš„æ–¹æ³•ï¼Œå…¶åŒ…å«4ä¸ªå‚æ•°</p>
<ul>
<li>input</li>
<li>filters</li>
<li>filter_shape</li>
<li>input_shape</li>
</ul>
<p>åœ¨è¿™é‡Œéœ€è¦äº†è§£çš„æ˜¯è¿™ä¸ªå·ç§¯</p>
<p><img src="http://img2.ph.126.net/91RStDgcpkATuDkX1q5QKQ==/6631565844468601421.jpg" alt="image"></p>
<p>åŸè¾“å…¥ã€28*28ã€‘çŸ©é˜µå’Œä½œä¸ºæ»¤æ³¢å™¨ã€5*5ã€‘çš„çŸ©é˜µå·ç§¯ï¼Œå¾—åˆ°çš„æ˜¯ä¸€ä¸ªç›¸å¯¹å°çš„çŸ©é˜µï¼Œè¿™ä¸ªçŸ©é˜µå°±æ˜¯feature mapã€‚</p>
<p>å®šä¹‰å·ç§¯æ“ä½œå’Œæœ€å¤§æ± å–æ ·æ“ä½œã€‚</p>
<h2 id="è®­ç»ƒå’ŒéªŒè¯çš„evaluate-lenet5å‡½æ•°"><a href="#è®­ç»ƒå’ŒéªŒè¯çš„evaluate-lenet5å‡½æ•°" class="headerlink" title="è®­ç»ƒå’ŒéªŒè¯çš„evaluate_lenet5å‡½æ•°"></a>è®­ç»ƒå’ŒéªŒè¯çš„evaluate_lenet5å‡½æ•°</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate_lenet5</span><span class="params">(learning_rate=<span class="number">0.1</span>, n_epochs=<span class="number">200</span>,</span></span></div><div class="line">                    dataset=<span class="string">'mnist.pkl.gz'</span>,</div><div class="line">                    nkerns=[<span class="number">20</span>, <span class="number">50</span>], batch_size=<span class="number">500</span>):</div><div class="line"></div><div class="line">    rng = numpy.random.RandomState(<span class="number">23455</span>)</div><div class="line"></div><div class="line">    datasets = load_data(dataset)</div><div class="line"></div><div class="line">    train_set_x, train_set_y = datasets[<span class="number">0</span>]</div><div class="line">    valid_set_x, valid_set_y = datasets[<span class="number">1</span>]</div><div class="line">    test_set_x, test_set_y = datasets[<span class="number">2</span>]</div><div class="line"></div><div class="line">    n_train_batches = train_set_x.get_value(borrow=<span class="keyword">True</span>).shape[<span class="number">0</span>]</div><div class="line">    n_valid_batches = valid_set_x.get_value(borrow=<span class="keyword">True</span>).shape[<span class="number">0</span>]</div><div class="line">    n_test_batches = test_set_x.get_value(borrow=<span class="keyword">True</span>).shape[<span class="number">0</span>]</div><div class="line">    n_train_batches //= batch_size</div><div class="line">    n_valid_batches //= batch_size</div><div class="line">    n_test_batches //= batch_size</div><div class="line"></div><div class="line">    index = T.lscalar()  <span class="comment"># index to a [mini]batch</span></div><div class="line"></div><div class="line">    <span class="comment"># start-snippet-1</span></div><div class="line">    x = T.matrix(<span class="string">'x'</span>)   <span class="comment"># the data is presented as rasterized images</span></div><div class="line">    y = T.ivector(<span class="string">'y'</span>)  <span class="comment"># the labels are presented as 1D vector of</span></div><div class="line">                        <span class="comment"># [int] labels</span></div><div class="line"></div><div class="line">    print(<span class="string">'... building the model'</span>)</div><div class="line"></div><div class="line">    layer0_input = x.reshape((batch_size, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>))</div><div class="line"></div><div class="line">    layer0 = LeNetConvPoolLayer(</div><div class="line">        rng,</div><div class="line">        input=layer0_input,</div><div class="line">        image_shape=(batch_size, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>),</div><div class="line">        filter_shape=(nkerns[<span class="number">0</span>], <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>),</div><div class="line">        poolsize=(<span class="number">2</span>, <span class="number">2</span>)</div><div class="line">    )</div><div class="line"></div><div class="line">    layer1 = LeNetConvPoolLayer(</div><div class="line">        rng,</div><div class="line">        input=layer0.output,</div><div class="line">        image_shape=(batch_size, nkerns[<span class="number">0</span>], <span class="number">12</span>, <span class="number">12</span>),</div><div class="line">        filter_shape=(nkerns[<span class="number">1</span>], nkerns[<span class="number">0</span>], <span class="number">5</span>, <span class="number">5</span>),</div><div class="line">        poolsize=(<span class="number">2</span>, <span class="number">2</span>)</div><div class="line">    )</div><div class="line"></div><div class="line">    layer2_input = layer1.output.flatten(<span class="number">2</span>)</div><div class="line"></div><div class="line">    <span class="comment"># construct a fully-connected sigmoidal layer</span></div><div class="line">    layer2 = HiddenLayer(</div><div class="line">        rng,</div><div class="line">        input=layer2_input,</div><div class="line">        n_in=nkerns[<span class="number">1</span>] * <span class="number">4</span> * <span class="number">4</span>,</div><div class="line">        n_out=<span class="number">500</span>,</div><div class="line">        activation=T.tanh</div><div class="line">    )</div><div class="line"></div><div class="line">    <span class="comment"># classify the values of the fully-connected sigmoidal layer</span></div><div class="line">    layer3 = LogisticRegression(input=layer2.output, n_in=<span class="number">500</span>, n_out=<span class="number">10</span>)</div><div class="line"></div><div class="line">    <span class="comment"># the cost we minimize during training is the NLL of the model</span></div><div class="line">    cost = layer3.negative_log_likelihood(y)</div><div class="line"></div><div class="line">    <span class="comment"># create a function to compute the mistakes that are made by the model</span></div><div class="line">    test_model = theano.function(</div><div class="line">        [index],</div><div class="line">        layer3.errors(y),</div><div class="line">        givens=&#123;</div><div class="line">            x: test_set_x[index * batch_size: (index + <span class="number">1</span>) * batch_size],</div><div class="line">            y: test_set_y[index * batch_size: (index + <span class="number">1</span>) * batch_size]</div><div class="line">        &#125;</div><div class="line">    )</div><div class="line"></div><div class="line">    validate_model = theano.function(</div><div class="line">        [index],</div><div class="line">        layer3.errors(y),</div><div class="line">        givens=&#123;</div><div class="line">            x: valid_set_x[index * batch_size: (index + <span class="number">1</span>) * batch_size],</div><div class="line">            y: valid_set_y[index * batch_size: (index + <span class="number">1</span>) * batch_size]</div><div class="line">        &#125;</div><div class="line">    )</div><div class="line"></div><div class="line">    params = layer3.params + layer2.params + layer1.params + layer0.params</div><div class="line"></div><div class="line">    grads = T.grad(cost, params)</div><div class="line"></div><div class="line">    updates = [</div><div class="line">        (param_i, param_i - learning_rate * grad_i)</div><div class="line">        <span class="keyword">for</span> param_i, grad_i <span class="keyword">in</span> zip(params, grads)</div><div class="line">    ]</div><div class="line"></div><div class="line">    train_model = theano.function(</div><div class="line">        [index],</div><div class="line">        cost,</div><div class="line">        updates=updates,</div><div class="line">        givens=&#123;</div><div class="line">            x: train_set_x[index * batch_size: (index + <span class="number">1</span>) * batch_size],</div><div class="line">            y: train_set_y[index * batch_size: (index + <span class="number">1</span>) * batch_size]</div><div class="line">        &#125;</div><div class="line">    )</div><div class="line"></div><div class="line">    print(<span class="string">'... training'</span>)</div><div class="line">    patience = <span class="number">10000</span>  </div><div class="line">    patience_increase = <span class="number">2</span> </div><div class="line">    improvement_threshold = <span class="number">0.995</span>  </div><div class="line">    validation_frequency = min(n_train_batches, patience // <span class="number">2</span>)</div><div class="line">    best_validation_loss = numpy.inf</div><div class="line">    best_iter = <span class="number">0</span></div><div class="line">    test_score = <span class="number">0.</span></div><div class="line">    start_time = timeit.default_timer()</div><div class="line"></div><div class="line">    epoch = <span class="number">0</span></div><div class="line">    done_looping = <span class="keyword">False</span></div><div class="line"></div><div class="line">    <span class="keyword">while</span> (epoch &lt; n_epochs) <span class="keyword">and</span> (<span class="keyword">not</span> done_looping):</div><div class="line">        epoch = epoch + <span class="number">1</span></div><div class="line">        <span class="keyword">for</span> minibatch_index <span class="keyword">in</span> range(n_train_batches):</div><div class="line"></div><div class="line">            iter = (epoch - <span class="number">1</span>) * n_train_batches + minibatch_index</div><div class="line"></div><div class="line">            <span class="keyword">if</span> iter % <span class="number">100</span> == <span class="number">0</span>:</div><div class="line">                print(<span class="string">'training @ iter = '</span>, iter)</div><div class="line">            cost_ij = train_model(minibatch_index)</div><div class="line"></div><div class="line">            <span class="keyword">if</span> (iter + <span class="number">1</span>) % validation_frequency == <span class="number">0</span>:</div><div class="line"></div><div class="line">                <span class="comment"># compute zero-one loss on validation set</span></div><div class="line">                validation_losses = [validate_model(i) <span class="keyword">for</span> i</div><div class="line">                                     <span class="keyword">in</span> range(n_valid_batches)]</div><div class="line">                this_validation_loss = numpy.mean(validation_losses)</div><div class="line">                print(<span class="string">'epoch %i, minibatch %i/%i, validation error %f %%'</span> %</div><div class="line">                      (epoch, minibatch_index + <span class="number">1</span>, n_train_batches,</div><div class="line">                       this_validation_loss * <span class="number">100.</span>))</div><div class="line"></div><div class="line">                <span class="comment"># if we got the best validation score until now</span></div><div class="line">                <span class="keyword">if</span> this_validation_loss &lt; best_validation_loss:</div><div class="line"></div><div class="line">                    <span class="comment">#improve patience if loss improvement is good enough</span></div><div class="line">                    <span class="keyword">if</span> this_validation_loss &lt; best_validation_loss *  \</div><div class="line">                       improvement_threshold:</div><div class="line">                        patience = max(patience, iter * patience_increase)</div><div class="line"></div><div class="line">                    <span class="comment"># save best validation score and iteration number</span></div><div class="line">                    best_validation_loss = this_validation_loss</div><div class="line">                    best_iter = iter</div><div class="line"></div><div class="line">                    <span class="comment"># test it on the test set</span></div><div class="line">                    test_losses = [</div><div class="line">                        test_model(i)</div><div class="line">                        <span class="keyword">for</span> i <span class="keyword">in</span> range(n_test_batches)</div><div class="line">                    ]</div><div class="line">                    test_score = numpy.mean(test_losses)</div><div class="line">                    print((<span class="string">'     epoch %i, minibatch %i/%i, test error of '</span></div><div class="line">                           <span class="string">'best model %f %%'</span>) %</div><div class="line">                          (epoch, minibatch_index + <span class="number">1</span>, n_train_batches,</div><div class="line">                           test_score * <span class="number">100.</span>))</div><div class="line"></div><div class="line">            <span class="keyword">if</span> patience &lt;= iter:</div><div class="line">                done_looping = <span class="keyword">True</span></div><div class="line">                <span class="keyword">break</span></div><div class="line"></div><div class="line">    end_time = timeit.default_timer()</div><div class="line">    print(<span class="string">'Optimization complete.'</span>)</div><div class="line">    print(<span class="string">'Best validation score of %f %% obtained at iteration %i, '</span></div><div class="line">          <span class="string">'with test performance %f %%'</span> %</div><div class="line">          (best_validation_loss * <span class="number">100.</span>, best_iter + <span class="number">1</span>, test_score * <span class="number">100.</span>))</div><div class="line">    print((<span class="string">'The code for file '</span> +</div><div class="line">           os.path.split(__file__)[<span class="number">1</span>] +</div><div class="line">           <span class="string">' ran for %.2fm'</span> % ((end_time - start_time) / <span class="number">60.</span>)), file=sys.stderr)</div></pre></td></tr></table></figure>
<p>é¦–å…ˆå‡½æ•°å®šä¹‰äº†å‡ ä¸ªå‚æ•°</p>
<ul>
<li>learning_rateï¼šå­¦ä¹ ç‡</li>
<li>n_epochsï¼šæœ€å¤§è¿­ä»£æ¬¡æ•°</li>
<li>datasetï¼š</li>
<li>nkernsï¼šå·ç§¯æ ¸æ•°ç›®</li>
<li></li>
</ul>
<h3 id="ç¬¬0å±‚ï¼ŒS1å±‚-C1å±‚"><a href="#ç¬¬0å±‚ï¼ŒS1å±‚-C1å±‚" class="headerlink" title="ç¬¬0å±‚ï¼ŒS1å±‚+C1å±‚"></a>ç¬¬0å±‚ï¼ŒS1å±‚+C1å±‚</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">layer0_input = x.reshape((batch_size, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>))</div><div class="line"></div><div class="line">layer0 = LeNetConvPoolLayer(</div><div class="line">    rng,</div><div class="line">    input=layer0_input,</div><div class="line">    image_shape=(batch_size, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>),</div><div class="line">    filter_shape=(nkerns[<span class="number">0</span>], <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>),</div><div class="line">    poolsize=(<span class="number">2</span>, <span class="number">2</span>)</div><div class="line">)</div></pre></td></tr></table></figure>
<p>å»ºæ¨¡çš„å¼€å§‹å’ŒMLPsæ˜¯ä¸€æ ·çš„ï¼Œä½†æ˜¯è¾“å…¥æ•°æ®è¦é‡æ„reshapeï¼Œä»2Dè½¬æ¢ä¸º4Dï¼Œé€šè¿‡<code>x.reshape((batch_size, 1, 28, 28))</code>å°†æ•°æ®è½¬åŒ–ä¸ºbatch_sizeè¡Œï¼Œ1è¡Œ1ä¸ªæ ·æœ¬ï¼Œæ¯è¡Œæœ‰28*28åˆ—ã€‚è¿™ä»£è¡¨äº†ç¬¬S1å±‚ï¼Œæ¨¡æ‹Ÿçš„æ˜¯å·ç§¯è¿‡ç¨‹ï¼Œåªéœ€è¦è°ƒç”¨LeNetConvPoolLayeræ¨¡å—å³å¯è¿›è¡Œè¿ç®—ã€‚</p>
<h3 id="ç¬¬1å±‚-S2å±‚-C2å±‚"><a href="#ç¬¬1å±‚-S2å±‚-C2å±‚" class="headerlink" title="ç¬¬1å±‚ S2å±‚+C2å±‚"></a>ç¬¬1å±‚ S2å±‚+C2å±‚</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">layer1 = LeNetConvPoolLayer(</div><div class="line">    rng,</div><div class="line">    input=layer0.output,</div><div class="line">    image_shape=(batch_size, nkerns[<span class="number">0</span>], <span class="number">12</span>, <span class="number">12</span>),</div><div class="line">    filter_shape=(nkerns[<span class="number">1</span>], nkerns[<span class="number">0</span>], <span class="number">5</span>, <span class="number">5</span>),</div><div class="line">    poolsize=(<span class="number">2</span>, <span class="number">2</span>)</div><div class="line">)</div></pre></td></tr></table></figure>
<p>å‘ç°å…¶å›¾åƒçš„ç‰¹å¾æ˜ å°„å˜æˆäº†20ï¼Œè€Œæ»¤æ³¢å™¨æ•°ç›®å˜ä¸º50ã€‚</p>
<h3 id="ç¬¬2å±‚-MLPéšå±‚"><a href="#ç¬¬2å±‚-MLPéšå±‚" class="headerlink" title="ç¬¬2å±‚ MLPéšå±‚"></a>ç¬¬2å±‚ MLPéšå±‚</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">layer2_input = layer1.output.flatten(<span class="number">2</span>)</div><div class="line"></div><div class="line"><span class="comment"># construct a fully-connected sigmoidal layer</span></div><div class="line">layer2 = HiddenLayer(</div><div class="line">    rng,</div><div class="line">    input=layer2_input,</div><div class="line">    n_in=nkerns[<span class="number">1</span>] * <span class="number">4</span> * <span class="number">4</span>,</div><div class="line">    n_out=<span class="number">500</span>,</div><div class="line">    activation=T.tanh</div><div class="line">)</div></pre></td></tr></table></figure>
<p>æœ€åçš„æ“ä½œæ˜¯è¦ç»§ç»­å°†å…¶å˜ä¸º2ç»´ï¼Œç„¶åè¿›è¡ŒMLPçš„è®¡ç®—ã€‚</p>
<h3 id="ç¬¬3å±‚-lRå±‚"><a href="#ç¬¬3å±‚-lRå±‚" class="headerlink" title="ç¬¬3å±‚ lRå±‚"></a>ç¬¬3å±‚ lRå±‚</h3><p>ç„¶åéœ€è¦è¿›è¡ŒLRæ“ä½œæ¥è®­ç»ƒ</p>
<p>æ¥ä¸‹æ¥è¿›è¡Œæ¢¯åº¦ä¸‹é™æ³•è¿›è¡Œè®­ç»ƒå‚æ•°ã€‚</p>
<h2 id="è¿è¡Œç»“æœ"><a href="#è¿è¡Œç»“æœ" class="headerlink" title="è¿è¡Œç»“æœ"></a>è¿è¡Œç»“æœ</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div><div class="line">198</div><div class="line">199</div><div class="line">200</div><div class="line">201</div><div class="line">202</div><div class="line">203</div><div class="line">204</div><div class="line">205</div><div class="line">206</div><div class="line">207</div><div class="line">208</div><div class="line">209</div><div class="line">210</div><div class="line">211</div><div class="line">212</div><div class="line">213</div><div class="line">214</div><div class="line">215</div><div class="line">216</div><div class="line">217</div><div class="line">218</div><div class="line">219</div><div class="line">220</div><div class="line">221</div><div class="line">222</div><div class="line">223</div><div class="line">224</div><div class="line">225</div><div class="line">226</div><div class="line">227</div><div class="line">228</div><div class="line">229</div><div class="line">230</div><div class="line">231</div><div class="line">232</div><div class="line">233</div><div class="line">234</div><div class="line">235</div><div class="line">236</div><div class="line">237</div><div class="line">238</div><div class="line">239</div><div class="line">240</div><div class="line">241</div><div class="line">242</div><div class="line">243</div><div class="line">244</div><div class="line">245</div><div class="line">246</div><div class="line">247</div><div class="line">248</div><div class="line">249</div><div class="line">250</div><div class="line">251</div><div class="line">252</div><div class="line">253</div><div class="line">254</div><div class="line">255</div><div class="line">256</div><div class="line">257</div><div class="line">258</div><div class="line">259</div><div class="line">260</div><div class="line">261</div><div class="line">262</div><div class="line">263</div><div class="line">264</div><div class="line">265</div><div class="line">266</div><div class="line">267</div><div class="line">268</div><div class="line">269</div><div class="line">270</div><div class="line">271</div><div class="line">272</div><div class="line">273</div><div class="line">274</div><div class="line">275</div><div class="line">276</div><div class="line">277</div><div class="line">278</div><div class="line">279</div><div class="line">280</div><div class="line">281</div><div class="line">282</div><div class="line">283</div><div class="line">284</div><div class="line">285</div><div class="line">286</div><div class="line">287</div><div class="line">288</div><div class="line">289</div><div class="line">290</div><div class="line">291</div><div class="line">292</div><div class="line">293</div><div class="line">294</div><div class="line">295</div><div class="line">296</div><div class="line">297</div><div class="line">298</div><div class="line">299</div><div class="line">300</div><div class="line">301</div><div class="line">302</div><div class="line">303</div><div class="line">304</div><div class="line">305</div><div class="line">306</div><div class="line">307</div><div class="line">308</div><div class="line">309</div><div class="line">310</div><div class="line">311</div><div class="line">312</div><div class="line">313</div><div class="line">314</div><div class="line">315</div><div class="line">316</div><div class="line">317</div><div class="line">318</div><div class="line">319</div><div class="line">320</div><div class="line">321</div><div class="line">322</div><div class="line">323</div><div class="line">324</div><div class="line">325</div><div class="line">326</div><div class="line">327</div><div class="line">328</div><div class="line">329</div><div class="line">330</div><div class="line">331</div><div class="line">332</div><div class="line">333</div><div class="line">334</div><div class="line">335</div><div class="line">336</div><div class="line">337</div><div class="line">338</div><div class="line">339</div><div class="line">340</div><div class="line">341</div><div class="line">342</div><div class="line">343</div><div class="line">344</div><div class="line">345</div><div class="line">346</div><div class="line">347</div><div class="line">348</div><div class="line">349</div><div class="line">350</div><div class="line">351</div><div class="line">352</div><div class="line">353</div><div class="line">354</div><div class="line">355</div><div class="line">356</div><div class="line">357</div><div class="line">358</div><div class="line">359</div><div class="line">360</div><div class="line">361</div><div class="line">362</div><div class="line">363</div><div class="line">364</div><div class="line">365</div><div class="line">366</div><div class="line">367</div><div class="line">368</div><div class="line">369</div><div class="line">370</div><div class="line">371</div><div class="line">372</div><div class="line">373</div><div class="line">374</div><div class="line">375</div><div class="line">376</div><div class="line">377</div><div class="line">378</div><div class="line">379</div><div class="line">380</div><div class="line">381</div><div class="line">382</div><div class="line">383</div><div class="line">384</div><div class="line">385</div><div class="line">386</div><div class="line">387</div><div class="line">388</div><div class="line">389</div><div class="line">390</div><div class="line">391</div><div class="line">392</div><div class="line">393</div><div class="line">394</div><div class="line">395</div><div class="line">396</div><div class="line">397</div><div class="line">398</div><div class="line">399</div><div class="line">400</div><div class="line">401</div><div class="line">402</div><div class="line">403</div><div class="line">404</div><div class="line">405</div><div class="line">406</div><div class="line">407</div><div class="line">408</div><div class="line">409</div><div class="line">410</div><div class="line">411</div><div class="line">412</div><div class="line">413</div><div class="line">414</div><div class="line">415</div><div class="line">416</div><div class="line">417</div><div class="line">418</div><div class="line">419</div><div class="line">420</div><div class="line">421</div><div class="line">422</div><div class="line">423</div><div class="line">424</div><div class="line">425</div><div class="line">426</div><div class="line">427</div><div class="line">428</div><div class="line">429</div><div class="line">430</div><div class="line">431</div><div class="line">432</div><div class="line">433</div><div class="line">434</div><div class="line">435</div><div class="line">436</div><div class="line">437</div><div class="line">438</div><div class="line">439</div><div class="line">440</div><div class="line">441</div><div class="line">442</div><div class="line">443</div><div class="line">444</div><div class="line">445</div><div class="line">446</div><div class="line">447</div><div class="line">448</div><div class="line">449</div><div class="line">450</div><div class="line">451</div><div class="line">452</div><div class="line">453</div><div class="line">454</div><div class="line">455</div><div class="line">456</div><div class="line">457</div><div class="line">458</div><div class="line">459</div><div class="line">460</div><div class="line">461</div><div class="line">462</div><div class="line">463</div><div class="line">464</div></pre></td><td class="code"><pre><div class="line">... loading data</div><div class="line">... building the model</div><div class="line">Pool&#123;ds=(2, 2), ignore_border=True, st=(2, 2), padding=(0, 0), mode=&apos;max&apos;&#125;.0</div><div class="line">Pool&#123;ds=(2, 2), ignore_border=True, st=(2, 2), padding=(0, 0), mode=&apos;max&apos;&#125;.0</div><div class="line">... training</div><div class="line">training @ iter =  0</div><div class="line">epoch 1, minibatch 100/100, validation error 9.230000 %</div><div class="line">     epoch 1, minibatch 100/100, test error of best model 9.520000 %</div><div class="line">training @ iter =  100</div><div class="line">epoch 2, minibatch 100/100, validation error 6.180000 %</div><div class="line">     epoch 2, minibatch 100/100, test error of best model 6.500000 %</div><div class="line">training @ iter =  200</div><div class="line">epoch 3, minibatch 100/100, validation error 4.640000 %</div><div class="line">     epoch 3, minibatch 100/100, test error of best model 4.850000 %</div><div class="line">training @ iter =  300</div><div class="line">epoch 4, minibatch 100/100, validation error 3.500000 %</div><div class="line">     epoch 4, minibatch 100/100, test error of best model 3.910000 %</div><div class="line">training @ iter =  400</div><div class="line">epoch 5, minibatch 100/100, validation error 3.020000 %</div><div class="line">     epoch 5, minibatch 100/100, test error of best model 3.260000 %</div><div class="line">training @ iter =  500</div><div class="line">epoch 6, minibatch 100/100, validation error 2.780000 %</div><div class="line">     epoch 6, minibatch 100/100, test error of best model 2.800000 %</div><div class="line">training @ iter =  600</div><div class="line">epoch 7, minibatch 100/100, validation error 2.480000 %</div><div class="line">     epoch 7, minibatch 100/100, test error of best model 2.500000 %</div><div class="line">training @ iter =  700</div><div class="line">epoch 8, minibatch 100/100, validation error 2.290000 %</div><div class="line">     epoch 8, minibatch 100/100, test error of best model 2.220000 %</div><div class="line">training @ iter =  800</div><div class="line">epoch 9, minibatch 100/100, validation error 2.160000 %</div><div class="line">     epoch 9, minibatch 100/100, test error of best model 2.010000 %</div><div class="line">training @ iter =  900</div><div class="line">epoch 10, minibatch 100/100, validation error 1.970000 %</div><div class="line">     epoch 10, minibatch 100/100, test error of best model 1.880000 %</div><div class="line">training @ iter =  1000</div><div class="line">epoch 11, minibatch 100/100, validation error 1.880000 %</div><div class="line">     epoch 11, minibatch 100/100, test error of best model 1.790000 %</div><div class="line">training @ iter =  1100</div><div class="line">epoch 12, minibatch 100/100, validation error 1.790000 %</div><div class="line">     epoch 12, minibatch 100/100, test error of best model 1.660000 %</div><div class="line">training @ iter =  1200</div><div class="line">epoch 13, minibatch 100/100, validation error 1.760000 %</div><div class="line">     epoch 13, minibatch 100/100, test error of best model 1.580000 %</div><div class="line">training @ iter =  1300</div><div class="line">epoch 14, minibatch 100/100, validation error 1.710000 %</div><div class="line">     epoch 14, minibatch 100/100, test error of best model 1.550000 %</div><div class="line">training @ iter =  1400</div><div class="line">epoch 15, minibatch 100/100, validation error 1.680000 %</div><div class="line">     epoch 15, minibatch 100/100, test error of best model 1.500000 %</div><div class="line">training @ iter =  1500</div><div class="line">epoch 16, minibatch 100/100, validation error 1.620000 %</div><div class="line">     epoch 16, minibatch 100/100, test error of best model 1.440000 %</div><div class="line">training @ iter =  1600</div><div class="line">epoch 17, minibatch 100/100, validation error 1.590000 %</div><div class="line">     epoch 17, minibatch 100/100, test error of best model 1.410000 %</div><div class="line">training @ iter =  1700</div><div class="line">epoch 18, minibatch 100/100, validation error 1.560000 %</div><div class="line">     epoch 18, minibatch 100/100, test error of best model 1.410000 %</div><div class="line">training @ iter =  1800</div><div class="line">epoch 19, minibatch 100/100, validation error 1.530000 %</div><div class="line">     epoch 19, minibatch 100/100, test error of best model 1.380000 %</div><div class="line">training @ iter =  1900</div><div class="line">epoch 20, minibatch 100/100, validation error 1.520000 %</div><div class="line">     epoch 20, minibatch 100/100, test error of best model 1.330000 %</div><div class="line">training @ iter =  2000</div><div class="line">epoch 21, minibatch 100/100, validation error 1.490000 %</div><div class="line">     epoch 21, minibatch 100/100, test error of best model 1.270000 %</div><div class="line">training @ iter =  2100</div><div class="line">epoch 22, minibatch 100/100, validation error 1.460000 %</div><div class="line">     epoch 22, minibatch 100/100, test error of best model 1.270000 %</div><div class="line">training @ iter =  2200</div><div class="line">epoch 23, minibatch 100/100, validation error 1.430000 %</div><div class="line">     epoch 23, minibatch 100/100, test error of best model 1.240000 %</div><div class="line">training @ iter =  2300</div><div class="line">epoch 24, minibatch 100/100, validation error 1.410000 %</div><div class="line">     epoch 24, minibatch 100/100, test error of best model 1.230000 %</div><div class="line">training @ iter =  2400</div><div class="line">epoch 25, minibatch 100/100, validation error 1.380000 %</div><div class="line">     epoch 25, minibatch 100/100, test error of best model 1.190000 %</div><div class="line">training @ iter =  2500</div><div class="line">epoch 26, minibatch 100/100, validation error 1.340000 %</div><div class="line">     epoch 26, minibatch 100/100, test error of best model 1.150000 %</div><div class="line">training @ iter =  2600</div><div class="line">epoch 27, minibatch 100/100, validation error 1.320000 %</div><div class="line">     epoch 27, minibatch 100/100, test error of best model 1.150000 %</div><div class="line">training @ iter =  2700</div><div class="line">epoch 28, minibatch 100/100, validation error 1.300000 %</div><div class="line">     epoch 28, minibatch 100/100, test error of best model 1.120000 %</div><div class="line">training @ iter =  2800</div><div class="line">epoch 29, minibatch 100/100, validation error 1.270000 %</div><div class="line">     epoch 29, minibatch 100/100, test error of best model 1.120000 %</div><div class="line">training @ iter =  2900</div><div class="line">epoch 30, minibatch 100/100, validation error 1.260000 %</div><div class="line">     epoch 30, minibatch 100/100, test error of best model 1.110000 %</div><div class="line">training @ iter =  3000</div><div class="line">epoch 31, minibatch 100/100, validation error 1.260000 %</div><div class="line">training @ iter =  3100</div><div class="line">epoch 32, minibatch 100/100, validation error 1.250000 %</div><div class="line">     epoch 32, minibatch 100/100, test error of best model 1.100000 %</div><div class="line">training @ iter =  3200</div><div class="line">epoch 33, minibatch 100/100, validation error 1.250000 %</div><div class="line">training @ iter =  3300</div><div class="line">epoch 34, minibatch 100/100, validation error 1.220000 %</div><div class="line">     epoch 34, minibatch 100/100, test error of best model 1.070000 %</div><div class="line">training @ iter =  3400</div><div class="line">epoch 35, minibatch 100/100, validation error 1.220000 %</div><div class="line">training @ iter =  3500</div><div class="line">epoch 36, minibatch 100/100, validation error 1.190000 %</div><div class="line">     epoch 36, minibatch 100/100, test error of best model 1.050000 %</div><div class="line">training @ iter =  3600</div><div class="line">epoch 37, minibatch 100/100, validation error 1.190000 %</div><div class="line">training @ iter =  3700</div><div class="line">epoch 38, minibatch 100/100, validation error 1.180000 %</div><div class="line">     epoch 38, minibatch 100/100, test error of best model 1.070000 %</div><div class="line">training @ iter =  3800</div><div class="line">epoch 39, minibatch 100/100, validation error 1.180000 %</div><div class="line">training @ iter =  3900</div><div class="line">epoch 40, minibatch 100/100, validation error 1.170000 %</div><div class="line">     epoch 40, minibatch 100/100, test error of best model 1.070000 %</div><div class="line">training @ iter =  4000</div><div class="line">epoch 41, minibatch 100/100, validation error 1.150000 %</div><div class="line">     epoch 41, minibatch 100/100, test error of best model 1.080000 %</div><div class="line">training @ iter =  4100</div><div class="line">epoch 42, minibatch 100/100, validation error 1.150000 %</div><div class="line">training @ iter =  4200</div><div class="line">epoch 43, minibatch 100/100, validation error 1.140000 %</div><div class="line">     epoch 43, minibatch 100/100, test error of best model 1.060000 %</div><div class="line">training @ iter =  4300</div><div class="line">epoch 44, minibatch 100/100, validation error 1.130000 %</div><div class="line">     epoch 44, minibatch 100/100, test error of best model 1.050000 %</div><div class="line">training @ iter =  4400</div><div class="line">epoch 45, minibatch 100/100, validation error 1.130000 %</div><div class="line">training @ iter =  4500</div><div class="line">epoch 46, minibatch 100/100, validation error 1.120000 %</div><div class="line">     epoch 46, minibatch 100/100, test error of best model 1.050000 %</div><div class="line">training @ iter =  4600</div><div class="line">epoch 47, minibatch 100/100, validation error 1.110000 %</div><div class="line">     epoch 47, minibatch 100/100, test error of best model 1.040000 %</div><div class="line">training @ iter =  4700</div><div class="line">epoch 48, minibatch 100/100, validation error 1.090000 %</div><div class="line">     epoch 48, minibatch 100/100, test error of best model 1.050000 %</div><div class="line">training @ iter =  4800</div><div class="line">epoch 49, minibatch 100/100, validation error 1.090000 %</div><div class="line">training @ iter =  4900</div><div class="line">epoch 50, minibatch 100/100, validation error 1.090000 %</div><div class="line">training @ iter =  5000</div><div class="line">epoch 51, minibatch 100/100, validation error 1.100000 %</div><div class="line">training @ iter =  5100</div><div class="line">epoch 52, minibatch 100/100, validation error 1.090000 %</div><div class="line">training @ iter =  5200</div><div class="line">epoch 53, minibatch 100/100, validation error 1.080000 %</div><div class="line">     epoch 53, minibatch 100/100, test error of best model 1.030000 %</div><div class="line">training @ iter =  5300</div><div class="line">epoch 54, minibatch 100/100, validation error 1.070000 %</div><div class="line">     epoch 54, minibatch 100/100, test error of best model 1.030000 %</div><div class="line">training @ iter =  5400</div><div class="line">epoch 55, minibatch 100/100, validation error 1.070000 %</div><div class="line">training @ iter =  5500</div><div class="line">epoch 56, minibatch 100/100, validation error 1.080000 %</div><div class="line">training @ iter =  5600</div><div class="line">epoch 57, minibatch 100/100, validation error 1.080000 %</div><div class="line">training @ iter =  5700</div><div class="line">epoch 58, minibatch 100/100, validation error 1.070000 %</div><div class="line">training @ iter =  5800</div><div class="line">epoch 59, minibatch 100/100, validation error 1.060000 %</div><div class="line">     epoch 59, minibatch 100/100, test error of best model 0.990000 %</div><div class="line">training @ iter =  5900</div><div class="line">epoch 60, minibatch 100/100, validation error 1.070000 %</div><div class="line">training @ iter =  6000</div><div class="line">epoch 61, minibatch 100/100, validation error 1.070000 %</div><div class="line">training @ iter =  6100</div><div class="line">epoch 62, minibatch 100/100, validation error 1.070000 %</div><div class="line">training @ iter =  6200</div><div class="line">epoch 63, minibatch 100/100, validation error 1.070000 %</div><div class="line">training @ iter =  6300</div><div class="line">epoch 64, minibatch 100/100, validation error 1.070000 %</div><div class="line">training @ iter =  6400</div><div class="line">epoch 65, minibatch 100/100, validation error 1.070000 %</div><div class="line">training @ iter =  6500</div><div class="line">epoch 66, minibatch 100/100, validation error 1.060000 %</div><div class="line">training @ iter =  6600</div><div class="line">epoch 67, minibatch 100/100, validation error 1.060000 %</div><div class="line">training @ iter =  6700</div><div class="line">epoch 68, minibatch 100/100, validation error 1.070000 %</div><div class="line">training @ iter =  6800</div><div class="line">epoch 69, minibatch 100/100, validation error 1.070000 %</div><div class="line">training @ iter =  6900</div><div class="line">epoch 70, minibatch 100/100, validation error 1.050000 %</div><div class="line">     epoch 70, minibatch 100/100, test error of best model 0.970000 %</div><div class="line">training @ iter =  7000</div><div class="line">epoch 71, minibatch 100/100, validation error 1.030000 %</div><div class="line">     epoch 71, minibatch 100/100, test error of best model 0.970000 %</div><div class="line">training @ iter =  7100</div><div class="line">epoch 72, minibatch 100/100, validation error 1.030000 %</div><div class="line">training @ iter =  7200</div><div class="line">epoch 73, minibatch 100/100, validation error 1.020000 %</div><div class="line">     epoch 73, minibatch 100/100, test error of best model 0.970000 %</div><div class="line">training @ iter =  7300</div><div class="line">epoch 74, minibatch 100/100, validation error 1.000000 %</div><div class="line">     epoch 74, minibatch 100/100, test error of best model 0.960000 %</div><div class="line">training @ iter =  7400</div><div class="line">epoch 75, minibatch 100/100, validation error 1.000000 %</div><div class="line">training @ iter =  7500</div><div class="line">epoch 76, minibatch 100/100, validation error 0.980000 %</div><div class="line">     epoch 76, minibatch 100/100, test error of best model 0.970000 %</div><div class="line">training @ iter =  7600</div><div class="line">epoch 77, minibatch 100/100, validation error 0.970000 %</div><div class="line">     epoch 77, minibatch 100/100, test error of best model 0.970000 %</div><div class="line">training @ iter =  7700</div><div class="line">epoch 78, minibatch 100/100, validation error 0.970000 %</div><div class="line">training @ iter =  7800</div><div class="line">epoch 79, minibatch 100/100, validation error 0.990000 %</div><div class="line">training @ iter =  7900</div><div class="line">epoch 80, minibatch 100/100, validation error 0.990000 %</div><div class="line">training @ iter =  8000</div><div class="line">epoch 81, minibatch 100/100, validation error 1.000000 %</div><div class="line">training @ iter =  8100</div><div class="line">epoch 82, minibatch 100/100, validation error 1.000000 %</div><div class="line">training @ iter =  8200</div><div class="line">epoch 83, minibatch 100/100, validation error 0.990000 %</div><div class="line">training @ iter =  8300</div><div class="line">epoch 84, minibatch 100/100, validation error 0.990000 %</div><div class="line">training @ iter =  8400</div><div class="line">epoch 85, minibatch 100/100, validation error 0.980000 %</div><div class="line">training @ iter =  8500</div><div class="line">epoch 86, minibatch 100/100, validation error 0.980000 %</div><div class="line">training @ iter =  8600</div><div class="line">epoch 87, minibatch 100/100, validation error 0.980000 %</div><div class="line">training @ iter =  8700</div><div class="line">epoch 88, minibatch 100/100, validation error 0.970000 %</div><div class="line">training @ iter =  8800</div><div class="line">epoch 89, minibatch 100/100, validation error 0.960000 %</div><div class="line">     epoch 89, minibatch 100/100, test error of best model 0.970000 %</div><div class="line">training @ iter =  8900</div><div class="line">epoch 90, minibatch 100/100, validation error 0.970000 %</div><div class="line">training @ iter =  9000</div><div class="line">epoch 91, minibatch 100/100, validation error 0.970000 %</div><div class="line">training @ iter =  9100</div><div class="line">epoch 92, minibatch 100/100, validation error 0.950000 %</div><div class="line">     epoch 92, minibatch 100/100, test error of best model 0.970000 %</div><div class="line">training @ iter =  9200</div><div class="line">epoch 93, minibatch 100/100, validation error 0.940000 %</div><div class="line">     epoch 93, minibatch 100/100, test error of best model 0.980000 %</div><div class="line">training @ iter =  9300</div><div class="line">epoch 94, minibatch 100/100, validation error 0.940000 %</div><div class="line">training @ iter =  9400</div><div class="line">epoch 95, minibatch 100/100, validation error 0.940000 %</div><div class="line">training @ iter =  9500</div><div class="line">epoch 96, minibatch 100/100, validation error 0.940000 %</div><div class="line">training @ iter =  9600</div><div class="line">epoch 97, minibatch 100/100, validation error 0.930000 %</div><div class="line">     epoch 97, minibatch 100/100, test error of best model 0.960000 %</div><div class="line">training @ iter =  9700</div><div class="line">epoch 98, minibatch 100/100, validation error 0.930000 %</div><div class="line">training @ iter =  9800</div><div class="line">epoch 99, minibatch 100/100, validation error 0.940000 %</div><div class="line">training @ iter =  9900</div><div class="line">epoch 100, minibatch 100/100, validation error 0.940000 %</div><div class="line">training @ iter =  10000</div><div class="line">epoch 101, minibatch 100/100, validation error 0.940000 %</div><div class="line">training @ iter =  10100</div><div class="line">epoch 102, minibatch 100/100, validation error 0.940000 %</div><div class="line">training @ iter =  10200</div><div class="line">epoch 103, minibatch 100/100, validation error 0.940000 %</div><div class="line">training @ iter =  10300</div><div class="line">epoch 104, minibatch 100/100, validation error 0.940000 %</div><div class="line">training @ iter =  10400</div><div class="line">epoch 105, minibatch 100/100, validation error 0.950000 %</div><div class="line">training @ iter =  10500</div><div class="line">epoch 106, minibatch 100/100, validation error 0.950000 %</div><div class="line">training @ iter =  10600</div><div class="line">epoch 107, minibatch 100/100, validation error 0.950000 %</div><div class="line">training @ iter =  10700</div><div class="line">epoch 108, minibatch 100/100, validation error 0.950000 %</div><div class="line">training @ iter =  10800</div><div class="line">epoch 109, minibatch 100/100, validation error 0.950000 %</div><div class="line">training @ iter =  10900</div><div class="line">epoch 110, minibatch 100/100, validation error 0.950000 %</div><div class="line">training @ iter =  11000</div><div class="line">epoch 111, minibatch 100/100, validation error 0.950000 %</div><div class="line">training @ iter =  11100</div><div class="line">epoch 112, minibatch 100/100, validation error 0.950000 %</div><div class="line">training @ iter =  11200</div><div class="line">epoch 113, minibatch 100/100, validation error 0.940000 %</div><div class="line">training @ iter =  11300</div><div class="line">epoch 114, minibatch 100/100, validation error 0.940000 %</div><div class="line">training @ iter =  11400</div><div class="line">epoch 115, minibatch 100/100, validation error 0.940000 %</div><div class="line">training @ iter =  11500</div><div class="line">epoch 116, minibatch 100/100, validation error 0.940000 %</div><div class="line">training @ iter =  11600</div><div class="line">epoch 117, minibatch 100/100, validation error 0.940000 %</div><div class="line">training @ iter =  11700</div><div class="line">epoch 118, minibatch 100/100, validation error 0.940000 %</div><div class="line">training @ iter =  11800</div><div class="line">epoch 119, minibatch 100/100, validation error 0.940000 %</div><div class="line">training @ iter =  11900</div><div class="line">epoch 120, minibatch 100/100, validation error 0.940000 %</div><div class="line">training @ iter =  12000</div><div class="line">epoch 121, minibatch 100/100, validation error 0.940000 %</div><div class="line">training @ iter =  12100</div><div class="line">epoch 122, minibatch 100/100, validation error 0.930000 %</div><div class="line">training @ iter =  12200</div><div class="line">epoch 123, minibatch 100/100, validation error 0.930000 %</div><div class="line">training @ iter =  12300</div><div class="line">epoch 124, minibatch 100/100, validation error 0.930000 %</div><div class="line">training @ iter =  12400</div><div class="line">epoch 125, minibatch 100/100, validation error 0.930000 %</div><div class="line">training @ iter =  12500</div><div class="line">epoch 126, minibatch 100/100, validation error 0.930000 %</div><div class="line">training @ iter =  12600</div><div class="line">epoch 127, minibatch 100/100, validation error 0.930000 %</div><div class="line">training @ iter =  12700</div><div class="line">epoch 128, minibatch 100/100, validation error 0.930000 %</div><div class="line">training @ iter =  12800</div><div class="line">epoch 129, minibatch 100/100, validation error 0.940000 %</div><div class="line">training @ iter =  12900</div><div class="line">epoch 130, minibatch 100/100, validation error 0.950000 %</div><div class="line">training @ iter =  13000</div><div class="line">epoch 131, minibatch 100/100, validation error 0.950000 %</div><div class="line">training @ iter =  13100</div><div class="line">epoch 132, minibatch 100/100, validation error 0.950000 %</div><div class="line">training @ iter =  13200</div><div class="line">epoch 133, minibatch 100/100, validation error 0.950000 %</div><div class="line">training @ iter =  13300</div><div class="line">epoch 134, minibatch 100/100, validation error 0.950000 %</div><div class="line">training @ iter =  13400</div><div class="line">epoch 135, minibatch 100/100, validation error 0.950000 %</div><div class="line">training @ iter =  13500</div><div class="line">epoch 136, minibatch 100/100, validation error 0.950000 %</div><div class="line">training @ iter =  13600</div><div class="line">epoch 137, minibatch 100/100, validation error 0.950000 %</div><div class="line">training @ iter =  13700</div><div class="line">epoch 138, minibatch 100/100, validation error 0.950000 %</div><div class="line">training @ iter =  13800</div><div class="line">epoch 139, minibatch 100/100, validation error 0.950000 %</div><div class="line">training @ iter =  13900</div><div class="line">epoch 140, minibatch 100/100, validation error 0.940000 %</div><div class="line">training @ iter =  14000</div><div class="line">epoch 141, minibatch 100/100, validation error 0.940000 %</div><div class="line">training @ iter =  14100</div><div class="line">epoch 142, minibatch 100/100, validation error 0.940000 %</div><div class="line">training @ iter =  14200</div><div class="line">epoch 143, minibatch 100/100, validation error 0.940000 %</div><div class="line">training @ iter =  14300</div><div class="line">epoch 144, minibatch 100/100, validation error 0.940000 %</div><div class="line">training @ iter =  14400</div><div class="line">epoch 145, minibatch 100/100, validation error 0.940000 %</div><div class="line">training @ iter =  14500</div><div class="line">epoch 146, minibatch 100/100, validation error 0.940000 %</div><div class="line">training @ iter =  14600</div><div class="line">epoch 147, minibatch 100/100, validation error 0.940000 %</div><div class="line">training @ iter =  14700</div><div class="line">epoch 148, minibatch 100/100, validation error 0.940000 %</div><div class="line">training @ iter =  14800</div><div class="line">epoch 149, minibatch 100/100, validation error 0.940000 %</div><div class="line">training @ iter =  14900</div><div class="line">epoch 150, minibatch 100/100, validation error 0.940000 %</div><div class="line">training @ iter =  15000</div><div class="line">epoch 151, minibatch 100/100, validation error 0.940000 %</div><div class="line">training @ iter =  15100</div><div class="line">epoch 152, minibatch 100/100, validation error 0.940000 %</div><div class="line">training @ iter =  15200</div><div class="line">epoch 153, minibatch 100/100, validation error 0.940000 %</div><div class="line">training @ iter =  15300</div><div class="line">epoch 154, minibatch 100/100, validation error 0.940000 %</div><div class="line">training @ iter =  15400</div><div class="line">epoch 155, minibatch 100/100, validation error 0.940000 %</div><div class="line">training @ iter =  15500</div><div class="line">epoch 156, minibatch 100/100, validation error 0.940000 %</div><div class="line">training @ iter =  15600</div><div class="line">epoch 157, minibatch 100/100, validation error 0.930000 %</div><div class="line">training @ iter =  15700</div><div class="line">epoch 158, minibatch 100/100, validation error 0.930000 %</div><div class="line">training @ iter =  15800</div><div class="line">epoch 159, minibatch 100/100, validation error 0.930000 %</div><div class="line">training @ iter =  15900</div><div class="line">epoch 160, minibatch 100/100, validation error 0.930000 %</div><div class="line">training @ iter =  16000</div><div class="line">epoch 161, minibatch 100/100, validation error 0.920000 %</div><div class="line">     epoch 161, minibatch 100/100, test error of best model 0.930000 %</div><div class="line">training @ iter =  16100</div><div class="line">epoch 162, minibatch 100/100, validation error 0.920000 %</div><div class="line">training @ iter =  16200</div><div class="line">epoch 163, minibatch 100/100, validation error 0.920000 %</div><div class="line">training @ iter =  16300</div><div class="line">epoch 164, minibatch 100/100, validation error 0.920000 %</div><div class="line">training @ iter =  16400</div><div class="line">epoch 165, minibatch 100/100, validation error 0.920000 %</div><div class="line">training @ iter =  16500</div><div class="line">epoch 166, minibatch 100/100, validation error 0.920000 %</div><div class="line">training @ iter =  16600</div><div class="line">epoch 167, minibatch 100/100, validation error 0.920000 %</div><div class="line">training @ iter =  16700</div><div class="line">epoch 168, minibatch 100/100, validation error 0.920000 %</div><div class="line">training @ iter =  16800</div><div class="line">epoch 169, minibatch 100/100, validation error 0.920000 %</div><div class="line">training @ iter =  16900</div><div class="line">epoch 170, minibatch 100/100, validation error 0.920000 %</div><div class="line">training @ iter =  17000</div><div class="line">epoch 171, minibatch 100/100, validation error 0.920000 %</div><div class="line">training @ iter =  17100</div><div class="line">epoch 172, minibatch 100/100, validation error 0.920000 %</div><div class="line">training @ iter =  17200</div><div class="line">epoch 173, minibatch 100/100, validation error 0.920000 %</div><div class="line">training @ iter =  17300</div><div class="line">epoch 174, minibatch 100/100, validation error 0.920000 %</div><div class="line">training @ iter =  17400</div><div class="line">epoch 175, minibatch 100/100, validation error 0.920000 %</div><div class="line">training @ iter =  17500</div><div class="line">epoch 176, minibatch 100/100, validation error 0.920000 %</div><div class="line">training @ iter =  17600</div><div class="line">epoch 177, minibatch 100/100, validation error 0.920000 %</div><div class="line">training @ iter =  17700</div><div class="line">epoch 178, minibatch 100/100, validation error 0.920000 %</div><div class="line">training @ iter =  17800</div><div class="line">epoch 179, minibatch 100/100, validation error 0.920000 %</div><div class="line">training @ iter =  17900</div><div class="line">epoch 180, minibatch 100/100, validation error 0.920000 %</div><div class="line">training @ iter =  18000</div><div class="line">epoch 181, minibatch 100/100, validation error 0.920000 %</div><div class="line">training @ iter =  18100</div><div class="line">epoch 182, minibatch 100/100, validation error 0.920000 %</div><div class="line">training @ iter =  18200</div><div class="line">epoch 183, minibatch 100/100, validation error 0.910000 %</div><div class="line">     epoch 183, minibatch 100/100, test error of best model 0.920000 %</div><div class="line">training @ iter =  18300</div><div class="line">epoch 184, minibatch 100/100, validation error 0.910000 %</div><div class="line">training @ iter =  18400</div><div class="line">epoch 185, minibatch 100/100, validation error 0.910000 %</div><div class="line">training @ iter =  18500</div><div class="line">epoch 186, minibatch 100/100, validation error 0.910000 %</div><div class="line">training @ iter =  18600</div><div class="line">epoch 187, minibatch 100/100, validation error 0.910000 %</div><div class="line">training @ iter =  18700</div><div class="line">epoch 188, minibatch 100/100, validation error 0.910000 %</div><div class="line">training @ iter =  18800</div><div class="line">epoch 189, minibatch 100/100, validation error 0.910000 %</div><div class="line">training @ iter =  18900</div><div class="line">epoch 190, minibatch 100/100, validation error 0.910000 %</div><div class="line">training @ iter =  19000</div><div class="line">epoch 191, minibatch 100/100, validation error 0.910000 %</div><div class="line">training @ iter =  19100</div><div class="line">epoch 192, minibatch 100/100, validation error 0.910000 %</div><div class="line">training @ iter =  19200</div><div class="line">epoch 193, minibatch 100/100, validation error 0.910000 %</div><div class="line">training @ iter =  19300</div><div class="line">epoch 194, minibatch 100/100, validation error 0.910000 %</div><div class="line">training @ iter =  19400</div><div class="line">epoch 195, minibatch 100/100, validation error 0.910000 %</div><div class="line">training @ iter =  19500</div><div class="line">epoch 196, minibatch 100/100, validation error 0.910000 %</div><div class="line">training @ iter =  19600</div><div class="line">epoch 197, minibatch 100/100, validation error 0.910000 %</div><div class="line">training @ iter =  19700</div><div class="line">epoch 198, minibatch 100/100, validation error 0.910000 %</div><div class="line">training @ iter =  19800</div><div class="line">epoch 199, minibatch 100/100, validation error 0.910000 %</div><div class="line">training @ iter =  19900</div><div class="line">epoch 200, minibatch 100/100, validatiThe code for file convolutional_mlp.py ran for 446.13m</div><div class="line">on error 0.910000 %</div><div class="line">Optimization complete.</div><div class="line">Best validation score of 0.910000 % obtained at iteration 18300, with test performance 0.920000 %</div></pre></td></tr></table></figure>
<p>å¯ä»¥çœ‹åˆ°è¿è¡Œäº†446.13åˆ†é’Ÿï¼Œç”µè„‘æ²¡æœ‰GPUï¼Œä¸èƒ½GPUåŠ é€Ÿï¼Œ/(ã„’oã„’)/~~ã€‚æ®è¯´å¥½çš„GPUåªè¦20åˆ†é’Ÿå°±èƒ½è¿è¡Œå®Œæˆã€‚</p>
<hr>
<p><strong>å‚è€ƒ</strong></p>
<ol>
<li><a href="http://www.gageet.com/2014/0878.php#%E4%B8%80%EF%BC%9A%E5%89%8D%E5%AF%BC%C2%A0Back%C2%A0Propagation%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95" target="_blank" rel="external">Convolutional Neural Networkså·ç§¯ç¥ç»ç½‘ç»œ</a></li>
<li><a href="http://www.36dsj.com/archives/24006" target="_blank" rel="external">æŠ€æœ¯å‘ï¼šä¸€æ–‡è¯»æ‡‚å·ç§¯ç¥ç»ç½‘ç»œ</a></li>
<li><a href="http://blog.csdn.net/zouxy09/article/details/8781543/" target="_blank" rel="external">Deep Learningï¼ˆæ·±åº¦å­¦ä¹ ï¼‰å­¦ä¹ ç¬”è®°æ•´ç†ç³»åˆ—ä¹‹ï¼ˆä¸ƒï¼‰</a></li>
<li><a href="http://blog.csdn.net/niuwei22007/article/details/48950347" target="_blank" rel="external">æ·±åº¦å­¦ä¹ (DL)ä¸å·ç§¯ç¥ç»ç½‘ç»œ(CNN)å­¦ä¹ éšç¬”-05-åŸºäºPythonçš„LeNetä¹‹CNN</a></li>
</ol>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/09/15/ã€pythonæœºå™¨å­¦ä¹ ã€‘å¤šå±‚æ„ŸçŸ¥å™¨ä¸BPæ¨¡å‹/" itemprop="url">
                  ã€pythonæœºå™¨å­¦ä¹ ã€‘å¤šå±‚æ„ŸçŸ¥å™¨ä¸BPæ¨¡å‹
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">å‘è¡¨äº</span>
            <time itemprop="dateCreated" datetime="2016-09-15T21:57:54+08:00" content="2016-09-15">
              2016-09-15
            </time>
          </span>

          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/09/15/ã€pythonæœºå™¨å­¦ä¹ ã€‘å¤šå±‚æ„ŸçŸ¥å™¨ä¸BPæ¨¡å‹/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/09/15/ã€pythonæœºå™¨å­¦ä¹ ã€‘å¤šå±‚æ„ŸçŸ¥å™¨ä¸BPæ¨¡å‹/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>æœ¬æ–‡çš„å…³é”®è¯æœ‰ä¸¤ä¸ª</p>
<ul>
<li>å¤šå±‚æ„ŸçŸ¥å™¨ï¼ˆ<em>Multilayer Perceptron</em>ï¼‰</li>
<li>BPç®—æ³•ï¼ˆ<em>Back propagation algorithm</em>ï¼‰ </li>
</ul>
<p>é¦–å…ˆï¼Œè¿˜æ˜¯è¦æä¸€ä¸‹å›å½’æ¨¡å‹ï¼Œå›å½’æ¨¡å‹ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡è¾“å…¥è¾“å‡ºè®­ç»ƒå‡ºä¸€ä¸ªçº¿æ€§æˆ–éçº¿æ€§çš„å›å½’æ¨¡å‹ï¼Œç”¨å›å½’æ¨¡å‹æ¥é¢„æµ‹æ–°è¾“å…¥çš„è¾“å‡ºå€¼ã€‚é€šè¿‡è¿™ç§æ–¹æ³•æ¥åˆ›å»ºåˆ†ç±»å™¨ã€‚é€»è¾‘å›å½’æ¨¡å‹æ˜¯ä¸€ç§å•å±‚æ„ŸçŸ¥å™¨ã€‚</p>
<p>BPç®—æ³•åœ¨å›å½’æ¨¡å‹ä¸ŠåŠ å…¥äº†ä¸€ä¸ªéšå±‚çš„æ¦‚å¿µï¼Œä¹Ÿæœ‰äººç§°ä¹‹ä¸ºä¸­é—´å±‚ã€‚å«æ˜¯è¿™æ ·å«çš„ï¼Œä½†æ˜¯å…¶å®BPç®—æ³•æ˜¯ä¸€ä¸ªå¤šå±‚LRåµŒå¥—çš„æ¨¡å‹ã€‚æ ¹æ®<a href="http://www.zhihu.com/question/27823925" target="_blank" rel="external">çŸ¥ä¹è¯´æ³•</a>ï¼Œè¾“å…¥å±‚å’Œä¸­é—´é‚£äº›éšå±‚ï¼Œå¯ä»¥æŠŠå®ƒä»¬çœ‹æˆä¸€ç§ç‰¹å¾æå–çš„è¿‡ç¨‹ï¼Œå°±æ˜¯æŠŠ Logistic Regression çš„è¾“å‡ºå½“ä½œç‰¹å¾ï¼Œç„¶åå†å°†å®ƒé€å…¥ä¸‹ä¸€ä¸ª Logistic Regressionï¼Œä¸€å±‚å±‚å˜æ¢ã€‚ç¥ç»ç½‘ç»œçš„è®­ç»ƒï¼Œå®é™…ä¸Šå°±æ˜¯åŒæ—¶è®­ç»ƒç‰¹å¾æå–ç®—æ³•ä»¥åŠæœ€åçš„ Logistic Regressionçš„å‚æ•°ã€‚</p>
<p>äºæ˜¯BPç®—æ³•å°±è¢«å«åšå¤šå±‚æ„ŸçŸ¥å™¨äº†ã€‚å®ƒçš„æ‹Ÿåˆèƒ½åŠ›å¾ˆå¼ºï¼Œå¯ä»¥å¤„ç†å¾ˆå¤š Logistic Regressionå¤„ç†ä¸äº†çš„æ•°æ®ï¼Œä½†æ˜¯ä¹Ÿæ›´å®¹æ˜“è¿‡æ‹Ÿåˆã€‚è€Œä¸”æŸå¤±å‡½æ•°ä¸æ˜¯å‡¸çš„ï¼Œç»™ä¼˜åŒ–å¸¦æ¥ä¸€äº›å›°éš¾ã€‚</p>
<h1 id="æ„ŸçŸ¥å™¨å’ŒLMSç®—æ³•"><a href="#æ„ŸçŸ¥å™¨å’ŒLMSç®—æ³•" class="headerlink" title="æ„ŸçŸ¥å™¨å’ŒLMSç®—æ³•"></a>æ„ŸçŸ¥å™¨å’ŒLMSç®—æ³•</h1><p>è¯´äº†è¿™ä¹ˆé•¿æ—¶é—´çš„æ„ŸçŸ¥å™¨ï¼Œé‚£ä¹ˆä»€ä¹ˆæ˜¯æ„ŸçŸ¥å™¨ï¼Ÿ</p>
<blockquote>
<p>åœ¨ç¥ç»ç½‘ç»œä¸­ï¼Œå¯¹å¤–éƒ¨ç¯å¢ƒæä¾›çš„æ¨¡å¼æ ·æœ¬è¿›è¡Œå­¦ä¹ è®­ç»ƒï¼Œå¹¶èƒ½å­˜å‚¨è¿™ç§æ¨¡å¼ï¼Œåˆ™ç§°ä¸ºæ„ŸçŸ¥å™¨ï¼›å¯¹å¤–éƒ¨ç¯å¢ƒæœ‰é€‚åº”èƒ½åŠ›ï¼Œèƒ½è‡ªåŠ¨æå–å¤–éƒ¨ç¯å¢ƒå˜åŒ–ç‰¹å¾ï¼Œåˆ™ç§°ä¸ºè®¤çŸ¥å™¨ã€‚</p>
</blockquote>
<p>æ„æ€å°±æ˜¯è¯´æ„ŸçŸ¥å™¨æ˜¯è ¢æï¼Œè¦åˆ«äººæ•™ä»–ï¼Œä»–æ‰ä¼šåšã€‚è®¤çŸ¥å™¨æ˜¯å¤©æ‰ï¼Œç”Ÿä¸‹æ¥å°±ä¼šåšã€‚</p>
<p>æ„ŸçŸ¥å™¨åœ¨æ–¯å¦ç¦çš„ä¸­æœ‰ä¸€ä¸ªLMSï¼ˆ<em>Least mean squares</em>ï¼‰ç®—æ³•ï¼Œå®é™…ä¸Šå°±æ˜¯ä¸€ç§Logistic Regressionçš„ä¸€ç§ï¼Œä½œä¸ºå•å±‚æ„ŸçŸ¥å™¨çš„ã€‚å…¶å®é™…ä¸Šæ˜¯åŸºäºLMSçš„æ¢¯åº¦ä¸‹é™æ³•ã€‚</p>
<p><img src="http://images.cnitblog.com/blog/533521/201306/03233254-3176ade5771e42988b03c18fc7c1d331.png" alt="image"></p>
<p>$x_1,x_2$éƒ½æ˜¯å˜é‡ï¼Œé€šè¿‡å‚æ•°$\theta_0,\theta_1,\theta_2$ç¡®å®šå¾—åˆ°çš„ç»“æœã€‚</p>
<p>å…¬å¼è¡¨è¾¾ï¼š</p>
<p>$$<br>h_{\theta}=\theta^{\top}=\theta_0+\theta_1x_1+\theta_2x_2<br>$$</p>
<p>æˆ‘ä»¬å®šä¹‰æŸå¤±å‡½æ•°$J(\theta)$æ˜¯è¿™æ ·ä¸€ä¸ªäºŒä¹˜çš„å½¢å¼</p>
<p>$$<br>J(\theta)=\frac{1}{2}\sum^m_{i=1}(h_{\theta}(x^{(i)})-y^{(i)})^2<br>$$</p>
<p>ç±»ä¼¼å‰é¢çš„LRï¼Œæˆ‘ä»¬è¦æ±‚$J(\theta)$æœ€å°æ—¶çš„$\theta$ï¼Œè¿™é‡Œæˆ‘ä»¬ä½¿ç”¨äº†æ¢¯åº¦ä¸‹é™æ³•ã€‚</p>
<p>é¦–å…ˆæˆ‘ä»¬éœ€è¦çŒœä¸€ä¸‹ä¸€ä¸ªåˆå§‹çš„$\theta$ï¼Œç„¶åé€šè¿‡å¯»æ‰¾å±€éƒ¨æ¢¯åº¦ä¸‹é™æœ€å¿«çš„æ—¶å€™æ¥æ›´æ–°$\theta$ï¼Œä»è€Œè¿›ä¸€æ­¥æ¢¯åº¦ä¸‹é™ï¼Œç›´åˆ°é™åˆ°ä¸èƒ½ç»§ç»­é™ä½ä¸ºæ­¢ã€‚$\theta$æ›´æ–°çš„å…¬å¼å¦‚ä¸‹</p>
<p>$$<br>\theta_j:=\theta_j-\alpha\frac{\partial}{\partial\theta_j}J(\theta)<br>$$</p>
<p>å…¶ä¸­$\alpha$æ˜¯å­¦ä¹ ç‡ï¼Œ$\frac{\partial}{\partial\theta_j}J(\theta)$è®¡ç®—å¾—åˆ°</p>
<p>$$<br>\frac{\partial}{\partial\theta_j}J(\theta)=(h_{\theta}(x)-y)x_j<br>$$</p>
<p>æ‰€ä»¥æœ€åæˆ‘ä»¬åªè¦å¯¹ç»“æœä¸æ–­æ›´æ–°å‚æ•°ï¼Œç›´åˆ°ä¸€å®šæ¡ä»¶ï¼Œå³å¯å¾—åˆ°æ­¤æ—¶çš„$h_{\theta}(x)$ã€‚</p>
<h1 id="MLPçš„pythonå®ç°"><a href="#MLPçš„pythonå®ç°" class="headerlink" title="MLPçš„pythonå®ç°"></a>MLPçš„pythonå®ç°</h1><p>BPç®—æ³•åœ¨Logistic Regressionç®—æ³•ä¸­åŠ å…¥äº†éšå±‚ï¼Œè¿™ä¸ªä¸­é—´å±‚è¦æ±‚æ˜¯éçº¿æ€§çš„ä¸€ä¸ªfunctionï¼Œä¸€èˆ¬ä½¿ç”¨<em>tanh</em>å‡½æ•°$tanh(a)=\frac{e^a-e^{-a}}{e^a+e^{-a}}$ï¼Œæˆ–è€…<em>sigmoid</em>å‡½æ•°ï¼Œ$sigmoid(a)=\frac{1}{1+e^{-a}}$ã€‚</p>
<p>MLPæ¨¡å‹å¦‚ä¸‹</p>
<p><img src="http://deeplearning.net/tutorial/_images/mlp.png" alt="image"></p>
<p>å‡è®¾xä¸ºè¾“å…¥å‘é‡ï¼Œ$f(x)$æ˜¯è¾“å‡ºå‘é‡ï¼Œæœ‰</p>
<p>$$<br>f(x)=G(b^{(2)}+W^{(2)}(s(b^{(1)}+W^{(1)}x)))<br>$$</p>
<p>å¯¹äºè¿™ä¸ªå¼å­å¯ä»¥æ‹†è§£å¼€æ¥ï¼Œé¦–å…ˆå¦$h(x)=\phi(x)=s(b^{(1)}+W^{(1)}x)$ï¼Œè¿™ä»£è¡¨äº†ä»input layeråˆ°hidden layerçš„è¿ç®—ï¼Œè€Œå…¶ä¸­çš„$W^{(1)}x)$å’Œ$b^{(1)}$ä»£è¡¨è¿™ä¸€è¿‡ç¨‹çš„æƒé‡çŸ©é˜µå’Œåç½®å‘é‡ï¼Œ$W^{(1)}x)$çš„æ¯ä¸€åˆ—éƒ½ä»£è¡¨äº†ä»è¾“å…¥å‘é‡xåˆ°è¾¾æ¯ä¸€ä¸ªç¥ç»å…ƒçš„æƒé‡ã€‚</p>
<p>è¿™é‡Œçš„så°±æ˜¯æˆ‘ä»¬éœ€è¦çš„ä»input layeråˆ°hidden layerçš„é¢„å¤„ç†çš„è¿‡ç¨‹ï¼Œæˆ‘ä»¬ä½¿ç”¨<em>tanh</em>å‡½æ•°ã€‚æˆ‘ä»¬ç›´åˆ°tanhå‡½æ•°çš„å€¼ä»-1åˆ°1ä¹‹é—´çš„så‹å˜åŒ–ã€‚</p>
<p>äºæ˜¯ä¸Šå¼å˜ä¸º</p>
<p>$$<br>f(x)=G(b^{(2)}+W^{(2)}h(x))<br>$$</p>
<p>è¿™ä¸ªå½¢å¼å’Œæˆ‘ä»¬ä¹‹å‰çš„Logistic Regressionååˆ†ç±»ä¼¼ï¼Œä¹‹å‰æœ‰<br>$$<br>P(Y=i|x,W,b)=softmax_i(Wx+b)<br>$$</p>
<p>æ‰€ä»¥æˆ‘ä»¬è¿™é‡Œä¹Ÿé€‰æ‹©Gå‡½æ•°ä¸ºsoftmaxå‡½æ•°ï¼Œå…³äºsoftmaxå›å½’ï¼Œstandordæœ‰ä¸€ä¸ªä¸“é—¨çš„<a href="http://deeplearning.stanford.edu/wiki/index.php/Softmax%E5%9B%9E%E5%BD%92" target="_blank" rel="external">è®²è§£</a>ï¼Œå¯¹äºåˆå­¦è€…åªè¦äº†è§£softmaxçš„åŠŸèƒ½æ˜¯logisticçš„æ‹“å±•ï¼Œlogisticæ˜¯äºŒæ ‡ç­¾åˆ†ç±»ï¼Œè¾“å‡ºå€¼0æˆ–1ï¼›softmaxæ˜¯å¤šæ ‡ç­¾åˆ†ç±»ï¼Œè¾“å‡ºå€¼0-1ä¹‹é—´ï¼Œå¯ä»¥çœ‹æˆæ˜¯å±äºæŸä¸ªæ ‡ç­¾çš„æ¦‚ç‡ã€‚ä¸€èˆ¬æ˜¯ä¸¤çº§åˆ†åŒ–çš„ã€‚</p>
<p>æˆ‘ä»¬åœ¨è¿™é‡Œæ±‚å‚æ•°ä½¿ç”¨MSGDæ–¹æ³•ï¼Œå’Œä¹‹å‰çš„LRç”¨åŒæ ·çš„æ–¹æ³•ã€‚ä¸è¿‡LRæ±‚çš„å‚æ•°æ˜¯$\theta={W,b}$ï¼Œè€ŒMLPæ˜¯$\theta={W^{(2)},b^{(2)},W^{(1)},b^{(1)}}$ã€‚</p>
<p>BPç®—æ³•æˆ‘ä»¬åœ¨æ±‚æ¢¯åº¦çš„æ—¶å€™æ˜¯é“¾å¼æ±‚åå¯¼ã€‚ä¸è¿‡åœ¨pythonè¿™äº›éƒ½æ˜¯é›†æˆå¥½çš„ã€‚</p>
<h2 id="å®šä¹‰éšå±‚class"><a href="#å®šä¹‰éšå±‚class" class="headerlink" title="å®šä¹‰éšå±‚class"></a>å®šä¹‰éšå±‚class</h2><p>ç±»ä¼¼LRä¸­çš„å®šä¹‰LRClassï¼Œé¦–å…ˆè¦è¿›è¡Œåˆå§‹åŒ–ï¼Œå…¶åˆå§‹åŒ–æ³¨æ„å‡ ä¸ªå‚æ•°</p>
<ul>
<li>rngï¼šnumpyæ–¹æ³•ï¼Œç”¨æ¥ç”Ÿæˆä¸€ä¸ªéšæœºæ•°æ¥åˆå§‹åŒ–æƒé‡çŸ©é˜µ</li>
<li>n_inï¼šè¾“å…¥çŸ©é˜µçš„ç»´åº¦</li>
<li>n_outï¼šéšå±‚çš„ç¥ç»å…ƒä¸ªæ•°</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">HiddenLayer</span><span class="params">(object)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, rng, input, n_in, n_out, W=None, b=None,</span></span></div><div class="line">                 activation=T.tanh):</div><div class="line">        self.input = input</div><div class="line">        </div><div class="line">        <span class="comment"># è‹¥Wä¸ºç©ºï¼Œåˆ™ç”¨rngå¯¹å…¶åˆå§‹åŒ–</span></div><div class="line">        <span class="keyword">if</span> W <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">            W_values = numpy.asarray(</div><div class="line">                rng.uniform(</div><div class="line">                    low=-numpy.sqrt(<span class="number">6.</span> / (n_in + n_out)),</div><div class="line">                    high=numpy.sqrt(<span class="number">6.</span> / (n_in + n_out)),</div><div class="line">                    size=(n_in, n_out)</div><div class="line">                ),</div><div class="line">                dtype=theano.config.floatX</div><div class="line">            )</div><div class="line">            <span class="keyword">if</span> activation == theano.tensor.nnet.sigmoid:</div><div class="line">                W_values *= <span class="number">4</span></div><div class="line"></div><div class="line">            W = theano.shared(value=W_values, name=<span class="string">'W'</span>, borrow=<span class="keyword">True</span>)</div><div class="line"></div><div class="line">        <span class="comment"># è‹¥bä¸ºç©ºï¼Œåˆ›å»ºä¸€ä¸ªéšå±‚ç¥ç»å…ƒä¸ªæ•°çš„0å‘é‡ï¼ˆæ•°ç»„ï¼‰</span></div><div class="line">        <span class="keyword">if</span> b <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">            b_values = numpy.zeros((n_out,), dtype=theano.config.floatX)</div><div class="line">            b = theano.shared(value=b_values, name=<span class="string">'b'</span>, borrow=<span class="keyword">True</span>)</div><div class="line"></div><div class="line">        self.W = W</div><div class="line">        self.b = b</div><div class="line">        </div><div class="line">        lin_output = T.dot(input, self.W) + self.b</div><div class="line">        self.output = (</div><div class="line">            lin_output <span class="keyword">if</span> activation <span class="keyword">is</span> <span class="keyword">None</span></div><div class="line">            <span class="keyword">else</span> activation(lin_output)</div><div class="line">        )</div></pre></td></tr></table></figure>
<p>æˆ‘ä»¬çŸ¥é“éšå±‚HiddenLayeræ˜¯æ¨¡æ‹Ÿ$h(x)=\phi(x)=s(b^{(1)}+W^{(1)}x)$ï¼Œè€Œæ¢¯åº¦ä¸‹é™çš„å‰æéœ€è¦æœ‰ä¸€ä¸ªåˆå€¼ã€‚æˆ‘ä»¬ç”¨numpyäº§ç”Ÿéšæœºæ•°æ¨¡å—çš„uniformç”Ÿæˆä¸€ä¸ª<code>n_inÃ—n_out</code>å¤§å°çš„éšæœºçŸ©é˜µï¼Œå…¶æ‰€æœ‰çš„å…ƒç´ éƒ½åœ¨$[-\sqrt{\frac{6}{n_in+n_out}},\sqrt{\frac{6}{n_in+n_out}}]$ä¹‹é—´ã€‚è‹¥bä¸ºç©ºï¼Œåˆ™ç”Ÿæˆä¸€ä¸ª<code>n_out</code>å¤§å°çš„0å‘é‡ã€‚</p>
<p>å®Œæˆäº†è¿™äº›ï¼Œå®é™…ä¸Šä½ åªè¦æŠŠHiddenLayerçš„è¾“å‡ºæ”¾å…¥ä¹‹å‰çš„LogisticRegressionçš„è¾“å…¥ï¼Œå°±æˆäº†MLPã€‚ä½†æˆ‘ä»¬è¿˜æ˜¯è¦å®šä¹‰ä¸€ä¸‹MLP Classã€‚</p>
<h2 id="å®šä¹‰MLP-Class"><a href="#å®šä¹‰MLP-Class" class="headerlink" title="å®šä¹‰MLP Class"></a>å®šä¹‰MLP Class</h2><p>MLP Classå…±å®šä¹‰äº†ä¸¤ä¸ªéƒ¨åˆ†</p>
<h3 id="åˆå§‹åŒ–"><a href="#åˆå§‹åŒ–" class="headerlink" title="åˆå§‹åŒ–"></a>åˆå§‹åŒ–</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">MLP</span><span class="params">(object)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, rng, input, n_in, n_hidden, n_out)</span>:</span></div><div class="line">        self.hiddenLayer = HiddenLayer(</div><div class="line">            rng=rng,</div><div class="line">            input=input,</div><div class="line">            n_in=n_in,</div><div class="line">            n_out=n_hidden,</div><div class="line">            activation=T.tanh</div><div class="line">        )</div><div class="line"></div><div class="line">        self.logRegressionLayer = LogisticRegression(</div><div class="line">            input=self.hiddenLayer.output,</div><div class="line">            n_in=n_hidden,</div><div class="line">            n_out=n_out</div><div class="line">        )</div><div class="line">        </div><div class="line">        self.L1 = (</div><div class="line">            abs(self.hiddenLayer.W).sum()</div><div class="line">            + abs(self.logRegressionLayer.W).sum()</div><div class="line">        )</div><div class="line"></div><div class="line">        self.L2_sqr = (</div><div class="line">            (self.hiddenLayer.W ** <span class="number">2</span>).sum()</div><div class="line">            + (self.logRegressionLayer.W ** <span class="number">2</span>).sum()</div><div class="line">        )</div><div class="line"></div><div class="line">        self.negative_log_likelihood = (</div><div class="line">            self.logRegressionLayer.negative_log_likelihood</div><div class="line">        )</div><div class="line"></div><div class="line">        self.errors = self.logRegressionLayer.errors</div><div class="line"></div><div class="line">        self.params = self.hiddenLayer.params + self.logRegressionLayer.params</div><div class="line">        </div><div class="line">        self.input = input</div></pre></td></tr></table></figure>
<p>åˆå§‹åŒ–ä¸­çš„å‚æ•°</p>
<ul>
<li>n_inï¼šinput layerä¸­ç¥ç»å…ƒä¸ªæ•°ï¼ˆæˆ–è¾“å…¥å‚æ•°ä¸ªæ•°ï¼‰</li>
<li>n_hiddenï¼šå‚æ•°è¡¨ç¤ºçš„æ˜¯éšå±‚çš„ç¥ç»å…ƒæ•°ç›®</li>
<li>n_outï¼šè¾“å‡ºå±‚ä¸­ç¥ç»å…ƒä¸ªæ•°ï¼Œä¹Ÿè¡¨ç¤ºæ ‡ç­¾ç©ºé—´ç»´åº¦</li>
</ul>
<p>é¦–å…ˆè°ƒç”¨äº†HiddenLayerå’ŒLogisticRegressionä¸¤ä¸ªæ¨¡å—ã€‚</p>
<p>æ¥ç€ï¼Œå®šä¹‰äº†$L_1$èŒƒæ•°å’Œ$L_2$èŒƒæ•°å¼€æ–¹,å…¶ä½™éƒ½å’ŒLogisticRegressionçš„æ–¹æ³•å·®ä¸å¤šï¼Œæ³¨æ„paramï¼ˆ$\theta$ï¼‰æ˜¯ä»¥å‰çš„ä¸¤å€é•¿åº¦ï¼Œå› ä¸ºå¤šäº†ä¸€å±‚ã€‚</p>
<h3 id="MLPæµ‹è¯•"><a href="#MLPæµ‹è¯•" class="headerlink" title="MLPæµ‹è¯•"></a>MLPæµ‹è¯•</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_mlp</span><span class="params">(learning_rate=<span class="number">0.01</span>, L1_reg=<span class="number">0.00</span>, L2_reg=<span class="number">0.0001</span>, n_epochs=<span class="number">1000</span>,</span></span></div><div class="line">             dataset=<span class="string">'mnist.pkl.gz'</span>, batch_size=<span class="number">20</span>, n_hidden=<span class="number">500</span>):</div><div class="line">    </div><div class="line">    datasets = load_data(dataset)</div><div class="line"></div><div class="line">    train_set_x, train_set_y = datasets[<span class="number">0</span>]</div><div class="line">    valid_set_x, valid_set_y = datasets[<span class="number">1</span>]</div><div class="line">    test_set_x, test_set_y = datasets[<span class="number">2</span>]</div><div class="line"></div><div class="line">    n_train_batches = train_set_x.get_value(borrow=<span class="keyword">True</span>).shape[<span class="number">0</span>] // batch_size</div><div class="line">    n_valid_batches = valid_set_x.get_value(borrow=<span class="keyword">True</span>).shape[<span class="number">0</span>] // batch_size</div><div class="line">    n_test_batches = test_set_x.get_value(borrow=<span class="keyword">True</span>).shape[<span class="number">0</span>] // batch_size</div><div class="line"></div><div class="line">    print(<span class="string">'... building the model'</span>)</div><div class="line"></div><div class="line">    index = T.lscalar()  <span class="comment"># index to a [mini]batch</span></div><div class="line">    x = T.matrix(<span class="string">'x'</span>)  <span class="comment"># the data is presented as rasterized images</span></div><div class="line">    y = T.ivector(<span class="string">'y'</span>)  <span class="comment"># the labels are presented as 1D vector of</span></div><div class="line">                        <span class="comment"># [int] labels</span></div><div class="line"></div><div class="line">    rng = numpy.random.RandomState(<span class="number">1234</span>)</div><div class="line"></div><div class="line">    classifier = MLP(</div><div class="line">        rng=rng,</div><div class="line">        input=x,</div><div class="line">        n_in=<span class="number">28</span> * <span class="number">28</span>,</div><div class="line">        n_hidden=n_hidden,</div><div class="line">        n_out=<span class="number">10</span></div><div class="line">    )</div><div class="line"></div><div class="line">    cost = (</div><div class="line">        classifier.negative_log_likelihood(y)</div><div class="line">        + L1_reg * classifier.L1</div><div class="line">        + L2_reg * classifier.L2_sqr</div><div class="line">    )</div><div class="line"></div><div class="line">    test_model = theano.function(</div><div class="line">        inputs=[index],</div><div class="line">        outputs=classifier.errors(y),</div><div class="line">        givens=&#123;</div><div class="line">            x: test_set_x[index * batch_size:(index + <span class="number">1</span>) * batch_size],</div><div class="line">            y: test_set_y[index * batch_size:(index + <span class="number">1</span>) * batch_size]</div><div class="line">        &#125;</div><div class="line">    )</div><div class="line"></div><div class="line">    validate_model = theano.function(</div><div class="line">        inputs=[index],</div><div class="line">        outputs=classifier.errors(y),</div><div class="line">        givens=&#123;</div><div class="line">            x: valid_set_x[index * batch_size:(index + <span class="number">1</span>) * batch_size],</div><div class="line">            y: valid_set_y[index * batch_size:(index + <span class="number">1</span>) * batch_size]</div><div class="line">        &#125;</div><div class="line">    )</div><div class="line"></div><div class="line">    gparams = [T.grad(cost, param) <span class="keyword">for</span> param <span class="keyword">in</span> classifier.params]</div><div class="line"></div><div class="line">    updates = [</div><div class="line">        (param, param - learning_rate * gparam)</div><div class="line">        <span class="keyword">for</span> param, gparam <span class="keyword">in</span> zip(classifier.params, gparams)</div><div class="line">    ]</div><div class="line"></div><div class="line">    train_model = theano.function(</div><div class="line">        inputs=[index],</div><div class="line">        outputs=cost,</div><div class="line">        updates=updates,</div><div class="line">        givens=&#123;</div><div class="line">            x: train_set_x[index * batch_size: (index + <span class="number">1</span>) * batch_size],</div><div class="line">            y: train_set_y[index * batch_size: (index + <span class="number">1</span>) * batch_size]</div><div class="line">        &#125;</div><div class="line">    )</div><div class="line">    </div><div class="line">    print(<span class="string">'... training'</span>)</div><div class="line"></div><div class="line">    patience = <span class="number">10000</span>  <span class="comment"># look as this many examples regardless</span></div><div class="line">    patience_increase = <span class="number">2</span>  <span class="comment"># wait this much longer when a new best is</span></div><div class="line">                           <span class="comment"># found</span></div><div class="line">    improvement_threshold = <span class="number">0.995</span>  <span class="comment"># a relative improvement of this much is</span></div><div class="line">                                   <span class="comment"># considered significant</span></div><div class="line">    validation_frequency = min(n_train_batches, patience // <span class="number">2</span>)</div><div class="line">                                  <span class="comment"># go through this many</span></div><div class="line">                                  <span class="comment"># minibatche before checking the network</span></div><div class="line">                                  <span class="comment"># on the validation set; in this case we</span></div><div class="line">                                  <span class="comment"># check every epoch</span></div><div class="line"></div><div class="line">    best_validation_loss = numpy.inf</div><div class="line">    best_iter = <span class="number">0</span></div><div class="line">    test_score = <span class="number">0.</span></div><div class="line">    start_time = timeit.default_timer()</div><div class="line"></div><div class="line">    epoch = <span class="number">0</span></div><div class="line">    done_looping = <span class="keyword">False</span></div><div class="line"></div><div class="line">    <span class="keyword">while</span> (epoch &lt; n_epochs) <span class="keyword">and</span> (<span class="keyword">not</span> done_looping):</div><div class="line">        epoch = epoch + <span class="number">1</span></div><div class="line">        <span class="keyword">for</span> minibatch_index <span class="keyword">in</span> range(n_train_batches):</div><div class="line"></div><div class="line">            minibatch_avg_cost = train_model(minibatch_index)</div><div class="line">            <span class="comment"># iteration number</span></div><div class="line">            iter = (epoch - <span class="number">1</span>) * n_train_batches + minibatch_index</div><div class="line"></div><div class="line">            <span class="keyword">if</span> (iter + <span class="number">1</span>) % validation_frequency == <span class="number">0</span>:</div><div class="line">                <span class="comment"># compute zero-one loss on validation set</span></div><div class="line">                validation_losses = [validate_model(i) <span class="keyword">for</span> i</div><div class="line">                                     <span class="keyword">in</span> range(n_valid_batches)]</div><div class="line">                this_validation_loss = numpy.mean(validation_losses)</div><div class="line"></div><div class="line">                print(</div><div class="line">                    <span class="string">'epoch %i, minibatch %i/%i, validation error %f %%'</span> %</div><div class="line">                    (</div><div class="line">                        epoch,</div><div class="line">                        minibatch_index + <span class="number">1</span>,</div><div class="line">                        n_train_batches,</div><div class="line">                        this_validation_loss * <span class="number">100.</span></div><div class="line">                    )</div><div class="line">                )</div><div class="line"></div><div class="line">                <span class="comment"># if we got the best validation score until now</span></div><div class="line">                <span class="keyword">if</span> this_validation_loss &lt; best_validation_loss:</div><div class="line">                    <span class="comment">#improve patience if loss improvement is good enough</span></div><div class="line">                    <span class="keyword">if</span> (</div><div class="line">                        this_validation_loss &lt; best_validation_loss *</div><div class="line">                        improvement_threshold</div><div class="line">                    ):</div><div class="line">                        patience = max(patience, iter * patience_increase)</div><div class="line"></div><div class="line">                    best_validation_loss = this_validation_loss</div><div class="line">                    best_iter = iter</div><div class="line"></div><div class="line">                    <span class="comment"># test it on the test set</span></div><div class="line">                    test_losses = [test_model(i) <span class="keyword">for</span> i</div><div class="line">                                   <span class="keyword">in</span> range(n_test_batches)]</div><div class="line">                    test_score = numpy.mean(test_losses)</div><div class="line"></div><div class="line">                    print((<span class="string">'     epoch %i, minibatch %i/%i, test error of '</span></div><div class="line">                           <span class="string">'best model %f %%'</span>) %</div><div class="line">                          (epoch, minibatch_index + <span class="number">1</span>, n_train_batches,</div><div class="line">                           test_score * <span class="number">100.</span>))</div><div class="line"></div><div class="line">            <span class="keyword">if</span> patience &lt;= iter:</div><div class="line">                done_looping = <span class="keyword">True</span></div><div class="line">                <span class="keyword">break</span></div><div class="line"></div><div class="line">    end_time = timeit.default_timer()</div><div class="line">    print((<span class="string">'Optimization complete. Best validation score of %f %% '</span></div><div class="line">           <span class="string">'obtained at iteration %i, with test performance %f %%'</span>) %</div><div class="line">          (best_validation_loss * <span class="number">100.</span>, best_iter + <span class="number">1</span>, test_score * <span class="number">100.</span>))</div><div class="line">    print((<span class="string">'The code for file '</span> +</div><div class="line">           os.path.split(__file__)[<span class="number">1</span>] +</div><div class="line">           <span class="string">' ran for %.2fm'</span> % ((end_time - start_time) / <span class="number">60.</span>)), file=sys.stderr)</div></pre></td></tr></table></figure>
<p>MLPæµ‹è¯•çš„å‡½æ•°test_mlpï¼Œåˆå§‹å‡½æ•°è¾“å…¥åŒ…æ‹¬å¦‚ä¸‹å‡ ä¸ª</p>
<ul>
<li>learning_rate=0.01ï¼šå­¦ä¹ ç‡</li>
<li>L1_reg=0.00ï¼šæŸå¤±å‡½æ•°ä¸­$L_1$èŒƒæ•°çš„æƒé‡</li>
<li>L2_reg=0.0001ï¼šæŸå¤±å‡½æ•°ä¸­$L_2$èŒƒæ•°çš„æƒé‡</li>
<li>n_epochs=1000ï¼šä¼˜åŒ–çš„æœ€å¤§è®¡ç®—æ¬¡æ•°</li>
<li>dataset=â€™mnist.pkl.gzâ€™ï¼šMINISTæ•°æ®é›†</li>
<li>batch_size=20ï¼šæ¯ä¸ªbatchçš„å¤§å°</li>
<li>n_hidden=500ï¼šéšå±‚ç¥ç»å…ƒä¸ªæ•°</li>
</ul>
<p>æ¥ä¸‹æ¥åŠ è½½æ•°æ®é›†å’ŒLRä¸­çš„æ˜¯ä¸€æ ·çš„ã€‚</p>
<p>æ³¨æ„rngéšæœºæ•°çš„äº§ç”Ÿæ–¹å¼ï¼š<code>rng = numpy.random.RandomState(1234)</code>ã€‚</p>
<p>åˆ†ç±»å™¨classifierå®šä¹‰ä¸ºMLPç±»ï¼Œè¾“å…¥ä¸º28*28çš„å›¾åƒï¼Œè¾“å‡ºæ˜¯10ä¸ªyã€‚</p>
<p>å…¶å‚æ•°æ›´æ–°æ˜¯</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">gparams = [T.grad(cost, param) <span class="keyword">for</span> param <span class="keyword">in</span> classifier.params]</div><div class="line">updates = [</div><div class="line">    (param, param - learning_rate * gparam)</div><div class="line">    <span class="keyword">for</span> param, gparam <span class="keyword">in</span> zip(classifier.params, gparams)</div><div class="line">]</div></pre></td></tr></table></figure>
<p>è¿˜è®°å¾—LMSé‡Œé¢çš„æ›´æ–°å…¬å¼$\theta_j:=\theta_j-\alpha\frac{\partial}{\partial\theta_j}J(\theta)$ï¼Œæœ€ç»ˆæƒ³è¦è¡¨è¾¾çš„å°±æ˜¯è¿™ä¸ªæ„æ€ã€‚</p>
<p>æ¥ä¸‹æ¥ï¼Œè¿›è¡Œè®­ç»ƒï¼Œä»£ç æ ¹æ®æœºå™¨ä¸åŒï¼Œè¿è¡Œæ—¶é—´ä¸ä¸€ï¼Œæœ¬äººæœºå™¨è¾ƒå·®ï¼Œæ¯è¿è¡Œä¸€ä¸ªbatchçº¦è¦15minï¼Œå¤§çº¦å…±éœ€è¦è¦åå‡ ä¸ªå°æ—¶ã€‚</p>
<p>å¼•ç”¨æ•™ç¨‹ä¸­çš„è¿è¡Œç»“æœ</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Optimization complete. Best validation score of 1.690000 % obtained at iteration 2070000, with test performance 1.650000 %</div><div class="line">The code for file mlp.py ran for 97.34m</div></pre></td></tr></table></figure>
<h1 id="æœ€å"><a href="#æœ€å" class="headerlink" title="æœ€å"></a>æœ€å</h1><p>ä½¿ç”¨ä¸Šé¢çš„ä»£ç ï¼Œè¯´å®è¯å¾ˆéš¾æ±‚å‡ºæœ€åçš„è¶…å‚ï¼Œæ‰¾åˆ°ä¸€ä¸ªæœ€ä¼˜çš„å‚æ•°ä¸å¤ªè¡Œå¾—é€šã€‚æœ‰äº›å‚æ•°æ˜¯ç¦»æ•£å€¼ï¼Œæœ‰äº›ç¡®å®å®æ•°ã€‚è¿˜æœ‰è¿™ä¸ªä¼˜åŒ–é—®é¢˜æ˜¯éå‡¸çš„ï¼Œè¿™ç»™è®¡ç®—å¸¦æ¥äº†å¾ˆå¤§å›°éš¾ã€‚ä½†æ˜¯ç§‘å­¦å®¶è¿˜æ˜¯æ‰¾åˆ°äº†å¾ˆå¤šè§£å†³ä¹‹é“ã€‚</p>
<hr>
<p><strong>å‚è€ƒ</strong></p>
<ol>
<li>åºæ™¶, ä¹”æ´ªå®¾. ç¥ç»ç½‘ç»œBPç®—æ³•ä¸å›å½’åˆ†æç®—æ³•è¿›è¡Œç»Ÿè®¡é¢„æµ‹çš„æ¯”è¾ƒç ”ç©¶[J]. å†…è’™å¤å·¥ä¸šå¤§å­¦å­¦æŠ¥:ç¤¾ä¼šç§‘å­¦ç‰ˆ, 1998(1):83-88.</li>
<li>Standford ML Lectureï¼Œ<a href="http://cs229.stanford.edu/notes/cs229-notes1.pdf" target="_blank" rel="external">cs229-notes1</a></li>
</ol>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/09/14/ã€pythonæœºå™¨å­¦ä¹ ã€‘ç”¨é€»è¾‘å›å½’åˆ†ææ¥åˆ†ç±»MINISTæ•°æ®é›†/" itemprop="url">
                  ã€pythonæœºå™¨å­¦ä¹ ã€‘ç”¨é€»è¾‘å›å½’åˆ†ææ¥åˆ†ç±»MINISTæ•°æ®é›†
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">å‘è¡¨äº</span>
            <time itemprop="dateCreated" datetime="2016-09-14T22:40:23+08:00" content="2016-09-14">
              2016-09-14
            </time>
          </span>

          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/09/14/ã€pythonæœºå™¨å­¦ä¹ ã€‘ç”¨é€»è¾‘å›å½’åˆ†ææ¥åˆ†ç±»MINISTæ•°æ®é›†/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/09/14/ã€pythonæœºå™¨å­¦ä¹ ã€‘ç”¨é€»è¾‘å›å½’åˆ†ææ¥åˆ†ç±»MINISTæ•°æ®é›†/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>åˆšå­¦ä¹ äº†Theanoçš„ä¸€äº›ç”¨æ³•ï¼Œç°åœ¨æ¥å®ç°ä¸€ä¸ªæœ€åŸºç¡€çš„åˆ†ç±»å™¨ï¼šé€»è¾‘å›å½’ã€‚</p>
<h1 id="Logistic-regression"><a href="#Logistic-regression" class="headerlink" title="Logistic regression"></a>Logistic regression</h1><p>é¦–å…ˆï¼Œä»€ä¹ˆæ˜¯é€»è¾‘å›å½’ï¼ˆ<em>Logistic regression</em>ï¼‰ï¼Ÿ</p>
<p>é€»è¾‘å›å½’æ˜¯ä¸€ä¸ªæ¦‚ç‡çš„ï¼Œçº¿æ€§åˆ†ç±»å™¨ã€‚å…¶ç”±ä¸€ä¸ªæƒé‡çŸ©é˜µ<strong>W</strong>å’Œä¸€ä¸ªåç¦»å‘é‡bä½œä¸ºå‚æ•°æ„æˆã€‚åˆ†ç±»çš„åŸç†æ˜¯è¿™æ ·çš„ï¼Œä¸€ä¸ªè¾“å…¥å‘é‡ï¼Œè®¡ç®—å…¶å’Œè®¸å¤šè¶…å¹³é¢çš„è·ç¦»ã€‚è·ç¦»è¶ŠçŸ­ï¼Œå±äºè¶…å¹³é¢å¯¹åº”çš„åˆ†ç±»å°±è¶Šæœ‰å¯èƒ½ã€‚</p>
<p>è¿™ä¸ªå¯èƒ½æ€§å°±å†™æˆè¿™æ ·</p>
<p>$$<br>P(Y=i|x,W,b)=softmax_i(Wx+b)<br>=\frac{e^{W_{ix}+b_i}}{\sum_je^{W_{jx}+b_j}}<br>$$<br>å…¶ä¸­ï¼ŒPä»£è¡¨æ¦‚ç‡ï¼Œxæ˜¯è¾“å…¥å‘é‡ï¼Œiæ˜¯ä¸€ä¸ªåˆ†ç±»ï¼ŒYæ˜¯éšæœºå˜é‡ã€‚æ‰€ä»¥åœ¨Wï¼Œbæ¡ä»¶ä¸‹ï¼Œxå±äºiä¸€ç±»çš„æ¦‚ç‡å¯ä»¥è¿™æ ·è¡¨è¾¾ã€‚</p>
<p>æˆ‘ä»¬ç”¨$y_{pred}$æ¥è¡¨ç¤ºæ¦‚ç‡æœ€å¤§æ—¶çš„é¢„æµ‹ç»“æœã€‚å³<br>$$<br>y_{pred}=argmax_iP(Y=i|x,W,b)<br>$$</p>
<p>ç”¨pythonè¡¨ç¤ºä¸Šè¿°å¼å­</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">self.W = theano.shared(</div><div class="line">    value=numpy.zeros(</div><div class="line">        (n_in, n_out),</div><div class="line">        dtype=theano.config.floatX</div><div class="line">    ),</div><div class="line">    name=<span class="string">'W'</span>,</div><div class="line">    borrow=<span class="keyword">True</span></div><div class="line">)</div><div class="line"></div><div class="line">self.b = theano.shared(</div><div class="line">    value=numpy.zeros(</div><div class="line">        (n_out,),</div><div class="line">        dtype=theano.config.floatX</div><div class="line">    ),</div><div class="line">    name=<span class="string">'b'</span>,</div><div class="line">    borrow=<span class="keyword">True</span></div><div class="line">)</div><div class="line"></div><div class="line">self.p_y_given_x = T.nnet.softmax(T.dot(input, self.W) + self.b)</div><div class="line"></div><div class="line">self.y_pred = T.argmax(self.p_y_given_x, axis=<span class="number">1</span>)</div></pre></td></tr></table></figure>
<p>å¦‚æœè®¾ç½®borrow=Falseï¼Œè¿™è¡¨ç¤ºåœ¨ä½¿ç”¨å˜é‡çš„è¿‡ç¨‹ä¸­å°†æ˜¯æ·±æ‹·è´ï¼Œå¯¹æ•°æ®çš„ä»»ä½•æ”¹å˜ä¸ä¼šå½±å“åˆ°åŸå§‹çš„å˜é‡ï¼Œé€šè¿‡æ§åˆ¶è¯¥å‚æ•°å¯ä»¥å®ç°ä¸åŒå‡½æ•°ä¹‹é—´å¯¹å˜é‡çš„å…±äº«ã€‚</p>
<h1 id="å®šä¹‰æŸå¤±å‡½æ•°"><a href="#å®šä¹‰æŸå¤±å‡½æ•°" class="headerlink" title="å®šä¹‰æŸå¤±å‡½æ•°"></a>å®šä¹‰æŸå¤±å‡½æ•°</h1><p>åœ¨é€»è¾‘å›å½’çš„æ¨¡å‹ä¸­ï¼Œæˆ‘ä»¬çŸ¥é“éœ€è¦æ±‚è§£çš„å‚æ•°æ˜¯æƒé‡çŸ©é˜µå’Œåç½®å‘é‡ï¼Œæ ¹æ®å‚æ•°æ¥è·å¾—é¢„æµ‹çš„å‡½æ•°ã€‚è·å¾—çš„é¢„æµ‹ç»“æœå¿…ç„¶ä¸åå‡ ç»“æœæœ‰å‡ºå…¥ï¼Œè¿™å°±è¦ç”¨æŸå¤±å‡½æ•°æ¥è¡¡é‡ã€‚åœ¨ä¹‹å‰çš„å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬å­¦ä¹ äº†0-1æŸå¤±å‡½æ•°å’Œè´Ÿå¯¹æ•°ä¼¼ç„¶æŸå¤±å‡½æ•°ã€‚è¿™é‡Œæˆ‘ä»¬å°±è¦ç”¨åè€…ã€‚</p>
<p>å› ä¸ºä½¿ç”¨äº†ä¼¼ç„¶ä¼°è®¡çš„æ–¹æ³•ï¼Œè¿™ç­‰ä»·äºåœ¨æ¨¡å‹å‚æ•°ä¸º$\theta$çš„æ¡ä»¶ä¸‹ï¼Œåœ¨æ•°æ®é›†$\mathcal{D}$ä¸Šæœ€å¤§åŒ–ä¼¼ç„¶å‡½æ•°ã€‚å…¶ä¸­ï¼Œä¼¼ç„¶å‡½æ•°$\mathcal{L}$ä¸ºï¼š</p>
<p>$$<br>\mathcal{L}(\theta ={W,b},\mathcal{D})=\sum_{i=0}^{|\mathcal{D}|}log(P(Y=y^{(i)}x^{(i)},W,b))<br>$$</p>
<p>æŸå¤±å‡½æ•°ä¸€èˆ¬å–è´Ÿï¼Œæ‰€ä»¥æŸå¤±å‡½æ•°$l$è¡¨ç¤ºä¸º</p>
<p>$$<br>\mathcal{l}(\theta ={ W,b},\mathcal{D})=-L(\theta ={ W,b},\mathcal{D})<br>$$</p>
<p>ç”¨pythonè¡¨ç¤ºä¸º</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># y:å¯¹åº”ç±»åˆ«æ ‡ç­¾æ˜¯ä¸€ä¸ªå‘é‡ï¼Œå…¶æ¯ä¸€ä¸ªå€¼éƒ½å¯¹åº”ä¸€ä¸ªæ ‡ç­¾ã€‚</span></div><div class="line"><span class="comment"># y.shape[0] ä»£è¡¨yçš„è¡Œæ•°ï¼Œå°±æ˜¯minibatchæ–¹æ³•ä¸­åˆ†æˆçš„æ ·æœ¬é‡ï¼Œè¿™æ˜¯numpyçš„æ–¹æ³•</span></div><div class="line"><span class="comment"># T.arange(y.shape[0]) è¿”å›ä¸€ä¸ªå‘é‡[0,1,...,yçš„è¡Œæ•°]</span></div><div class="line"><span class="comment"># [T.arange(y.shape[0]), y]æ„å³ä¸€ä¸ªä¸¤åˆ—çš„çŸ©é˜µ,å¦‚ä¸‹å½¢å¼</span></div><div class="line"><span class="comment"># [0,y[0]]</span></div><div class="line"><span class="comment"># [1,y[1]]</span></div><div class="line"><span class="comment"># [2,y[2]]</span></div><div class="line"><span class="comment"># ...</span></div><div class="line"><span class="comment"># [i,y[i]]</span></div><div class="line"><span class="comment"># T.log(self.p_y_given_x)è¿™æ˜¯ä¸€ä¸ªçŸ©é˜µï¼Œå…¶æ¯ä¸€è¡Œå¯¹åº”ä¸€ä¸ªæ ·æœ¬ç±»å‹ï¼Œæ¯ä¸€åˆ—åˆ™å¯¹åº”ä¸€ä¸ªç±»åˆ«,p_y_given_xæ˜¯å±äºæŸä¸€ä¸ªç±»åˆ«çš„æ¦‚ç‡</span></div><div class="line"><span class="comment"># LP[T.arange(y.shape[0]),y]</span></div><div class="line"><span class="comment"># T.mean(LP[T.arange(y.shape[0]),y])meanç®—å‡ºäº†æ‰€æœ‰minibatchçš„å¯¹æ•°ä¼¼ç„¶å¹³å‡å€¼</span></div><div class="line"></div><div class="line"><span class="keyword">return</span> -T.mean(T.log(self.p_y_given_x)[T.arange(y.shape[<span class="number">0</span>]), y])</div></pre></td></tr></table></figure>
<h1 id="åˆ›å»ºé€»è¾‘å›å½’ç±»"><a href="#åˆ›å»ºé€»è¾‘å›å½’ç±»" class="headerlink" title="åˆ›å»ºé€»è¾‘å›å½’ç±»"></a>åˆ›å»ºé€»è¾‘å›å½’ç±»</h1><p>å°†ä¹‹å‰çš„é€»è¾‘å›å½’çš„æ¦‚å¿µä»£ç ï¼Œå…¨éƒ¨èåˆæˆå¦‚ä¸‹</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">LogisticRegression</span><span class="params">(object)</span>:</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input, n_in, n_out)</span>:</span></div><div class="line">        self.W = theano.shared(</div><div class="line">            value=numpy.zeros(</div><div class="line">                (n_in, n_out),</div><div class="line">                dtype=theano.config.floatX</div><div class="line">            ),</div><div class="line">            name=<span class="string">'W'</span>,</div><div class="line">            borrow=<span class="keyword">True</span></div><div class="line">        )</div><div class="line">        self.b = theano.shared(</div><div class="line">            value=numpy.zeros(</div><div class="line">                (n_out,),</div><div class="line">                dtype=theano.config.floatX</div><div class="line">            ),</div><div class="line">            name=<span class="string">'b'</span>,</div><div class="line">            borrow=<span class="keyword">True</span></div><div class="line">        )</div><div class="line">        self.p_y_given_x = T.nnet.softmax(T.dot(input, self.W) + self.b)</div><div class="line">        self.y_pred = T.argmax(self.p_y_given_x, axis=<span class="number">1</span>)</div><div class="line">        self.params = [self.W, self.b]</div><div class="line">        self.input = input</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">negative_log_likelihood</span><span class="params">(self, y)</span>:</span></div><div class="line">        <span class="keyword">return</span> -T.mean(T.log(self.p_y_given_x)[T.arange(y.shape[<span class="number">0</span>]), y])</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">errors</span><span class="params">(self, y)</span>:</span></div><div class="line">        <span class="keyword">if</span> y.ndim != self.y_pred.ndim:</div><div class="line">            <span class="keyword">raise</span> TypeError(</div><div class="line">                <span class="string">'y should have the same shape as self.y_pred'</span>,</div><div class="line">                (<span class="string">'y'</span>, y.type, <span class="string">'y_pred'</span>, self.y_pred.type)</div><div class="line">            )</div><div class="line">        <span class="keyword">if</span> y.dtype.startswith(<span class="string">'int'</span>):</div><div class="line">            <span class="keyword">return</span> T.mean(T.neq(self.y_pred, y))</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            <span class="keyword">raise</span> NotImplementedError()</div><div class="line"></div><div class="line">    x = T.matrix(<span class="string">'x'</span>)  <span class="comment"># data, presented as rasterized images</span></div><div class="line">    y = T.ivector(<span class="string">'y'</span>)  <span class="comment"># labels, presented as 1D vector of [int] labels</span></div><div class="line"></div><div class="line">    classifier = LogisticRegression(input=x, n_in=<span class="number">28</span> * <span class="number">28</span>, n_out=<span class="number">10</span>)</div></pre></td></tr></table></figure>
<p>å°†ä¸Šè¿°çš„ä»£ç ç»“åˆï¼Œå³å¯å¾—åˆ°æ•´ä¸ªä»£ç ã€‚</p>
<p>è¿è¡Œç»“æœ<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div></pre></td><td class="code"><pre><div class="line">... loading data</div><div class="line">... building the model</div><div class="line">... training the model</div><div class="line">epoch 1, minibatch 83/83, validation error 12.458333 %</div><div class="line">epoch 1, minibatch 83/83, test error of best model 12.375000 %</div><div class="line">epoch 2, minibatch 83/83, validation error 11.010417 %</div><div class="line">epoch 2, minibatch 83/83, test error of best model 10.958333 %</div><div class="line">epoch 3, minibatch 83/83, validation error 10.312500 %</div><div class="line">epoch 3, minibatch 83/83, test error of best model 10.312500 %</div><div class="line">epoch 4, minibatch 83/83, validation error 9.875000 %</div><div class="line">epoch 4, minibatch 83/83, test error of best model 9.833333 %</div><div class="line">epoch 5, minibatch 83/83, validation error 9.562500 %</div><div class="line">epoch 5, minibatch 83/83, test error of best model 9.479167 %</div><div class="line">epoch 6, minibatch 83/83, validation error 9.322917 %</div><div class="line">epoch 6, minibatch 83/83, test error of best model 9.291667 %</div><div class="line">epoch 7, minibatch 83/83, validation error 9.187500 %</div><div class="line">epoch 7, minibatch 83/83, test error of best model 9.000000 %</div><div class="line">epoch 8, minibatch 83/83, validation error 8.989583 %</div><div class="line">epoch 8, minibatch 83/83, test error of best model 8.958333 %</div><div class="line">epoch 9, minibatch 83/83, validation error 8.937500 %</div><div class="line">epoch 9, minibatch 83/83, test error of best model 8.812500 %</div><div class="line">epoch 10, minibatch 83/83, validation error 8.750000 %</div><div class="line">epoch 10, minibatch 83/83, test error of best model 8.666667 %</div><div class="line">epoch 11, minibatch 83/83, validation error 8.666667 %</div><div class="line">epoch 11, minibatch 83/83, test error of best model 8.520833 %</div><div class="line">epoch 12, minibatch 83/83, validation error 8.583333 %</div><div class="line">epoch 12, minibatch 83/83, test error of best model 8.416667 %</div><div class="line">epoch 13, minibatch 83/83, validation error 8.489583 %</div><div class="line">epoch 13, minibatch 83/83, test error of best model 8.291667 %</div><div class="line">epoch 14, minibatch 83/83, validation error 8.427083 %</div><div class="line">epoch 14, minibatch 83/83, test error of best model 8.281250 %</div><div class="line">epoch 15, minibatch 83/83, validation error 8.354167 %</div><div class="line">epoch 15, minibatch 83/83, test error of best model 8.270833 %</div><div class="line">epoch 16, minibatch 83/83, validation error 8.302083 %</div><div class="line">epoch 16, minibatch 83/83, test error of best model 8.239583 %</div><div class="line">epoch 17, minibatch 83/83, validation error 8.250000 %</div><div class="line">epoch 17, minibatch 83/83, test error of best model 8.177083 %</div><div class="line">epoch 18, minibatch 83/83, validation error 8.229167 %</div><div class="line">epoch 18, minibatch 83/83, test error of best model 8.062500 %</div><div class="line">epoch 19, minibatch 83/83, validation error 8.260417 %</div><div class="line">epoch 20, minibatch 83/83, validation error 8.260417 %</div><div class="line">epoch 21, minibatch 83/83, validation error 8.208333 %</div><div class="line">epoch 21, minibatch 83/83, test error of best model 7.947917 %</div><div class="line">epoch 22, minibatch 83/83, validation error 8.187500 %</div><div class="line">epoch 22, minibatch 83/83, test error of best model 7.927083 %</div><div class="line">epoch 23, minibatch 83/83, validation error 8.156250 %</div><div class="line">epoch 23, minibatch 83/83, test error of best model 7.958333 %</div><div class="line">epoch 24, minibatch 83/83, validation error 8.114583 %</div><div class="line">epoch 24, minibatch 83/83, test error of best model 7.947917 %</div><div class="line">epoch 25, minibatch 83/83, validation error 8.093750 %</div><div class="line">epoch 25, minibatch 83/83, test error of best model 7.947917 %</div><div class="line">epoch 26, minibatch 83/83, validation error 8.104167 %</div><div class="line">epoch 27, minibatch 83/83, validation error 8.104167 %</div><div class="line">epoch 28, minibatch 83/83, validation error 8.052083 %</div><div class="line">epoch 28, minibatch 83/83, test error of best model 7.843750 %</div><div class="line">epoch 29, minibatch 83/83, validation error 8.052083 %</div><div class="line">epoch 30, minibatch 83/83, validation error 8.031250 %</div><div class="line">epoch 30, minibatch 83/83, test error of best model 7.843750 %</div><div class="line">epoch 31, minibatch 83/83, validation error 8.010417 %</div><div class="line">epoch 31, minibatch 83/83, test error of best model 7.833333 %</div><div class="line">epoch 32, minibatch 83/83, validation error 7.979167 %</div><div class="line">epoch 32, minibatch 83/83, test error of best model 7.812500 %</div><div class="line">epoch 33, minibatch 83/83, validation error 7.947917 %</div><div class="line">epoch 33, minibatch 83/83, test error of best model 7.739583 %</div><div class="line">epoch 34, minibatch 83/83, validation error 7.875000 %</div><div class="line">epoch 34, minibatch 83/83, test error of best model 7.729167 %</div><div class="line">epoch 35, minibatch 83/83, validation error 7.885417 %</div><div class="line">epoch 36, minibatch 83/83, validation error 7.843750 %</div><div class="line">epoch 36, minibatch 83/83, test error of best model 7.697917 %</div><div class="line">epoch 37, minibatch 83/83The code for file logical_regression.py ran for 37.6s, validation error 7.802083 %</div><div class="line">epoch 37, minibatch 83/83, test error of best model 7.635417 %</div><div class="line">epoch 38, minibatch 83/83, validation error 7.812500 %</div><div class="line">epoch 39, minibatch 83/83, validation error 7.812500 %</div><div class="line">epoch 40, minibatch 83/83, validation error 7.822917 %</div><div class="line">epoch 41, minibatch 83/83, validation error 7.791667 %</div><div class="line">epoch 41, minibatch 83/83, test error of best model 7.625000 %</div><div class="line">epoch 42, minibatch 83/83, validation error 7.770833 %</div><div class="line">epoch 42, minibatch 83/83, test error of best model 7.614583 %</div><div class="line">epoch 43, minibatch 83/83, validation error 7.750000 %</div><div class="line">epoch 43, minibatch 83/83, test error of best model 7.593750 %</div><div class="line">epoch 44, minibatch 83/83, validation error 7.739583 %</div><div class="line">epoch 44, minibatch 83/83, test error of best model 7.593750 %</div><div class="line">epoch 45, minibatch 83/83, validation error 7.739583 %</div><div class="line">epoch 46, minibatch 83/83, validation error 7.739583 %</div><div class="line">epoch 47, minibatch 83/83, validation error 7.739583 %</div><div class="line">epoch 48, minibatch 83/83, validation error 7.708333 %</div><div class="line">epoch 48, minibatch 83/83, test error of best model 7.583333 %</div><div class="line">epoch 49, minibatch 83/83, validation error 7.677083 %</div><div class="line">epoch 49, minibatch 83/83, test error of best model 7.572917 %</div><div class="line">epoch 50, minibatch 83/83, validation error 7.677083 %</div><div class="line">epoch 51, minibatch 83/83, validation error 7.677083 %</div><div class="line">epoch 52, minibatch 83/83, validation error 7.656250 %</div><div class="line">epoch 52, minibatch 83/83, test error of best model 7.541667 %</div><div class="line">epoch 53, minibatch 83/83, validation error 7.656250 %</div><div class="line">epoch 54, minibatch 83/83, validation error 7.635417 %</div><div class="line">epoch 54, minibatch 83/83, test error of best model 7.520833 %</div><div class="line">epoch 55, minibatch 83/83, validation error 7.635417 %</div><div class="line">epoch 56, minibatch 83/83, validation error 7.635417 %</div><div class="line">epoch 57, minibatch 83/83, validation error 7.604167 %</div><div class="line">epoch 57, minibatch 83/83, test error of best model 7.489583 %</div><div class="line">epoch 58, minibatch 83/83, validation error 7.583333 %</div><div class="line">epoch 58, minibatch 83/83, test error of best model 7.458333 %</div><div class="line">epoch 59, minibatch 83/83, validation error 7.572917 %</div><div class="line">epoch 59, minibatch 83/83, test error of best model 7.468750 %</div><div class="line">epoch 60, minibatch 83/83, validation error 7.572917 %</div><div class="line">epoch 61, minibatch 83/83, validation error 7.583333 %</div><div class="line">epoch 62, minibatch 83/83, validation error 7.572917 %</div><div class="line">epoch 62, minibatch 83/83, test error of best model 7.520833 %</div><div class="line">epoch 63, minibatch 83/83, validation error 7.562500 %</div><div class="line">epoch 63, minibatch 83/83, test error of best model 7.510417 %</div><div class="line">epoch 64, minibatch 83/83, validation error 7.572917 %</div><div class="line">epoch 65, minibatch 83/83, validation error 7.562500 %</div><div class="line">epoch 66, minibatch 83/83, validation error 7.552083 %</div><div class="line">epoch 66, minibatch 83/83, test error of best model 7.520833 %</div><div class="line">epoch 67, minibatch 83/83, validation error 7.552083 %</div><div class="line">epoch 68, minibatch 83/83, validation error 7.531250 %</div><div class="line">epoch 68, minibatch 83/83, test error of best model 7.520833 %</div><div class="line">epoch 69, minibatch 83/83, validation error 7.531250 %</div><div class="line">epoch 70, minibatch 83/83, validation error 7.510417 %</div><div class="line">epoch 70, minibatch 83/83, test error of best model 7.500000 %</div><div class="line">epoch 71, minibatch 83/83, validation error 7.520833 %</div><div class="line">epoch 72, minibatch 83/83, validation error 7.510417 %</div><div class="line">epoch 73, minibatch 83/83, validation error 7.500000 %</div><div class="line">epoch 73, minibatch 83/83, test error of best model 7.489583 %</div><div class="line">Optimization complete with best validation score of 7.500000 %,with test performance 7.489583 %</div><div class="line">The code run for 74 epochs, with 1.968730 epochs/sec</div></pre></td></tr></table></figure></p>
<h1 id="åˆ†æ"><a href="#åˆ†æ" class="headerlink" title="åˆ†æ"></a>åˆ†æ</h1><p>åšåˆ°è¿™é‡Œï¼Œå°†åˆ«äººçš„ä»£ç è¿è¡Œèµ·æ¥æ˜¯ä¸å¤Ÿçš„ï¼Œè¿˜éœ€è¦åˆ†æé‡Œé¢çš„é“ç†ã€‚</p>
<p>é¦–å…ˆï¼Œæœ¬æ–‡çš„ç›®çš„æ˜¯ä»€ä¹ˆï¼Ÿå¦‚æ ‡é¢˜æ‰€ç¤ºã€ç”¨é€»è¾‘å›å½’åˆ†ææ¥åˆ†ç±»MINISTæ•°æ®é›†ã€‘ï¼Œä¹Ÿå°±æ˜¯æˆ‘ä»¬å¯¹MINISTæ•°æ®é›†è¿›è¡Œåˆ†ç±»ï¼Œæ€ä¹ˆåˆ†ç±»å‘¢ï¼Ÿç”¨é€»è¾‘å›å½’çš„æ–¹æ³•ã€‚</p>
<h2 id="ä»£ç ç»“æ„"><a href="#ä»£ç ç»“æ„" class="headerlink" title="ä»£ç ç»“æ„"></a>ä»£ç ç»“æ„</h2><h3 id="é€»è¾‘å›å½’çš„ç±»LogisticRegression"><a href="#é€»è¾‘å›å½’çš„ç±»LogisticRegression" class="headerlink" title="é€»è¾‘å›å½’çš„ç±»LogisticRegression"></a>é€»è¾‘å›å½’çš„ç±»<code>LogisticRegression</code></h3><p>ä»ä»£ç ä¸Šçœ‹ï¼Œé¦–å…ˆå®šä¹‰äº†ä¸€ä¸ªé€»è¾‘å›å½’çš„ç±»<code>LogisticRegression</code>ï¼Œå°†åˆå§‹åŒ–çš„é€»è¾‘å›å½’çš„æµç¨‹ç­‰éƒ½é›†æˆèµ·æ¥ã€‚</p>
<p>é‡Œé¢åŒ…å«äº†</p>
<ul>
<li>ä¸€ä¸ªæƒé‡çŸ©é˜µ<code>W</code></li>
<li>ä¸€ä¸ªåç½®å‘é‡<code>b</code>çš„å®šä¹‰</li>
<li>è¾“å…¥å‘é‡å±äºæŸä¸ªç±»çš„æ¦‚ç‡<code>p_y_given_x</code></li>
<li><code>p_y_given_x</code>æœ€å¤§æ—¶çš„ç±»åˆ«æ ‡ç­¾<code>y_pred</code></li>
<li>è´Ÿå¯¹æ•°ä¼¼ç„¶å‡½æ•°<code>negative_log_likelihood</code></li>
<li>å®¹é”™å¤„ç†å‡½æ•°<code>errors</code></li>
</ul>
<p>å› ä¸ºæˆ‘ä»¬çš„é—®é¢˜ä¸æ˜¯åœ¨ä¸€ç»´çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬çš„è¾“å…¥ä¸€èˆ¬æ˜¯ä¸€ä¸ªå‘é‡ã€‚</p>
<p>è¯´ä¸€è¯´<code>T.dot(input, self.W)</code>ã€‚</p>
<p>è¿™é‡Œçš„dotæ˜¯theanoçš„tensorå˜é‡çš„ç‚¹ä¹˜æ“ä½œ,T.dotæ¥å—ä¸¤ä¸ªçŸ©é˜µ(å‘é‡)è¾“å…¥,è®¡ç®—å®ƒä»¬çš„ç‚¹ç§¯å¹¶è¿”å›ä¸€ä¸ªä¿å­˜äº†ç‚¹ä¹˜ä¿¡æ¯çš„èŠ‚ç‚¹å¯¹è±¡,ä½¿ç”¨è¿”å›çš„å¯¹è±¡è°ƒç”¨eval()æ–¹æ³•å³å¯è·å¾—å®é™…æ•°å€¼ç»“æœã€‚<br>æ‰€ä»¥<code>self.p_y_given_x = T.nnet.softmax(T.dot(input, self.W) + self.b)</code>åŸºæœ¬å°±æ˜¯</p>
<p>$$<br>P(Y=i|x,W,b)=softmax_i(Wx+b)<br>=\frac{e^{W_{ix}+b_i}}{\sum_je^{W_{jx}+b_j}}<br>$$</p>
<p>çš„ç›´æ¥è¡¨è¾¾ã€‚</p>
<p>ç„¶åå°±æ˜¯è´Ÿå¯¹æ•°ä¼¼ç„¶å‡½æ•°<code>negative_log_likelihood</code>å’Œå®¹é”™å‡½æ•°ã€‚</p>
<h3 id="è½½å…¥æ•°æ®å‡½æ•°é›†load-data"><a href="#è½½å…¥æ•°æ®å‡½æ•°é›†load-data" class="headerlink" title="è½½å…¥æ•°æ®å‡½æ•°é›†load_data"></a>è½½å…¥æ•°æ®å‡½æ•°é›†load_data</h3><p>å› ä¸ºæœ¬èº«ä»£ç æ˜¯åŸºäºMINISTæ•°æ®é›†çš„ï¼Œå½“ç„¶éœ€è¦æŠŠå…¶å¯¼å…¥å…¶ä¸­ï¼Œç„¶åè¿›è¡Œè®­ç»ƒã€‚</p>
<p>è¿™é‡Œä¸»è¦å°±æ˜¯ä¸€ä¸ª<code>load_data</code>å‡½æ•°</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data</span><span class="params">(dataset)</span>:</span></div><div class="line">    data_dir, data_file = os.path.split(dataset)</div><div class="line">    <span class="keyword">if</span> data_dir == <span class="string">""</span> <span class="keyword">and</span> <span class="keyword">not</span> os.path.isfile(dataset):</div><div class="line">        <span class="comment"># Check if dataset is in the data directory.</span></div><div class="line">        new_path = os.path.join(</div><div class="line">            os.path.split(__file__)[<span class="number">0</span>],</div><div class="line">            <span class="string">".."</span>,</div><div class="line">            <span class="string">"data"</span>,</div><div class="line">            dataset</div><div class="line">        )</div><div class="line">        <span class="keyword">if</span> os.path.isfile(new_path) <span class="keyword">or</span> data_file == <span class="string">'mnist.pkl.gz'</span>:</div><div class="line">            dataset = new_path</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (<span class="keyword">not</span> os.path.isfile(dataset)) <span class="keyword">and</span> data_file == <span class="string">'mnist.pkl.gz'</span>:</div><div class="line">        <span class="keyword">from</span> six.moves <span class="keyword">import</span> urllib</div><div class="line">        origin = (</div><div class="line">            <span class="string">'http://www.iro.umontreal.ca/~lisa/deep/data/mnist/mnist.pkl.gz'</span></div><div class="line">        )</div><div class="line">        print(<span class="string">'Downloading data from %s'</span> % origin)</div><div class="line">        urllib.request.urlretrieve(origin, dataset)</div><div class="line"></div><div class="line">    print(<span class="string">'... loading data'</span>)</div><div class="line"></div><div class="line">   </div><div class="line">    <span class="keyword">with</span> gzip.open(dataset, <span class="string">'rb'</span>) <span class="keyword">as</span> f:</div><div class="line">        <span class="keyword">try</span>:</div><div class="line">            train_set, valid_set, test_set = pickle.load(f, encoding=<span class="string">'latin1'</span>)</div><div class="line">        <span class="keyword">except</span>:</div><div class="line">            train_set, valid_set, test_set = pickle.load(f)</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">shared_dataset</span><span class="params">(data_xy, borrow=True)</span>:</span></div><div class="line">        </div><div class="line">        data_x, data_y = data_xy</div><div class="line">        shared_x = theano.shared(numpy.asarray(data_x,</div><div class="line">                                               dtype=theano.config.floatX),</div><div class="line">                                 borrow=borrow)</div><div class="line">        shared_y = theano.shared(numpy.asarray(data_y,</div><div class="line">                                               dtype=theano.config.floatX),</div><div class="line">                                 borrow=borrow)</div><div class="line">     </div><div class="line">        <span class="keyword">return</span> shared_x, T.cast(shared_y, <span class="string">'int32'</span>)</div><div class="line"></div><div class="line">    test_set_x, test_set_y = shared_dataset(test_set)</div><div class="line">    valid_set_x, valid_set_y = shared_dataset(valid_set)</div><div class="line">    train_set_x, train_set_y = shared_dataset(train_set)</div><div class="line"></div><div class="line">    rval = [(train_set_x, train_set_y), (valid_set_x, valid_set_y),</div><div class="line">            (test_set_x, test_set_y)]</div><div class="line">    <span class="keyword">return</span> rval</div></pre></td></tr></table></figure>
<p>å…¶ä¸»è¦ç”±å‡ ä¸ªéƒ¨åˆ†ç»„æˆ</p>
<ul>
<li>å®šä¹‰datasetï¼Œä¸ºã€mnist.pkl.gzã€‘åŒ…ï¼Œè‹¥åŠ è½½å¤±è´¥ï¼Œåˆ™é‡æ–°ä¸‹è½½ã€‚</li>
<li>åŠ è½½dataset</li>
<li>å…±äº«dataset</li>
</ul>
<p>åŠ è½½datasetåªè¦æ‰“å¼€datasetåŒ…ã€mnist.pkl.gzã€‘ç„¶åç”¨<code>pickle.load</code>æ¥è½½å…¥ã€‚</p>
<p>åœ¨è¿™é‡Œå®šä¹‰äº†ä¸‰ä¸ªæ•°æ®é›†åˆ†åˆ«æ˜¯è®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†ã€‚è€Œä»–ä»¬éƒ½æ˜¯ä»datasetåŒ…ä¸­å¾—åˆ°çš„ï¼Œå€¼å„ä¸ç›¸åŒã€‚å°†ä»–ä»¬çš„å€¼æ‰“å°å‡ºæ¥:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">with</span> gzip.open(dataset, <span class="string">'rb'</span>) <span class="keyword">as</span> f:</div><div class="line">    <span class="keyword">try</span>:</div><div class="line">        train_set, valid_set, test_set = pickle.load(f, encoding=<span class="string">'latin1'</span>)</div><div class="line">    <span class="keyword">except</span>:</div><div class="line">        train_set, valid_set, test_set = pickle.load(f)</div><div class="line"></div><div class="line">print(train_set)</div><div class="line">print(valid_set)</div><div class="line">print(test_set)</div></pre></td></tr></table></figure>
<p>ç»“æœï¼š</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">(array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],</div><div class="line">       [ 0.,  0.,  0., ...,  0.,  0.,  0.],</div><div class="line">       [ 0.,  0.,  0., ...,  0.,  0.,  0.],</div><div class="line">       ...,</div><div class="line">       [ 0.,  0.,  0., ...,  0.,  0.,  0.],</div><div class="line">       [ 0.,  0.,  0., ...,  0.,  0.,  0.],</div><div class="line">       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32), array([5, 0, 4, ..., 8, 4, 8], dtype=int64))</div><div class="line">(array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],</div><div class="line">       [ 0.,  0.,  0., ...,  0.,  0.,  0.],</div><div class="line">       [ 0.,  0.,  0., ...,  0.,  0.,  0.],</div><div class="line">       ...,</div><div class="line">       [ 0.,  0.,  0., ...,  0.,  0.,  0.],</div><div class="line">       [ 0.,  0.,  0., ...,  0.,  0.,  0.],</div><div class="line">       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32), array([3, 8, 6, ..., 5, 6, 8], dtype=int64))</div><div class="line">(array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],</div><div class="line">       [ 0.,  0.,  0., ...,  0.,  0.,  0.],</div><div class="line">       [ 0.,  0.,  0., ...,  0.,  0.,  0.],</div><div class="line">       ...,</div><div class="line">       [ 0.,  0.,  0., ...,  0.,  0.,  0.],</div><div class="line">       [ 0.,  0.,  0., ...,  0.,  0.,  0.],</div><div class="line">       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32), array([7, 2, 1, ..., 4, 5, 6], dtype=int64))</div></pre></td></tr></table></figure>
<p>åŠ è½½çš„æ•°æ®é›†çš„æœ€ç»ˆè¿”å›æ•°æ®rvalï¼Œå°†å…¶æ‰“å°å‡ºæ¥å¦‚ä¸‹</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">rval is as follow...</div><div class="line">[(&lt;TensorType(float64, matrix)&gt;, Elemwise&#123;Cast&#123;int32&#125;&#125;.0),</div><div class="line"> (&lt;TensorType(float64, matrix)&gt;, Elemwise&#123;Cast&#123;int32&#125;&#125;.0),</div><div class="line"> (&lt;TensorType(float64, matrix)&gt;, Elemwise&#123;Cast&#123;int32&#125;&#125;.0)]</div></pre></td></tr></table></figure>
<p>æ²¡é”™ï¼ŒåŠ è½½çš„æ•°æ®é›†ä»å‰å¾€ååˆ†åˆ«æ˜¯è®­ç»ƒé›†ã€éªŒè¯é›†ã€æµ‹è¯•é›†ã€‚ä»–ä»¬éƒ½ç”±ä¸¤ä¸ªéƒ¨åˆ†ç»„æˆï¼Œåˆ†åˆ«æ˜¯è¾“å…¥çŸ©é˜µï¼ˆä¸€å¼ å›¾ç‰‡ï¼‰xï¼Œå¯¹åº”æ ‡ç­¾yã€‚è¿™é‡Œçš„yå…¨éƒ¨æ˜¯int32å‹ã€‚</p>
<p>æˆ‘ä»¬å›æƒ³æ•°æ®é›†çš„ä½œç”¨â€”â€”è®­ç»ƒï¼é€šè¿‡å·²çŸ¥çš„ä¸€äº›å›¾ç‰‡ï¼Œè¿™äº›å›¾ç‰‡éƒ½å·²ç»æœ‰äº†æ ‡ç­¾ï¼Œæ¥è®­ç»ƒå‡ºä¸€ä¸ªéšæ„ç»™å®šæœªçŸ¥æ ‡ç­¾çš„å›¾ç‰‡éƒ½èƒ½é¢„æµ‹å‡ºå…¶æ ‡ç­¾çš„å‡½æ•°ï¼</p>
<h3 id="å¯¹æ•°æ®é›†çš„éšæœºæ¢¯åº¦ä¸‹é™ä¼˜åŒ–"><a href="#å¯¹æ•°æ®é›†çš„éšæœºæ¢¯åº¦ä¸‹é™ä¼˜åŒ–" class="headerlink" title="å¯¹æ•°æ®é›†çš„éšæœºæ¢¯åº¦ä¸‹é™ä¼˜åŒ–"></a>å¯¹æ•°æ®é›†çš„éšæœºæ¢¯åº¦ä¸‹é™ä¼˜åŒ–</h3><p>åœ¨minibatchesçš„æ–¹æ³•ä¸­ï¼Œæ•°æ®é›†æ˜¯è¦éä¸ºå¤šä¸ªbatchï¼Œåˆ†åˆ«åšè®­ç»ƒï¼Œè¿™æ ·å¯ä»¥åŠ å¿«è®­ç»ƒçš„æ—¶é—´ã€‚æ ¹æ®è®¾å®šçš„batch_sizeè®¡ç®—å¯ä»¥åˆ†æˆå¤šå°‘ä¸ªbatchï¼Œç”¨<code>n_train_batches</code> ,<code>n_valid_batches</code>,<code>n_test_batches</code>æ¥åˆ†åˆ«è¡¨ç¤ºè®­ç»ƒã€éªŒè¯ã€æµ‹è¯•é›†çš„batchæ•°ã€‚å°†ä»–ä»¬åˆ†åˆ«æ‰“å°å‡ºæ¥å¯ä»¥çŸ¥é“</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">n_train_batches=83</div><div class="line">n_valid_batches=16</div><div class="line">n_test_batches=16</div></pre></td></tr></table></figure>
<p>å¯ä»¥çœ‹å‡ºè®­ç»ƒé›†çš„æ•°æ®é‡è¿˜æ˜¯è¿œè¿œå¤§äºéªŒè¯é›†å’Œæµ‹è¯•é›†çš„ã€‚</p>
<p>æ¥ä¸‹å°±è¦å»ºç«‹è®­ç»ƒæ¨¡å‹äº†ã€‚åœ¨è¿™é‡Œå»ºç«‹äº†3ä¸ªmodelï¼Œåˆ†åˆ«æ˜¯<code>test_model</code>,<code>validate_model</code>,<code>train_model</code>ã€‚åˆ†åˆ«ä»£è¡¨ä¸‰ä¸ªæ¨¡å‹ã€‚</p>
<p>åŒæ—¶å»ºç«‹çš„è¿˜æœ‰</p>
<ul>
<li>é€»è¾‘å›å½’åˆ†ç±»å™¨classifierï¼Œé€šè¿‡ä¹‹å‰çš„å‡½æ•°</li>
<li>æŸå¤±å‡½æ•°cost </li>
<li>æƒé‡çŸ©é˜µçš„æ¢¯åº¦g_W</li>
<li>åç½®å‘é‡çš„æ¢¯åº¦g_b</li>
<li>å‚æ•°æ›´æ–°updates</li>
</ul>
<p>å¼€å§‹è®­ç»ƒã€‚</p>
<p>è®­ç»ƒè¿‡ç¨‹å¯¹äºæ¯ä¸€ä¸ªæ ·æœ¬ï¼Œè·å¾—çš„æŸå¤±å‡½æ•°å¯¹æ¯”ï¼Œé€‰å–è¾ƒå°çš„æŸå¤±å‡½æ•°çš„åˆ†ç±»å™¨ï¼Œå°†å…¶ä¿å­˜åœ¨â€˜best_model.pklâ€™æ–‡ä»¶ä¸­ã€‚</p>
<h2 id="é¢„æµ‹"><a href="#é¢„æµ‹" class="headerlink" title="é¢„æµ‹"></a>é¢„æµ‹</h2><p>ç”±ä¹‹å‰è®­ç»ƒè·å¾—çš„åˆ†ç±»å™¨å­˜å‚¨åœ¨â€˜best_model.pklâ€™æ–‡ä»¶ä¸­ï¼Œæ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å†æ¬¡ç”¨æœ€åˆçš„ã€mnist.pkl.gzã€‘çš„æ•°æ®é›†ï¼Œä»ä¸­é€‰å–æ•°æ®æ¥éªŒè¯åˆ†ç±»å™¨ã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">()</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    An example of how to load a trained model and use it</div><div class="line">    to predict labels.</div><div class="line">    """</div><div class="line"></div><div class="line">    <span class="comment"># load the saved model</span></div><div class="line">    classifier = pickle.load(open(<span class="string">'best_model.pkl'</span>))</div><div class="line"></div><div class="line">    <span class="comment"># compile a predictor function</span></div><div class="line">    predict_model = theano.function(</div><div class="line">        inputs=[classifier.input],</div><div class="line">        outputs=classifier.y_pred)</div><div class="line"></div><div class="line">    <span class="comment"># We can test it on some examples from test test</span></div><div class="line">    dataset=<span class="string">'mnist.pkl.gz'</span></div><div class="line">    datasets = load_data(dataset)</div><div class="line">    test_set_x, test_set_y = datasets[<span class="number">2</span>]</div><div class="line">    test_set_x = test_set_x.get_value()</div><div class="line"></div><div class="line">    predicted_values = predict_model(test_set_x[:<span class="number">10</span>])</div><div class="line">    print(<span class="string">"Predicted values for the first 10 examples in test set:"</span>)</div><div class="line">    print(predicted_values)</div></pre></td></tr></table></figure>
<p>å¯ä»¥çœ‹å‡ºï¼Œå®šä¹‰äº†ä¸€ä¸ªtheanoå‡½æ•°predict_modelï¼Œå…¶è¾“å…¥æ˜¯xçŸ©é˜µï¼Œè¾“å‡ºæ˜¯yé¢„æµ‹å€¼ã€‚ç”¨<code>test_set_x[:10]</code>å–è¿™ä¸ªæ•°æ®é›†çš„å‰10ä¸ªæ ·æœ¬ï¼Œè¿›è¡Œè®¡ç®—ï¼Œè·å¾—ç»“æœ</p>
<p>è°ƒç”¨å¯å¾—<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">Predicted values for the first 10 examples in test set:</div><div class="line">[7 2 1 0 4 1 4 9 6 9]</div></pre></td></tr></table></figure></p>
<hr>
<p><strong>å‚è€ƒ</strong></p>
<ol>
<li><a href="http://blog.csdn.net/google19890102/article/details/48976021" target="_blank" rel="external">åˆ©ç”¨Theanoç†è§£æ·±åº¦å­¦ä¹ â€”â€”Logistic Regression</a></li>
<li><a href="http://www.cnblogs.com/lancelod/p/4134276.html" target="_blank" rel="external">åŸºäºtheano.tensor.dotçš„é€»è¾‘å›å½’ä»£ç ä¸­çš„SGDéƒ¨åˆ†çš„ç–‘é—®æ¢å¹½</a></li>
</ol>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/09/05/ã€æœºå™¨å­¦ä¹ ã€‘3-çº¿æ€§ä»£æ•°åˆçª¥MLâ€”â€”PCAç®—æ³•/" itemprop="url">
                  ã€æœºå™¨å­¦ä¹ ã€‘3-çº¿æ€§ä»£æ•°åˆçª¥MLâ€”â€”PCAç®—æ³•
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">å‘è¡¨äº</span>
            <time itemprop="dateCreated" datetime="2016-09-05T16:39:37+08:00" content="2016-09-05">
              2016-09-05
            </time>
          </span>

          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/09/05/ã€æœºå™¨å­¦ä¹ ã€‘3-çº¿æ€§ä»£æ•°åˆçª¥MLâ€”â€”PCAç®—æ³•/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/09/05/ã€æœºå™¨å­¦ä¹ ã€‘3-çº¿æ€§ä»£æ•°åˆçª¥MLâ€”â€”PCAç®—æ³•/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>ä»Šå¤©æ¥çœ‹çœ‹ä¸€ä¸ªç®€å•çš„æœºå™¨å­¦ä¹ ç®—æ³•ï¼Œä¸»æˆåˆ†åˆ†æï¼ˆ<em>Principal Component Analysis</em>ï¼Œ<strong>PCA</strong>ï¼‰ã€‚è¿™ä¸ªåªè¦ç”¨çº¿æ€§ä»£æ•°çš„çŸ¥è¯†å°±å¯ä»¥ç†è§£äº†ï¼Œæ˜¯ä¸æ˜¯æœ‰ç‚¹å…´å¥‹ï¼Ÿå½“ç„¶å‰ææ˜¯æ‰€æœ‰æ¡ä»¶æœ€ç®€çš„æƒ…å†µã€‚</p>
<p>é¦–å…ˆæ¥çœ‹çœ‹ç™¾åº¦çš„å®šä¹‰ï¼Œ<strong>ä¸»æˆåˆ†åˆ†æï¼ˆ<em>Principal Component Analysisï¼ŒPCA</em>ï¼‰</strong>ï¼Œ æ˜¯ä¸€ç§ç»Ÿè®¡æ–¹æ³•ã€‚é€šè¿‡æ­£äº¤å˜æ¢å°†ä¸€ç»„å¯èƒ½å­˜åœ¨ç›¸å…³æ€§çš„å˜é‡è½¬æ¢ä¸ºä¸€ç»„çº¿æ€§ä¸ç›¸å…³çš„å˜é‡ï¼Œè½¬æ¢åçš„è¿™ç»„å˜é‡å«ä¸»æˆåˆ†ã€‚è¿™è¯´çš„å¤ªæŠ½è±¡äº†ã€‚å€Ÿç”¨â‘ çš„è¯´æ³•ï¼ŒPCAï¼ˆPrincipal Components Analysisï¼‰å³ä¸»æˆåˆ†åˆ†æï¼Œæ˜¯å›¾åƒå¤„ç†ä¸­ç»å¸¸ç”¨åˆ°çš„é™ç»´æ–¹æ³•ã€‚</p>
<h1 id="å‡è®¾"><a href="#å‡è®¾" class="headerlink" title="å‡è®¾"></a>å‡è®¾</h1><ol>
<li>æˆ‘ä»¬æœ‰ä¸€ä¸ªåŒ…å«mä¸ªå…ƒç´ çš„ç‚¹é›†${x^{(1)},â€¦,x^{(m)}}$åœ¨$\mathbb{R}^n$ç©ºé—´å†…ã€‚</li>
<li>æˆ‘ä»¬èƒ½å¤Ÿæ¥å—å¯¹å­˜å‚¨çš„ç‚¹è¿›è¡Œå‹ç¼©ï¼Œå³ä½¿è¿™ä¼šä½¿å¾—ä¸¢å¤±ä¸€äº›ç²¾åº¦ã€‚</li>
</ol>
<p>ä¸ºä»€ä¹ˆæˆ‘ä»¬è¦è¿™ä¹ˆåšå‘¢ï¼Ÿåœ¨å›¾åƒæˆ–æ˜¯å…¶ä»–çš„å¤§æ•°æ®å­˜å‚¨çš„æ—¶å€™ï¼Œä¸€èˆ¬ä»¥é«˜ç»´çš„å½¢å¼å­˜å‚¨ï¼Œè¿™ä¸ªå­˜å‚¨é‡æ˜¯ç›¸å½“å¤§çš„ï¼Œç´¢å¼•èµ·æ¥ä¹Ÿç›¸å½“çš„éº»çƒ¦ï¼Œäºæ˜¯æˆ‘ä»¬å°±æœ‰é™ç»´æ–¹å¼æ¥å¯¹æ¯ä¸ªå‘é‡é™ç»´ï¼Œè¿™æ ·å¯¹äºæ•´ä¸ªç³»ç»Ÿçš„ç´¢å¼•å­˜å‚¨éƒ½å°†æœ‰æ˜¾è‘—æ€§èƒ½æå‡ã€‚</p>
<p>å¯¹äºåˆšæ‰æˆ‘ä»¬å‡è®¾çš„ç‚¹é›†ï¼Œå¯¹äºæ¯ä¸€ä¸ªç‚¹å‘é‡$x^{(i)}\in\mathbb{R}^n$,åœ¨lç»´ï¼ˆl&lt; xï¼‰éƒ½æœ‰ä¸€ä¸ªå¯¹åº”çš„å‘é‡$c^{(i)}\in\mathbb{R}^l$ï¼Œè¿™æ ·å°±æ˜¯å‹ç¼©ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯<strong>æ‰¾åˆ°è¿™æ ·çš„ä¸€ä¸ªæ–¹æ³•èƒ½å¤Ÿä½¿å¾—$f(x)=c$,ä»¥åŠå…¶é€†å‡½æ•°$x=g[f(c)]$</strong>ã€‚</p>
<p>ä¸Šè¿°çš„é€†å‡½æ•°å°±æ˜¯PCAçš„æ–¹æ³•ã€‚</p>
<h1 id="åˆ†æ"><a href="#åˆ†æ" class="headerlink" title="åˆ†æ"></a>åˆ†æ</h1><p>è¿™é‡Œæˆ‘ä»¬é€‰æ‹©ç”¨çŸ©é˜µä¹˜æ³•æ¥ä½œä¸ºè¿™æ ·ä¸€ä¸ªå°†lç»´æ˜ å°„åˆ°nç»´çš„æ–¹æ³•ï¼Œæˆ‘ä»¬ä½¿ç”¨$g(c)=Dc$ï¼Œè¿™é‡Œçš„$D\in\mathbb{R}^{n\times l}$æ˜¯ä¸€ä¸ªçŸ©é˜µã€‚</p>
<p>å¦‚ä½•æ‰¾åˆ°è¿™æ ·çš„ä¸€ä¸ªæœ€ä½³Dæ˜¯è¾ƒä¸ºå›°éš¾çš„äº‹æƒ…ï¼Œä¸ºäº†è¿½æ±‚ç®€å•æ–¹ä¾¿è®¡ç®—ï¼Œæˆ‘ä»¬å‡è®¾Dçš„æ¯ä¸€åˆ—éƒ½æ˜¯æ­£äº¤çš„ã€‚å®é™…ä¸Šæˆ‘ä»¬çŸ¥é“ï¼Œå¦‚æœDæ˜¯ä¸€ä¸ªæ–¹é˜µï¼ŒDå°±æ˜¯ä¸€ä¸ªæ­£äº¤çŸ©é˜µã€‚</p>
<blockquote>
<p>With the problem as described so far, many solutions are possible, because we can increase the scale of $D_{:,i}$if we decrease $c_i$ proportionally for all points. To give the problem a unique solution, we constrain all of the columns of D to have unit norm.</p>
</blockquote>
<p>å¯¹äºè¿™æ ·çš„ä¸€ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬çš„ç›®çš„æ˜¯è¶Šç®€å•è¶Šå¥½ï¼Œäºæ˜¯æˆ‘ä»¬æ›´è¿›ä¸€æ­¥ï¼ŒæŠŠDçš„æ¯ä¸€ä¸ªåˆ—å‘é‡éƒ½çœ‹æˆæ˜¯å•ä½å‘é‡ã€‚</p>
<p>OKï¼Œåˆ°æ­¤æˆ‘ä»¬å¼€å§‹è€ƒè™‘è¿™ä¸ªé—®é¢˜çš„è§£å†³æ–¹æ³•äº†ã€‚æˆ‘ä»¬çŸ¥é“cæ˜¯xçš„encodeï¼Œæ‰€ä»¥å¯»æ‰¾æœ€ä¼˜$c^*$å°±æ˜¯æˆ‘ä»¬çš„ç¬¬ä¸€æ­¥ã€‚</p>
<h2 id="ç¬¬ä¸€æ­¥-å¯»æ‰¾æœ€ä¼˜-c"><a href="#ç¬¬ä¸€æ­¥-å¯»æ‰¾æœ€ä¼˜-c" class="headerlink" title="ç¬¬ä¸€æ­¥ å¯»æ‰¾æœ€ä¼˜$c^*$"></a>ç¬¬ä¸€æ­¥ å¯»æ‰¾æœ€ä¼˜$c^*$</h2><p>å¦‚ä½•æ‰¾åˆ°æœ€ä¼˜çš„$c^*$ ï¼Œæˆ‘ä»¬çŸ¥é“cæ˜¯xçš„encodeï¼Œåœ¨encodeä¸­ï¼Œå› ä¸ºæ˜¯é™ç»´ï¼Œæ‰€ä»¥æ— æ³•åšåˆ°å¯¹c decodeå¯ä»¥è¿˜åŸxï¼Œæ‰€ä»¥æœ€ä¼˜çš„ $c^*$å°±æ˜¯èƒ½ä¿è¯$g(c^*)$å’Œxçš„è·ç¦»æœ€çŸ­ï¼Œæœ€æ¥è¿‘ï¼Œå³æ˜¯æœ€ä¼˜ã€‚</p>
<p>è¿™é‡Œæ˜¯ä¸æ˜¯æƒ³åˆ°æˆ‘ä»¬ä¹‹å‰çš„èŒƒæ•°ï¼Ÿæ²¡é”™ï¼Œè¿™é‡Œæ­£å¥½å°±å¯ä»¥ç”¨å¾—ä¸Šï¼Œæè¿°xå’Œ$g(c^*)$ä¹‹é—´çš„è·ç¦»ï¼Œå³xåˆ°$g(c^*)$çš„å‘é‡é•¿åº¦ã€‚æˆ‘ä»¬è¿™é‡Œç”¨$L^2$èŒƒæ•°ã€‚</p>
<p>$$<br>c^*=argmin_c||x-g(c)||_2<br>$$</p>
<p>ä¸ºäº†æ–¹ä¾¿ï¼Œæˆ‘ä»¬å–$L^2$èŒƒæ•°çš„å¹³æ–¹ã€‚</p>
<p>$$<br>c^*=argmin_c||x-g(c)||_2^2<br>$$</p>
<p>æ ¹æ®$L^2$èŒƒæ•°çš„è®¡ç®—æ–¹å¼ï¼Œè¿™ä¸ªè®¡ç®—å¯ä»¥å˜ä¸º</p>
<p>$$<br>||x-g(c)||_2^2\\<br>=(x-g(c))^\top(x-g(c))\\<br>=x^\top x-g(c)^\top x-x^\top g(c)+g(c)^\top g(c)\\<br>=x^\top x-2x^\top g(c)+g(c)^\top g(c)<br>$$</p>
<p>å³</p>
<p>$$<br>c^*=argmin_c[x^\top x-2x^\top g(c)+g(c)^\top g(c)]<br>$$</p>
<p>ç”±ä¸Šæ–‡ï¼Œ$g(c)=Dc$ï¼Œå¹¶ä¸”å‘é‡å†…ç§¯å¿…ä¸ºæ­£æ•°ï¼Œè¿™ä¸ªå¼å­å¯ä»¥å˜ä¸º,<br>$$<br>c^*=argmin_c[x^\top x-2x^\top Dc+(Dc)^\top Dc]\\<br>=argmin_c[x^\top x-2x^\top Dc+c^\top D^\top Dc]\\<br>=argmin_c[-2x^\top Dc+c^\top D^\top Dc]<br>$$</p>
<p>å› ä¸ºDæ˜¯æ­£äº¤çŸ©é˜µ<br>$$<br>=argmin_c[-2x^\top Dc+c^\top c]<br>$$</p>
<p>ä½¿ç”¨<strong>æ¢¯åº¦ä¸‹é™æ³•</strong>ï¼ˆåé¢å†å­¦ï¼‰ï¼Œ</p>
<p>$$<br>\nabla_c(-2x^\top Dc+c^\top c)=0<br>-2D^\top x+2c=0<br>c=D^\top x<br>$$</p>
<p>åˆ°è¿™é‡Œï¼Œæˆ‘ä»¬å‘ç°ï¼ŒåŸæ¥åªè¦<br>$$<br>f(x)=D^\top x<br>$$<br>å°±å¯ä»¥å¯¹xè¿›è¡Œencodeï¼Œå…¶decodeçš„ç»“æœ$r(x)$å¦‚ä¸‹ï¼Œ<br>$$<br>r(x)=g(f(x))=DD^\top x<br>$$</p>
<h2 id="ç¬¬äºŒæ­¥-æ±‚æœ€ä¼˜çŸ©é˜µD"><a href="#ç¬¬äºŒæ­¥-æ±‚æœ€ä¼˜çŸ©é˜µD" class="headerlink" title="ç¬¬äºŒæ­¥ æ±‚æœ€ä¼˜çŸ©é˜µD"></a>ç¬¬äºŒæ­¥ æ±‚æœ€ä¼˜çŸ©é˜µD</h2><p>å’Œä¹‹å‰å¯»æ‰¾æœ€ä¼˜cçš„æ–¹æ³•ä¸€æ ·ï¼Œæˆ‘ä»¬ä»ç„¶è¦æ‰¾æœ€æ¥è¿‘xçš„$r(x)$,ç”±äº$r(x)$ä¸­ç”¨äº†çŸ©é˜µD,è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨FrobeniusèŒƒæ•°æ¥è¡¡é‡</p>
<p>$$<br>D^*=arg\ min_D\sqrt{\sum_{i,j}(x_j^{(i)}-r(x^{(i)})_j)^2}\\<br>subject\  to\ D^\top D=I_l<br>$$</p>
<p>è€ƒè™‘æœ€æç«¯çš„æƒ…å†µï¼Œè‹¥l=1ï¼Œè¿™æ—¶å€™DçŸ©é˜µå˜æˆäº†då‘é‡ï¼Œä¸Šå¼åˆå˜æˆäº†ä¸€ä¸ªæ±‚$L^2$èŒƒæ•°çš„é—®é¢˜<br>$$<br>d^*=arg\ min_d\sum_i||x^{(i)}-dd^\top x^{(i)}||_2^2 \ \ \ subject\ to \ ||d||_2=1<br>$$<br>å› ä¸º$d^\top x^{(i)}$æ˜¯ä¸ªæ ‡é‡ï¼Œæ‰€ä»¥ä¸Šå¼å¯ä»¥å˜ä¸º<br>$$<br>d^*=arg\ min_d\sum_i||x^{(i)}- x^{(i)\top} dd||_2^2 \ \ \ subject\ to \ ||d||_2=1<br>$$<br>è€ƒè™‘åˆ°è®¡ç®—sumä¸æ˜“ï¼Œæˆ‘ä»¬ç”¨çŸ©é˜µæ¥æ•´åˆå‘é‡ï¼Œå°†æ‰€æœ‰çš„xå‘é‡ç»„åˆæˆXçŸ©é˜µï¼Œæœ‰$X_{i,:}=x^{(i)\top}$,äºæ˜¯</p>
<p>$$<br>d^*=arg\ min_d||X- X dd^\top||_F^2 \ \ \ subject\ to \ d^\top d=1<br>$$<br>æ ¹æ®<br>$$<br>||A||_F=\sqrt{Tr(AA^\top)}<br>$$<br>ä¸Šå¼å¯å˜ä¸º</p>
<p>$$<br>d^*=arg\ min_d||X- X dd^\top||_F^2\\<br>=arg\ min_dTr[(X-Xdd^\top)^\top(X-Xdd^\top)]\\<br>=arg\ min_dTr(X^\top X-X^\top Xdd^\top-dd^\top X^\top X+dd^\top X^\top Xdd^\top)\\<br>=arg\ min_dTr(X^\top X)-Tr(X^\top Xdd^\top)-Tr(dd^\top X^\top X)+Tr(dd^\top X^\top Xdd^\top)<br>$$<br>å› ä¸ºä¸åŒ…å«dçš„éƒ¨åˆ†ä¸å½±å“è®¡ç®—ï¼Œæ•…<br>$$<br>=arg\ min_d[-Tr(X^\top Xdd^\top)-Tr(dd^\top X^\top X)+Tr(dd^\top X^\top Xdd^\top)]\\<br>=arg\ min_d[-2Tr(X^\top Xdd^\top)+Tr(dd^\top X^\top Xdd^\top)]\\<br>=arg\ min_d[-2Tr(X^\top Xdd^\top)+Tr(X^\top Xdd^\top dd^\top)]\\<br>=arg\ min_d[-2Tr(X^\top Xdd^\top)+Tr(X^\top Xdd^\top)]\\<br>=arg\ min_d-Tr(X^\top Xdd^\top)\ \ s.t.\ \ d^\top d=1\\<br>=arg\ max_dTr(X^\top Xdd^\top)\ \ s.t.\ \ d^\top d=1\\<br>=arg\ max_dTr(d^\top X^\top Xd)\ \ s.t.\ \ d^\top d=1<br>$$<br>æ ¹æ®ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡çš„çŸ¥è¯†ï¼Œæˆ‘ä»¬çŸ¥é“è¿™ä¸ªé—®é¢˜å¯ä»¥è½¬åŒ–ä¸ºæ±‚ç‰¹å¾å€¼çš„é—®é¢˜ï¼Œå‡è®¾$X^\top X$ç‰¹å¾åˆ†è§£ä¸º$X^\top Xd=\lambda d$ï¼Œ$\lambda$æ˜¯$X^\top X$çš„ç‰¹å¾å€¼ï¼Œ$d$æ˜¯$X^\top X$çš„ç‰¹å¾å‘é‡,æ‰€ä»¥ä¸Šå¼å°±å¯ä»¥å˜ä¸º<br>$$<br>=arg\ max_dTr(d^\top(X^\top Xd))\ \ s.t.\ \ d^\top d=1\\<br>=arg\ max_dTr(d^\top(\lambda d))\ \ s.t.\ \ d^\top d=1\\<br>=arg\ max_dTr(\lambda d^\top d)\ \ s.t.\ \ d^\top d=1\\<br>=arg\ max_dTr(\lambda)\ \ s.t.\ \ d^\top d=1\\<br>=arg\ max_d \lambda\ \ s.t.\ \ d^\top d=1<br>$$<br>æ‰€ä»¥æœ€ä¼˜då°±æ˜¯$X^\top X$çš„ç‰¹å¾å€¼æœ€å¤§çš„ç‰¹å¾å‘é‡ã€‚</p>
<h1 id="æ€»ç»“"><a href="#æ€»ç»“" class="headerlink" title="æ€»ç»“"></a>æ€»ç»“</h1><p>æœ€ç»ˆè·å¾—è¿™æ ·çš„ä¸€ä¸ªç»“æœï¼Œåœ¨è¿™æ ·çš„ä¸€ä¸ªç®—æ³•é‡Œé¢åªç”¨äº†çº¿æ€§ä»£æ•°çš„çŸ¥è¯†ï¼Œä¸è¿‡é—®é¢˜æœ¬èº«å·²ç»æ˜¯ä¸€å†ç®€åŒ–ï¼Œä½œä¸ºåé¢ç ”ç©¶å¤æ‚çš„PCAç®—æ³•ä¹Ÿç®—æ˜¯é“ºå«ä¸€ä¸‹ã€‚</p>
<p>ç®—æ³•çš„é‡ç‚¹åœ¨äºï¼š</p>
<p>â‘ ä¸ºä»€ä¹ˆä¼˜åŒ–é—®é¢˜ä¸­ç”¨åˆ°äº†æ¢¯åº¦ä¸‹é™æ³•</p>
<p>â‘¡ç”±å‘é‡å‘çŸ©é˜µçš„å˜æ¢</p>
<hr>
<p>æœ¬æ–‡å€Ÿé‰´ï¼š</p>
<p>â‘  <a href="http://my.oschina.net/gujianhan/blog/225241" target="_blank" rel="external">PCA ï¼ˆä¸»æˆåˆ†åˆ†æï¼‰è¯¦è§£ ï¼ˆå†™ç»™åˆå­¦è€…ï¼‰ ç»“åˆmatlab</a></p>
<p>â‘  <a href="http://www.deeplearningbook.org/" target="_blank" rel="external">Deep Learning</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/08/21/ã€æœºå™¨å­¦ä¹ ã€‘2-çŸ©é˜µå’Œå‘é‡çš„ä¸€äº›è®¡ç®—/" itemprop="url">
                  ã€æœºå™¨å­¦ä¹ ã€‘2-çŸ©é˜µå’Œå‘é‡çš„ä¸€äº›è®¡ç®—
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">å‘è¡¨äº</span>
            <time itemprop="dateCreated" datetime="2016-08-21T20:57:26+08:00" content="2016-08-21">
              2016-08-21
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">åˆ†ç±»äº</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/æœºå™¨å­¦ä¹ /" itemprop="url" rel="index">
                    <span itemprop="name">æœºå™¨å­¦ä¹ </span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/08/21/ã€æœºå™¨å­¦ä¹ ã€‘2-çŸ©é˜µå’Œå‘é‡çš„ä¸€äº›è®¡ç®—/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/08/21/ã€æœºå™¨å­¦ä¹ ã€‘2-çŸ©é˜µå’Œå‘é‡çš„ä¸€äº›è®¡ç®—/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>ä¹‹å‰å¤ä¹ äº†ä¸€äº›çŸ©é˜µçš„æ¦‚å¿µï¼Œè¿˜å­¦ä¹ äº†ä¸€äº›èŒƒæ•°çš„æ¦‚å¿µï¼Œç°åœ¨æ˜¯ä¸æ˜¯ä¿¡å¿ƒæ»¡æ»¡å‘¢ï¼Ÿ</p>
<h3 id="ç‰¹æ®Šçš„çŸ©é˜µå’Œå‘é‡"><a href="#ç‰¹æ®Šçš„çŸ©é˜µå’Œå‘é‡" class="headerlink" title="ç‰¹æ®Šçš„çŸ©é˜µå’Œå‘é‡"></a>ç‰¹æ®Šçš„çŸ©é˜µå’Œå‘é‡</h3><p><strong>Diagonal Matrices</strong>:å¯¹è§’çŸ©é˜µï¼Œå³é™¤äº†ä¸­é—´i=jçš„åœ°æ–¹ï¼Œéƒ½æ˜¯0çš„çŸ©é˜µã€‚å•ä½çŸ©é˜µä¹Ÿæ˜¯å¯¹è§’çŸ©é˜µã€‚æˆ‘ä»¬ç”¨<br>$$<br>diag(\mathbf{v})<br>$$<br>æ¥è¡¨ç¤ºå¯¹è§’çŸ©é˜µï¼Œè¿™é‡Œçš„<strong>v</strong>æ˜¯<strong>å‘é‡</strong>ï¼Œä¸æ˜¯çŸ©é˜µï¼Œæ˜¯å°†å¯¹è§’çŸ©é˜µçš„å¯¹è§’ä¸Šçš„å€¼ï¼Œåšæˆä¸€ä¸ªå‘é‡ã€‚</p>
<p>è€Œä¸€èˆ¬æ¥è¯´è®¡ç®—å’Œå¯¹è§’çŸ©é˜µçš„ä¹˜ç§¯ï¼Œåªè¦ç®—è¿™ä¸ªå‘é‡å’Œè¦ä¹˜3çš„çŸ©é˜µçš„ç‚¹ä¹˜å°±å¥½äº†<br>$$<br>diag(\mathbf{v}) \mathbf{x}=\mathbf{v}\odot\mathbf{x}<br>$$</p>
<p><strong>å¯¹ç§°çŸ©é˜µ</strong>ï¼šè‡ªå·±å’Œè‡ªå·±çš„è½¬ç½®ç›¸ç­‰çš„çŸ©é˜µã€‚å³<br>$$<br>\mathbf{A}=\mathbf{A}^\top<br>$$</p>
<blockquote>
<p>Symmetric matrices often arise when the entries are generated by some function of two arguments that does not depend on the order of the arguments.</p>
</blockquote>
<p>å¯¹ç§°çŸ©é˜µç»å¸¸ç”¨åœ¨é‚£ç§ç”±ä¸¤ä¸ªå‚æ•°æ„æˆå´å’Œå‚æ•°é¡ºåºæ— å…³çš„å‡½æ•°æ„æˆä¸­ã€‚</p>
<p><strong>å•ä½å‘é‡</strong>ï¼š$L^2$èŒƒæ•°ä¸º1çš„å‘é‡ã€‚<br>$$<br>\vert\vert{\mathbf{x}}\vert\vert_2=1<br>$$<br><strong>æ­£äº¤</strong>ï¼šåˆ†ä¸ºå‘é‡æ­£äº¤å’ŒçŸ©é˜µæ­£äº¤ï¼Œä¸¤å‘é‡æ­£äº¤ï¼Œæ„å‘³ç€<br>$$<br>\mathbf{x}^\top\mathbf{y}=0<br>$$<br>çŸ©é˜µæ­£äº¤åˆ™<br>$$<br>\mathbf{A}^\top\mathbf{A}=\mathbf{A}\mathbf{A}^\top=I<br>$$</p>
<p>æ‰€ä»¥æœ‰<br>$$<br>\mathbf{A}^{-1}=\mathbf{A}^\top<br>$$</p>
<hr>
<h3 id="çŸ©é˜µçš„ç‰¹å¾åˆ†è§£"><a href="#çŸ©é˜µçš„ç‰¹å¾åˆ†è§£" class="headerlink" title="çŸ©é˜µçš„ç‰¹å¾åˆ†è§£"></a>çŸ©é˜µçš„ç‰¹å¾åˆ†è§£</h3><p>OKï¼Œå°±åƒæ˜¯ä¸€ä¸ªéç´ æ•°å¯ä»¥æˆå¤šä¸ªç´ æ•°çš„ä¹˜ç§¯ä¸€æ ·ï¼ŒçŸ©é˜µä¹Ÿå¯ä»¥åˆ†è§£ï¼Œè¿™é‡Œå­¦ä¹ ä¸€ç§åˆ†è§£æ–¹æ³•â€”â€”ç‰¹å¾åˆ†è§£ï¼ˆ<em>Eigendecomposition</em>ï¼‰ï¼ŒçŸ©é˜µå°±è¢«åˆ†è§£ä¸ºç‰¹å¾å‘é‡å’Œç‰¹å¾å€¼äº†ã€‚</p>
<p>$$<br>\mathbf{Av}=\mathbf{\lambda v}<br>$$<br>ç”±ä¸Šé¢å¯ä»¥çŸ¥é“ï¼Œæœ€åˆçš„å®šä¹‰å°±æ˜¯çŸ©é˜µå’Œå…¶ç‰¹å¾å‘é‡ä¹˜ç§¯ç­‰äºç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡çš„ä¹˜ç§¯ã€‚</p>
<p>å¦‚æœç‰¹å¾å‘é‡æœ‰å¾ˆå¤šï¼Œé‚£ä¹ˆå¯ä»¥ç»„æˆä¸€ä¸ªäº²å‹å›¢ï¼Œä¸å¯¹ï¼Œåº”è¯¥æ˜¯äº²å‹çŸ©é˜µ$\mathbf{V}=[\mathbf{v}^{(1)},â€¦â€¦,\mathbf{v}^{(n)}]$ï¼Œè€Œç‰¹å¾å€¼åˆ™å¯ä»¥ç»„æˆäº²å‹å‘é‡$\mathbf{\lambda}=[\lambda_1,â€¦â€¦,\lambda_n]$,äºæ˜¯åŸçŸ©é˜µ<strong>A</strong>å°±èƒ½åˆ†è§£ä¸º<br>$$<br>A=Vdiag(\lambda)V^{-1}<br>$$</p>
<p>å½“ç„¶å¹¶éæ‰€æœ‰çŸ©é˜µéƒ½å¯ä»¥æœ‰ç‰¹å¾å‘é‡å’Œç‰¹å¾å€¼å•¦ã€‚é¦–å…ˆï¼Œå¯¹ç§°çŸ©é˜µä¸€å®šæœ‰ã€‚</p>
<p>è¿˜æœ‰ä¸€äº›çŸ©é˜µçš„ç‰¹å¾å‘é‡å’Œç‰¹å¾å€¼çš„ç‰¹æ€§ï¼Œä¹‹åå†è¡¥å……å§ï¼</p>
<hr>
<h3 id="å¥‡å¼‚å€¼åˆ†è§£"><a href="#å¥‡å¼‚å€¼åˆ†è§£" class="headerlink" title="å¥‡å¼‚å€¼åˆ†è§£"></a>å¥‡å¼‚å€¼åˆ†è§£</h3><p>æˆ‘ä»¬ä»¥å‰å°±å­¦è¿‡çŸ©é˜µåˆ†è§£ä¸ºç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡ï¼Œå…¶å®çŸ©é˜µè¿˜å¯ä»¥åˆ†è§£ä¸ºå¥‡å¼‚å€¼å’Œå¥‡å¼‚å‘é‡ï¼Œè¿™ä¸ªåˆ†è§£å°±å«åšå¥‡å¼‚å€¼åˆ†è§£SVDï¼ˆ<em>Singular Value Decomposition</em>ï¼‰ã€‚<br>$$<br>A=UDV^\top<br>$$</p>
<p>å’Œç‰¹å¾åˆ†è§£ä¸åŒï¼Œæ¯ä¸€ä¸ªå®çŸ©é˜µéƒ½æœ‰å¥‡å¼‚å€¼åˆ†è§£ã€‚å‡è®¾$A_{m\times n}$æ˜¯ä¸€ä¸ªçŸ©é˜µï¼Œäºæ˜¯Uæ˜¯ä¸€ä¸ªmÃ—mçŸ©é˜µï¼ŒVæ˜¯ä¸€ä¸ªnÃ—nçš„çŸ©é˜µï¼Œè€ŒDä¹Ÿæ˜¯ä¸€ä¸ªmÃ—nçš„çŸ©é˜µã€‚Uå’ŒVæ˜¯æ­£äº¤çŸ©é˜µï¼ŒDæ˜¯å¯¹è§’çŸ©é˜µã€‚å½“ç„¶Dä¸å¿…æ˜¯æ–¹é˜µã€‚ä½†æ˜¯Dçš„å¯¹è§’ä¸Šçš„å…ƒç´ éƒ½æ˜¯AçŸ©é˜µçš„å¥‡å¼‚å€¼ã€‚</p>
<p>Uçš„æ¯ä¸€åˆ—ç§°ä¹‹ä¸ºå·¦å¥‡å¼‚å‘é‡ï¼ŒVçš„æ¯ä¸€åˆ—ç§°ä¹‹ä¸ºå³å¥‡å¼‚å‘é‡ã€‚</p>
<p>å¥‡å¼‚å‘é‡å’Œç‰¹å¾å‘é‡æ˜¯æœ‰ä¸€å®šå…³ç³»çš„ï¼ŒAçš„å·¦å¥‡å¼‚å‘é‡å°±æ˜¯$AA^\top$çš„ç‰¹å¾å‘é‡ï¼›Açš„å³å¥‡å¼‚å‘é‡å°±æ˜¯$A^\top A$çš„ç‰¹å¾å‘é‡ã€‚Açš„éé›¶å¥‡å¼‚å€¼æ˜¯$AA^\top$å’Œ$A^\top A$çš„ç‰¹å¾å€¼çš„å¼€æ–¹ã€‚</p>
<p>è¿™ä¸ªåˆ†è§£ ä¸»è¦æ˜¯ä¸ºäº†ä¸‹é¢çš„å¹¿ä¹‰é€†çŸ©é˜µçš„å­¦ä¹ ã€‚</p>
<hr>
<h3 id="å¹¿ä¹‰é€†çŸ©é˜µ"><a href="#å¹¿ä¹‰é€†çŸ©é˜µ" class="headerlink" title="å¹¿ä¹‰é€†çŸ©é˜µ"></a>å¹¿ä¹‰é€†çŸ©é˜µ</h3><p>æˆ‘ä»¬ä¹‹å‰çš„é€†çŸ©é˜µä¸€èˆ¬éƒ½æ˜¯æ–¹é˜µã€‚<br>ä¸€ä¸ªçº¿æ€§æ–¹ç¨‹ç»„<br>$$<br>Ax=y<br>$$<br>å¦‚æœAå¯é€†ï¼Œé‚£ä¹ˆå¯ä»¥å˜ä¸º<br>$$<br>x=A^{-1}y<br>$$<br>å¦‚æœAæ˜¯å¥‡å¼‚çŸ©é˜µæˆ–è€…ä¸æ˜¯æ–¹é˜µçš„æ—¶å€™ï¼Œæ€ä¹ˆåŠå‘¢ï¼Ÿ</p>
<p>å¹¿ä¹‰é€†çŸ©é˜µçš„æ–¹æ³•å…è®¸æˆ‘ä»¬å®šä¹‰Açš„å¹¿ä¹‰é€†ä¸º<br>$$<br>A^+=\lim_{\alpha\to0}(A^\top A+\alpha I)^{-1}A^\top<br>$$<br>ä¸€èˆ¬ç”¨ä¸‹é¢çš„å…¬å¼ä»£æ›¿ã€‚</p>
<p>$$<br>A^+=VD^+U^\top<br>$$<br>U,D,Væ˜¯Açš„å¥‡å¼‚å€¼åˆ†è§£çš„ç»“æœã€‚è€Œå¯¹è§’çŸ©é˜µDçš„å¹¿ä¹‰é€†$D^+$å³<strong>æŠŠDçš„éé›¶å…ƒç´ å–å€’æ•°ï¼Œç„¶åè½¬ç½®å°±å¯å¾—åˆ°ã€‚</strong></p>
<p>å½“Açš„åˆ—æ•°å¤§äºè¡Œæ•°ï¼Œå¯¹äºä¸Šè¿°çš„çº¿æ€§æ–¹ç¨‹ï¼Œå¯èƒ½æœ‰å¤šä¸ªè§£ã€‚</p>
<p>å½“Açš„è¡Œæ•°å¤§äºåˆ—æ•°ï¼Œå¯¹äºä¸Šè¿°çš„çº¿æ€§æ–¹ç¨‹ï¼Œå¯èƒ½æ²¡æœ‰è§£ã€‚è¿™æ—¶ï¼Œåªèƒ½æ±‚å¾—è¿‘ä¼¼è§£äº†ã€‚</p>
<hr>
<h3 id="çŸ©é˜µçš„è¿¹"><a href="#çŸ©é˜µçš„è¿¹" class="headerlink" title="çŸ©é˜µçš„è¿¹"></a>çŸ©é˜µçš„è¿¹</h3><p>ä¸€èˆ¬æ¥è¯´ï¼ŒçŸ©é˜µçš„è¿¹å°±æ˜¯çŸ©é˜µçš„ä¸»å¯¹è§’çº¿å¯¹è§’å…ƒç´ çš„å’Œã€‚<br>$$<br>Tr(A)=\sum_iA_{i,j}<br>$$<br>è¿™ä¸ªå¯ä»¥æ¥è§£é‡Šè®¸å¤šä¸å¤ªå¥½è§£é‡Šã€è®¡ç®—çš„æ“ä½œã€‚ä¾‹å¦‚ï¼Œè®¡ç®—FrobeniusèŒƒæ•°ï¼Œ<br>$$<br>\vert\vert{A}\vert\vert_F=\sqrt{Tr(AA^T)}<br>$$<br>è¿™æ¯”æŠŠæ‰€æœ‰å…ƒç´ çš„å¹³æ–¹å’Œè®¡ç®—ä¸€éå¿«å¾—å¤šäº†ã€‚</p>
<p>è¿¹æœ‰è®¸å¤šç‰¹æ€§ï¼Œä¾‹å¦‚ï¼ŒçŸ©é˜µçš„è¿¹ç­‰äºçŸ©é˜µçš„è½¬ç½®çš„è¿¹<br>$$<br>Tr(A)=Tr(A^\top)<br>$$<br>å¤šä¸ªçŸ©é˜µä¹˜ç§¯çš„è¿¹ä¹Ÿå¯ä»¥æœ‰ä¸€ä¸ªä¼ªäº¤æ¢å¾‹çš„æ€§è´¨â€”â€”æœ€åä¸€ä¸ªå¯ä»¥æ‹¿åˆ°å‰é¢æ¥ï¼Œä¸èƒ½éšä¾¿äº¤æ¢<br>$$<br>Tr(ABC)=Tr(CAB)=Tr(BCA)<br>$$<br>Or<br>$$<br>Tr(\prod^n_{i=1}F^{(i)})=Tr(F^{(n)}\prod^{n-1}_{i=1}F^{(i)})<br>$$<br>æ–¹å‘ä¸èƒ½å˜å“¦,è¿™ä¸ªä¼ªäº¤æ¢å¾‹æ— éœ€è€ƒè™‘æ˜¯å¦æ–¹é˜µ</p>
<p>æ ‡é‡çš„è¿¹å°±æ˜¯å…¶æœ¬èº«ã€‚</p>
<hr>
<h3 id="è¡Œåˆ—å¼"><a href="#è¡Œåˆ—å¼" class="headerlink" title="è¡Œåˆ—å¼"></a>è¡Œåˆ—å¼</h3><h2 id="å¾…è¡¥å……"><a href="#å¾…è¡¥å……" class="headerlink" title="å¾…è¡¥å……"></a>å¾…è¡¥å……</h2>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/08/21/ã€æœºå™¨å­¦ä¹ ã€‘1-ä»çº¿æ€§ä»£æ•°å¼€å§‹/" itemprop="url">
                  ã€æœºå™¨å­¦ä¹ ã€‘1-ä»çº¿æ€§ä»£æ•°å¼€å§‹
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">å‘è¡¨äº</span>
            <time itemprop="dateCreated" datetime="2016-08-21T16:26:22+08:00" content="2016-08-21">
              2016-08-21
            </time>
          </span>

          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/08/21/ã€æœºå™¨å­¦ä¹ ã€‘1-ä»çº¿æ€§ä»£æ•°å¼€å§‹/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/08/21/ã€æœºå™¨å­¦ä¹ ã€‘1-ä»çº¿æ€§ä»£æ•°å¼€å§‹/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>æœ¬ç§‘æ—¶å€™ï¼Œå·²ç»å­¦è¿‡äº†çº¿æ€§ä»£æ•°ï¼Œè€ƒç ”çš„æ—¶å€™ä¹Ÿæ˜¯é‡ç‚¹ä¹‹ä¸€ï¼Œä½†æ˜¯æ—¶é—´è¿‡å»ç•¥ä¹…ï¼Œä»¥æˆ‘çš„æ²¡è®°æ€§çš„è„‘å­è¿˜æ˜¯å†æ¥å¤ä¹ ä¸€ä¸‹å§ï¼ä¸»è¦æ˜¯æ¦‚å¿µä¸Šçš„ã€‚</p>
<hr>
<h3 id="Scalars-Vectors-Matrices-and-Tensors"><a href="#Scalars-Vectors-Matrices-and-Tensors" class="headerlink" title="Scalars, Vectors, Matrices and Tensors"></a>Scalars, Vectors, Matrices and Tensors</h3><p>ã€æ ‡é‡ã€å‘é‡ã€çŸ©é˜µã€å¼ é‡ã€‘<br>æ ‡é‡ã€å‘é‡çš„æ¦‚å¿µå°±ä¸å¤šè¯´äº†<br>å…³äºçŸ©é˜µçš„å…¬å¼åœ¨è¿™é‡Œåˆ—å‡ ä¸ªå§ï¼š</p>
<ol>
<li>$\mathbf{C} = \mathbf{A} + \mathbf{B} $   where  $C_{i,j}= A_{i,j}+B_{i,j}$\ ddd $a^{3}_{ij}$\</li>
<li>$\mathbf{D}=a \bullet \mathbf{B} + c$ where $ D _{i,j}= a \bullet B _{i,j}+c $</li>
<li>$\mathbf{C}=\mathbf{A}+\mathbf{b}$ where  $ C _{i,j}=a \bullet B _{i,j}+b _j $</li>
<li>$\mathbf{C}=\mathbf{AB}$ where  $ C _{i,j}=\sum _kA _{i,k}B _{j,k} $</li>
</ol>
<p>$$<br>C=AB=\begin{pmatrix} 1 &amp; 2 &amp; 3 \\4 &amp; 5 &amp; 6 \end{pmatrix} \begin{pmatrix}1 &amp; 4\\ 2&amp;5\\ 3&amp;6 \end{pmatrix}=\begin{pmatrix} 1\times1+2\times2+3\times3 &amp; 1\times4+2\times5+3\times6  \\4\times1+5\times2+6\times3&amp; 4\times4+5\times5+6\times6 \end{pmatrix}=\begin{pmatrix} 14 &amp; 32 \\32 &amp; 77 \end{pmatrix}<br>$$</p>
<ol>
<li><strong>Hadamard product:</strong> $\mathbf{A}\bigodot\mathbf{B}$  where  ${A\bigodot B}_{i,j}=a_{i,j}b_{i,j}$ </li>
</ol>
<p>$$<br>\begin{pmatrix} 1 &amp; 3 &amp; 2 \\1 &amp; 0 &amp; 0\\1&amp;2&amp;2 \end{pmatrix}\bigodot \begin{pmatrix}0&amp;0 &amp;2\\ 7&amp;5&amp;0\\ 2&amp;1&amp;1 \end{pmatrix}=\begin{pmatrix} 1\times0&amp;3\times0&amp;2\times2\\ 1\times7&amp;0\times5&amp;0\times0 \\1\times3&amp;2\times1&amp;2\times1\end{pmatrix}=\begin{pmatrix} 0 &amp; 0&amp;4 \\7 &amp; 0&amp;0\\2&amp;2&amp;2 \end{pmatrix}<br>$$</p>
<ol>
<li>éƒ¨åˆ†ä¹˜æ³•å…¬å¼ï¼š</li>
</ol>
<ul>
<li><strong><em>A</em></strong>(<strong><em>B</em></strong> + <strong><em>C</em></strong>) = <strong><em>AB</em></strong> + <strong><em>AC</em></strong>. </li>
<li><strong><em>A</em></strong>(<strong><em>BC</em></strong>) = (<strong><em>AB</em></strong>)<strong><em>C</em></strong>.</li>
<li>ä¸€èˆ¬ä¸æ»¡è¶³äº¤æ¢å¾‹</li>
<li>å‘é‡å¯ä»¥æ»¡è¶³äº¤æ¢å¾‹$\mathbf{x}^{\top}\mathbf{y}=\mathbf{y}^{\top}\mathbf{x}$</li>
<li>$(\mathbf{AB})^{\top}=\mathbf{B}^{\top}\mathbf{A}^{\top}$</li>
</ul>
<ol>
<li>é€†çŸ©é˜µï¼š$\mathbf{A^{-1}}\mathbf{A}=\mathbf{I_n}$</li>
</ol>
<h3 id="Linear-Dependence-and-Span"><a href="#Linear-Dependence-and-Span" class="headerlink" title="Linear Dependence and Span"></a>Linear Dependence and Span</h3><p>æ ¹æ®é€†çŸ©é˜µçš„å®šä¹‰ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨è¿™ä¸ªæ¥è§£<strong><em>Ax=b</em></strong>çš„è§£ï¼Œå› ä¸º$\mathbf{x}=\mathbf{A^{-1}b}$,ä½†è¿™æœ‰ä¸€ä¸ªå‰æé‚£å°±æ˜¯$A^{-a}$å¿…é¡»å­˜åœ¨ã€‚</p>
<h3 id="Norms-èŒƒæ•°"><a href="#Norms-èŒƒæ•°" class="headerlink" title="Norms èŒƒæ•°"></a>Norms èŒƒæ•°</h3><p>å…³äºèŒƒæ•°çš„ä½œç”¨ï¼Œä¹¦é‡Œé¢ç»™å‡ºè¿™æ ·çš„è§£é‡Šï¼š</p>
<blockquote>
<p>Sometimes we need to measure the size of a vector. In machine learning, we usually measure the size of vectors using a function called a norm. Formally, the $L^p$ norm is given by</p>
</blockquote>
<p>$$<br>\begin{aligned}<br>\vert\vert{x}\vert\vert _p=(\sum_i \vert{x}\vert ^p)^{\frac{1}{p}}<br>\end{aligned}<br>$$<br>for $p\in\mathbb{R},p \ge1$</p>
<p>å¯¹äºèŒƒæ•°ï¼Œå¯ä»¥è®¤ä¸ºæ˜¯æè¿°å‘é‡é•¿åº¦çš„ä¸€ä¸ªæ–¹å¼ï¼Œå¯ä»¥çœ‹ä½œæ˜¯ä¸€ä¸ªå‡½æ•°<em>f</em>ï¼Œé‚£ä¹ˆåªè¦æ»¡è¶³ä¸‹é¢ä¸‰ä¸ªæ¡ä»¶ï¼Œé‚£ä¹ˆéƒ½æ˜¯èŒƒæ•°ï¼š</p>
<ol>
<li>æ­£å®šæ€§ï¼š$f(\mathbf{x})=0\Rightarrow \mathbf{x=0}$ï¼Œå¯ä»¥ç†è§£ä¸ºè‹¥æ˜¯é•¿åº¦ä¸º0ï¼Œåˆ™ä¸€å®šä¸º0å‘é‡</li>
<li>ä¸‰è§’ä¸ç­‰å¼ï¼š$f(\mathbf{x+y})\le f(\mathbf{x})+f(\mathbf{y})$</li>
<li>é½æ¬¡æ€§ï¼š$\forall\alpha\in\mathbb{R},f(\alpha x)=\vert\alpha\vert f(x)$,å¯¹äºæ ‡é‡çš„ä¹˜æ³•åº”è¯¥æ»¡è¶³é½æ¬¡æ€§</li>
</ol>
<p><strong>ä¸‹é¢è¯´ä¸‹å‡ ä¸ªç‰¹æ®Šçš„èŒƒæ•°ï¼š</strong></p>
<p>$L^2$èŒƒæ•°,pæ˜¯2çš„æ—¶å€™ï¼Œå°±æ˜¯$\vert\vert{\mathbf{x}}\vert\vert$ï¼ˆ2çš„æ—¶å€™å¯ä»¥æŠŠ2ç•¥æ‰ï¼‰ï¼Œç§°ä¸ºæ¬§å‡ é‡Œå¾—èŒƒæ•°ï¼ˆ<em>Euclidean norm</em>ï¼‰,å®ƒçš„è®¡ç®—æ–¹å¼å¾ˆç®€å•å°±æ˜¯$\sqrt{\mathbf{x^{\top}x}}$,ä¸€èˆ¬æ¥è¯´ï¼Œç”¨åˆ°2èŒƒæ•°çš„å¹³æ–¹æ›´å¤šä¸€äº›ã€‚</p>
<p>$L^1$èŒƒæ•°ï¼Œä¸€èˆ¬ä»$L^2$å¼€å§‹çš„èŒƒæ•°ï¼Œå…¶å˜åŒ–éƒ½æ˜¯è¶Šå¼€å§‹è¶Šæ…¢ï¼Œè€Œåªæœ‰$L^1$èŒƒæ•°å¯ä»¥åšåˆ°æ’å®šå˜åŒ–ã€‚è¿™åœ¨åšä¸€äº›åˆå§‹å˜åŒ–çš„æœºå™¨å­¦ä¹ ä¸­å¾ˆæœ‰å¸®åŠ©ã€‚</p>
<p>åœ¨è¿™é‡Œè¦è¯´ä¸€ä¸‹$L^0$èŒƒæ•°ï¼Œæœ‰äººæŠŠ<strong>å‘é‡ä¸­é0å…ƒç´ çš„ä¸ªæ•°</strong>ç§°ä¸º$L^0$èŒƒæ•°ã€‚ä½†è¿™æ˜¯<strong>ä¸è§„èŒƒ</strong>çš„ï¼Œå®é™…ä¸Šä¸€èˆ¬çš„ä¹¦ä¸Šéƒ½æ²¡æœ‰$L^0$èŒƒæ•°çš„è¯´æ³•ã€‚å› ä¸ºå…¶ä¸æ»¡è¶³ä¸Šè¿°çš„ç¬¬ä¸‰ä¸ªæ¡ä»¶â€”â€”é½æ¬¡æ€§ï¼Œå‘é‡çš„å˜åŒ–ï¼Œä¸ä¼šæ”¹å˜é0çš„æ•°ç›®ã€‚æ‰€ä»¥æœ€å¥½ç”¨$L^1$èŒƒæ•°æ¥æ›¿ä»£ã€‚</p>
<p>$L^\infty$èŒƒæ•°ï¼Œå‘é‡ä¸­å…ƒç´ ç»å¯¹å€¼çš„æœ€å¤§å€¼ï¼Œå³</p>
<p>$$<br>\begin{aligned}<br>\vert\vert{\mathbf{x}}\vert\vert_\infty=max_{i}\vert{x_i}\vert<br>\end{aligned}<br>$$</p>
<p>Frobenius norm:å‰é¢çš„èŒƒæ•°éƒ½æ˜¯ä¸ˆé‡å‘é‡çš„ï¼Œè€ŒFrobenius normæ˜¯ä¸ˆé‡çŸ©é˜µçš„ï¼Œè€Œä¸”è¿™é‡Œå°¤ç±»ä¼¼ä¸Šè¿°çš„$L^2$èŒƒæ•°ï¼Œ</p>
<p>$$<br>\begin{aligned}<br>\vert\vert{A}\vert\vert_F=\sqrt{\sum_{i,j}A^2_{i,j}}<br>\end{aligned}<br>$$</p>
<p>å‘é‡çš„ç‚¹ä¹˜å¯è¡¨ç¤ºä¸ºèŒƒæ•°çš„ä¹˜æœº$\mathbf{x}^\top\mathbf{y}=\vert\vert{\mathbf{x}}\vert\vert_2\vert\vert{\mathbf{y}}\vert\vert_2cos\theta$</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  


          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel  sidebar-panel-active ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="https://img1.doubanio.com/icon/ul61277596-19.jpg"
               alt="ç™¾è‰²æ¢µ" />
          <p class="site-author-name" itemprop="name">ç™¾è‰²æ¢µ</p>
          <p class="site-description motion-element" itemprop="description">æ˜¯ç¿©ç¿©å…¬å­ï¼Œä¹Ÿæ˜¯æµŠä¸–çƒŸæª
æ˜¯ä¸‰åˆ†å‰‘ä¾ ï¼Œåˆæ˜¯ä¸‰åˆ†éªšå®¢
çˆ±è‡ªç”±åˆè¨€æ…ç‹¬
æ˜æ˜¯éå´æ€§æ¿€æ„¤
è½»è£…ä¸Šé˜µï¼Œä¸å¿˜ä¸‡é‡Œå±±æ²³
æ¬²ç™»äº‘å¤©ï¼Œè°äººå»æˆ‘é˜¡é™Œ
å°†é”™å°±é”™æ— äººä¹‹è¿‡
ä¼¼é†’éé†’æœ¬æ˜¯å¯‚å¯
</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">9</span>
              <span class="site-state-item-name">æ—¥å¿—</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">1</span>
                <span class="site-state-item-name">åˆ†ç±»</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">5</span>
                <span class="site-state-item-name">æ ‡ç­¾</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

      </section>

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2016</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">ç™¾è‰²æ¢µ</span>
</div>

<div class="powered-by">
  ç”± <a class="theme-link" href="https://hexo.io">Hexo</a> å¼ºåŠ›é©±åŠ¨
</div>

<div class="theme-info">
  ä¸»é¢˜ -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>

        

<div class="busuanzi-count">

  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv"><i class="fa fa-user"></i><span class="busuanzi-value" id="busuanzi_value_site_uv"></span></span>
  

  
    <span class="site-pv"><i class="fa fa-eye"></i><span class="busuanzi-value" id="busuanzi_value_site_pv"></span></span>
  
  
</div>



        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.1"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.1"></script>



  

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"lvvan"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.id = 'duoshuo-script';
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>

  
    
    <script src="/vendors/ua-parser-js/dist/ua-parser.min.js?v=0.7.9"></script>
    <script src="/js/src/hook-duoshuo.js"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
  






  
  

  

  

  

</body>
</html>
